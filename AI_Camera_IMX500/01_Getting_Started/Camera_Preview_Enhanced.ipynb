{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“¸ Your First AI Camera Experience: From Pixels to Intelligence\n",
    "\n",
    "**Welcome to the magic moment!** âœ¨ You're about to see your **Sony IMX500 AI Camera** in action for the first time.\n",
    "\n",
    "## ğŸ¯ What You'll Experience\n",
    "\n",
    "This notebook demonstrates the **fundamental difference** between traditional cameras and AI cameras:\n",
    "\n",
    "**ğŸ”„ The Journey From Passive to Intelligent Vision:**\n",
    "1. **Traditional Preview**: See what a regular camera sees (just pixels)\n",
    "2. **AI-Enhanced Preview**: Experience intelligent vision in real-time\n",
    "3. **Understanding**: Learn what makes your camera \"smart\"\n",
    "\n",
    "## ğŸ§  The Revolutionary IMX500 Difference\n",
    "\n",
    "Your camera doesn't just capture light - it **understands** what it sees:\n",
    "- **Real-time AI processing** at 30+ FPS\n",
    "- **On-sensor intelligence** (no cloud needed!)\n",
    "- **Instant object recognition** with confidence scores\n",
    "- **Edge AI computing** in a sensor smaller than your thumbnail\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ Camera System Preparation\n",
    "\n",
    "**Let's prepare your AI camera for its first demonstration:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import cv2\n",
    "import numpy as np\n",
    "from IPython.display import display, clear_output, Image, HTML\n",
    "import ipywidgets as widgets\n",
    "import threading\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"ğŸš€ AI CAMERA SYSTEM INITIALIZATION\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"ğŸ“… Session Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "print(\"\\nğŸ”§ Preparing camera system...\")\n",
    "\n",
    "# Clean up any existing camera processes for exclusive access\n",
    "camera_processes = [\"libcamera-vid\", \"libcamera-still\", \"libcamera-raw\", \"rpicam-vid\", \"rpicam-still\"]\n",
    "for process in camera_processes:\n",
    "    subprocess.run([\"pkill\", \"-9\", process], stderr=subprocess.DEVNULL)\n",
    "\n",
    "# Unload conflicting video driver to ensure libcamera has exclusive access\n",
    "subprocess.run([\"sudo\", \"rmmod\", \"bcm2835_v4l2\"], stderr=subprocess.DEVNULL)\n",
    "\n",
    "print(\"âœ… Camera processes cleaned up\")\n",
    "print(\"âœ… System prepared for AI camera access\")\n",
    "\n",
    "# Quick system check\n",
    "print(\"\\nğŸ” Quick system verification...\")\n",
    "try:\n",
    "    result = subprocess.run([\"rpicam-hello\", \"--list-cameras\"], \n",
    "                          capture_output=True, text=True, timeout=5)\n",
    "    if \"imx500\" in result.stdout.lower():\n",
    "        print(\"âœ… IMX500 AI Camera detected and ready!\")\n",
    "    else:\n",
    "        print(\"âš ï¸ Camera detected, but may not be IMX500\")\n",
    "        print(\"ğŸ’¡ Don't worry - you can still see the difference between regular and AI cameras!\")\nexcept:\n",
    "    print(\"ğŸ”§ Camera detection had issues, but let's proceed with the demo\")\n",
    "\n",
    "print(\"\\nğŸ‰ System ready for your first AI camera experience!\")\n",
    "print(\"\\nğŸ“‹ What you'll see in this demonstration:\")\n",
    "print(\"   ğŸ“· Traditional camera view: Raw pixels and colors\")\n",
    "print(\"   ğŸ§  AI-enhanced view: Smart object detection and analysis\")\n",
    "print(\"   ğŸ“Š Real-time confidence scores and object identification\")\n",
    "print(\"\\nğŸš€ Let's begin your journey into intelligent vision!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“· Part 1: Traditional Camera Preview\n",
    "\n",
    "**First, let's see what a traditional camera sees - just raw pixels without intelligence:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“· TRADITIONAL CAMERA PREVIEW\")\n",
    "print(\"=\" * 35)\n",
    "print(\"\\nğŸ¯ This is how regular cameras see the world:\")\n",
    "print(\"   â€¢ Just pixels and colors\")\n",
    "print(\"   â€¢ No understanding of what objects are\")\n",
    "print(\"   â€¢ Raw visual data without intelligence\")\n",
    "\n",
    "# Create control widgets for traditional preview\n",
    "traditional_stop_button = widgets.ToggleButton(\n",
    "    value=False,\n",
    "    description='â¹ï¸ Stop Traditional Preview',\n",
    "    button_style='danger',\n",
    "    layout=widgets.Layout(width='220px', height='40px')\n",
    ")\n",
    "\n",
    "traditional_status = widgets.Output()\n",
    "\n",
    "display(widgets.VBox([traditional_stop_button, traditional_status]))\n",
    "\n",
    "def traditional_camera_preview():\n",
    "    \"\"\"Show traditional camera preview without AI processing\"\"\"\n",
    "    \n",
    "    with traditional_status:\n",
    "        clear_output(wait=True)\n",
    "        print(\"ğŸ“· Traditional Camera Active\")\n",
    "        print(\"ğŸ’­ Camera thinking: 'I see pixels, but I don't know what they are'\")\n",
    "        print(\"ğŸ” Look closely - no object identification or intelligence!\")\n",
    "    \n",
    "    # Use basic camera preview without AI post-processing\n",
    "    cmd = [\n",
    "        \"rpicam-vid\",\n",
    "        \"--inline\",           # Needed for streaming\n",
    "        \"-t\", \"0\",            # No timeout\n",
    "        \"--width\", \"640\",     # Medium resolution for comparison\n",
    "        \"--height\", \"480\",\n",
    "        \"--framerate\", \"30\",\n",
    "        \"--codec\", \"mjpeg\",\n",
    "        \"-o\", \"-\"             # Output to stdout\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.DEVNULL)\n",
    "        \n",
    "        data = b\"\"\n",
    "        frame_count = 0\n",
    "        display_handle = display(None, display_id=True)\n",
    "        \n",
    "        while not traditional_stop_button.value:\n",
    "            chunk = proc.stdout.read(2048)\n",
    "            if not chunk:\n",
    "                break\n",
    "                \n",
    "            data += chunk\n",
    "            \n",
    "            # Look for complete JPEG frames\n",
    "            start = data.find(b'\\xff\\xd8')  # JPEG start marker\n",
    "            end = data.find(b'\\xff\\xd9')    # JPEG end marker\n",
    "            \n",
    "            if start != -1 and end != -1:\n",
    "                jpg_data = data[start:end+2]\n",
    "                data = data[end+2:]  # Keep remaining data for next frame\n",
    "                \n",
    "                try:\n",
    "                    # Decode and display frame\n",
    "                    frame = cv2.imdecode(np.frombuffer(jpg_data, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "                    if frame is not None:\n",
    "                        _, display_jpg = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 80])\n",
    "                        display_handle.update(Image(data=display_jpg.tobytes()))\n",
    "                        \n",
    "                        frame_count += 1\n",
    "                        \n",
    "                        # Update status periodically\n",
    "                        if frame_count % 90 == 0:  # Every ~3 seconds\n",
    "                            with traditional_status:\n",
    "                                clear_output(wait=True)\n",
    "                                print(f\"ğŸ“· Traditional Camera Active - Frame {frame_count}\")\n",
    "                                print(\"ğŸ’­ Camera: 'I see colors and shapes, but what are they?'\")\n",
    "                                print(\"ğŸ¤· No object recognition, no intelligence, just raw pixels\")\n",
    "                                print(\"\\nğŸ‘€ Notice: No boxes, no labels, no understanding!\")\n",
    "                        \n",
    "                except Exception:\n",
    "                    continue  # Skip corrupted frames\n",
    "            \n",
    "            time.sleep(0.001)  # Small delay to prevent overwhelming the system\n",
    "    \n",
    "    except Exception as e:\n",
    "        with traditional_status:\n",
    "            clear_output(wait=True)\n",
    "            print(f\"âŒ Traditional camera error: {e}\")\n",
    "            print(\"ğŸ”§ This might be a connection issue, but don't worry!\")\n",
    "    \n",
    "    finally:\n",
    "        try:\n",
    "            proc.terminate()\n",
    "            proc.wait(timeout=2)\n",
    "        except:\n",
    "            proc.kill()\n",
    "        \n",
    "        with traditional_status:\n",
    "            clear_output(wait=True)\n",
    "            print(\"â¹ï¸ Traditional camera preview stopped\")\n",
    "            print(\"\\nğŸ“ What you just saw:\")\n",
    "            print(\"   â€¢ Raw camera feed with no intelligence\")\n",
    "            print(\"   â€¢ Just pixels, shapes, and colors\")\n",
    "            print(\"   â€¢ No understanding of what objects are\")\n",
    "            print(\"\\nğŸ¤– Ready to see the AI difference? Scroll down!\")\n",
    "\n",
    "# Start traditional preview in a separate thread\n",
    "traditional_thread = threading.Thread(target=traditional_camera_preview, daemon=True)\n",
    "traditional_thread.start()\n",
    "\n",
    "print(\"\\nğŸ¥ Traditional camera preview started above!\")\n",
    "print(\"\\nğŸ“ Observe carefully:\")\n",
    "print(\"   âŒ No bounding boxes around objects\")\n",
    "print(\"   âŒ No object labels or names\")\n",
    "print(\"   âŒ No confidence scores\")\n",
    "print(\"   âŒ No intelligent analysis\")\n",
    "print(\"\\nğŸ’¡ This is how ALL cameras worked before AI revolution!\")\n",
    "print(\"\\nâ¹ï¸ Click 'Stop Traditional Preview' when ready to see AI magic!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§  Part 2: AI-Enhanced Camera Preview\n",
    "\n",
    "**Now, let's see the same world through the eyes of artificial intelligence!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ§  AI-ENHANCED CAMERA PREVIEW\")\n",
    "print(\"=\" * 35)\n",
    "print(\"\\nğŸš€ This is how your IMX500 AI camera sees the world:\")\n",
    "print(\"   ğŸ¯ Real-time object detection\")\n",
    "print(\"   ğŸ·ï¸ Instant object identification\")\n",
    "print(\"   ğŸ“Š Confidence scores for each detection\")\n",
    "print(\"   ğŸ”² Precise bounding boxes around objects\")\n",
    "print(\"   âš¡ All processing happens ON THE SENSOR!\")\n",
    "\n",
    "# Create control widgets for AI preview\n",
    "ai_stop_button = widgets.ToggleButton(\n",
    "    value=False,\n",
    "    description='â¹ï¸ Stop AI Preview',\n",
    "    button_style='danger',\n",
    "    layout=widgets.Layout(width='180px', height='40px')\n",
    ")\n",
    "\n",
    "ai_status = widgets.Output()\n",
    "\n",
    "display(widgets.VBox([ai_stop_button, ai_status]))\n",
    "\n",
    "def ai_camera_preview():\n",
    "    \"\"\"Show AI-enhanced camera preview with real-time object detection\"\"\"\n",
    "    \n",
    "    with ai_status:\n",
    "        clear_output(wait=True)\n",
    "        print(\"ğŸ§  AI Camera Activating...\")\n",
    "        print(\"âš¡ Loading neural network on IMX500 sensor...\")\n",
    "        print(\"ğŸš€ Preparing real-time object detection...\")\n",
    "    \n",
    "    # Use AI-enabled camera with MobileNet SSD object detection\n",
    "    cmd = [\n",
    "        \"rpicam-vid\",\n",
    "        \"--inline\",           # Needed for streaming\n",
    "        \"-t\", \"0\",            # No timeout\n",
    "        \"--width\", \"640\",     # Same resolution as traditional for fair comparison\n",
    "        \"--height\", \"480\",\n",
    "        \"--framerate\", \"30\",  # Smooth 30fps AI processing!\n",
    "        \"--codec\", \"mjpeg\",\n",
    "        \"--post-process-file\", \"/usr/share/rpi-camera-assets/imx500_mobilenet_ssd.json\",\n",
    "        \"-o\", \"-\"             # Output to stdout\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.DEVNULL)\n",
    "        \n",
    "        data = b\"\"\n",
    "        frame_count = 0\n",
    "        detection_count = 0\n",
    "        display_handle = display(None, display_id=True)\n",
    "        \n",
    "        with ai_status:\n",
    "            clear_output(wait=True)\n",
    "            print(\"ğŸ§  AI Camera ACTIVE - Intelligence Engaged!\")\n",
    "            print(\"âš¡ Neural network processing at 30 FPS\")\n",
    "            print(\"ğŸ¯ Detecting objects in real-time...\")\n",
    "        \n",
    "        while not ai_stop_button.value:\n",
    "            chunk = proc.stdout.read(2048)\n",
    "            if not chunk:\n",
    "                break\n",
    "                \n",
    "            data += chunk\n",
    "            \n",
    "            # Look for complete JPEG frames\n",
    "            start = data.find(b'\\xff\\xd8')  # JPEG start marker\n",
    "            end = data.find(b'\\xff\\xd9')    # JPEG end marker\n",
    "            \n",
    "            if start != -1 and end != -1:\n",
    "                jpg_data = data[start:end+2]\n",
    "                data = data[end+2:]  # Keep remaining data for next frame\n",
    "                \n",
    "                try:\n",
    "                    # Decode and display frame\n",
    "                    frame = cv2.imdecode(np.frombuffer(jpg_data, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "                    if frame is not None:\n",
    "                        _, display_jpg = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 80])\n",
    "                        display_handle.update(Image(data=display_jpg.tobytes()))\n",
    "                        \n",
    "                        frame_count += 1\n",
    "                        \n",
    "                        # Simulate detection counting (in real implementation, this would parse metadata)\n",
    "                        if frame_count % 30 == 0:  # Every second\n",
    "                            detection_count += 1  # Simulated\n",
    "                        \n",
    "                        # Update status periodically\n",
    "                        if frame_count % 90 == 0:  # Every ~3 seconds\n",
    "                            with ai_status:\n",
    "                                clear_output(wait=True)\n",
    "                                print(f\"ğŸ§  AI Camera ACTIVE - Frame {frame_count}\")\n",
    "                                print(f\"ğŸ’­ AI Brain: 'I understand what I see!'\")\n",
    "                                print(f\"ğŸ¯ Processing {frame_count//30} seconds of intelligent analysis\")\n",
    "                                print(\"\\nâœ¨ Notice the DIFFERENCE:\")\n",
    "                                print(\"   ğŸ”² Colored boxes around detected objects\")\n",
    "                                print(\"   ğŸ·ï¸ Object labels (person, car, phone, etc.)\")\n",
    "                                print(\"   ğŸ“Š Confidence percentages (85%, 92%, etc.)\")\n",
    "                                print(\"   âš¡ All happening in REAL-TIME on the sensor!\")\n",
    "                        \n",
    "                except Exception:\n",
    "                    continue  # Skip corrupted frames\n",
    "            \n",
    "            time.sleep(0.001)  # Small delay to prevent overwhelming the system\n",
    "    \n",
    "    except Exception as e:\n",
    "        with ai_status:\n",
    "            clear_output(wait=True)\n",
    "            print(f\"âŒ AI camera error: {e}\")\n",
    "            print(\"\\nğŸ”§ Possible issues:\")\n",
    "            print(\"   â€¢ AI model files not installed\")\n",
    "            print(\"   â€¢ Try: sudo apt install imx500-models\")\n",
    "            print(\"   â€¢ Camera connection problems\")\n",
    "            print(\"\\nğŸ’¡ Even if AI features don't work, you learned the concept!\")\n",
    "    \n",
    "    finally:\n",
    "        try:\n",
    "            proc.terminate()\n",
    "            proc.wait(timeout=2)\n",
    "        except:\n",
    "            proc.kill()\n",
    "        \n",
    "        with ai_status:\n",
    "            clear_output(wait=True)\n",
    "            print(\"â¹ï¸ AI camera preview stopped\")\n",
    "            print(\"\\nğŸ‰ What you just experienced:\")\n",
    "            print(\"   âœ… Real-time AI object detection\")\n",
    "            print(\"   âœ… Intelligent understanding of visual scenes\")\n",
    "            print(\"   âœ… On-sensor neural network processing\")\n",
    "            print(\"   âœ… Edge AI computing at incredible speed\")\n",
    "            print(\"\\nğŸ† You've seen the future of computer vision!\")\n",
    "\n",
    "print(\"\\nğŸš€ Starting AI-enhanced preview...\")\n",
    "print(\"\\nğŸ¯ What to look for:\")\n",
    "print(\"   âœ… Colored rectangles around detected objects\")\n",
    "print(\"   âœ… Object names like 'person', 'cell phone', 'cup'\")\n",
    "print(\"   âœ… Confidence scores like '89%', '94%'\")\n",
    "print(\"   âœ… Real-time updates as you move objects\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Try this experiment:\")\n",
    "print(\"   ğŸ“± Hold your phone in front of the camera\")\n",
    "print(\"   â˜• Show it a cup or bottle\")\n",
    "print(\"   ğŸ‘‹ Wave your hand (detects as 'person')\")\n",
    "print(\"   ğŸ“š Try a book or any household object\")\n",
    "\n",
    "# Start AI preview in a separate thread\n",
    "ai_thread = threading.Thread(target=ai_camera_preview, daemon=True)\n",
    "ai_thread.start()\n",
    "\n",
    "print(\"\\nğŸ¤– AI magic happening above! This is the power of the IMX500!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ Understanding What You Just Experienced\n",
    "\n",
    "**Let's break down the incredible technology you just witnessed:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“ UNDERSTANDING YOUR AI CAMERA EXPERIENCE\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "print(\"\\nğŸ” THE DRAMATIC DIFFERENCE YOU WITNESSED:\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "comparison = {\n",
    "    \"ğŸ“· Traditional Camera\": {\n",
    "        \"what_it_sees\": \"Just pixels, colors, and shapes\",\n",
    "        \"processing\": \"No analysis - raw image data only\",\n",
    "        \"output\": \"Video stream with no understanding\",\n",
    "        \"intelligence\": \"Zero - requires human interpretation\",\n",
    "        \"response_time\": \"Instant capture, but no analysis\",\n",
    "        \"analogy\": \"Like a photocopier - duplicates but doesn't understand\"\n",
    "    },\n",
    "    \"ğŸ§  IMX500 AI Camera\": {\n",
    "        \"what_it_sees\": \"Objects, people, and their relationships\",\n",
    "        \"processing\": \"Real-time neural network analysis on sensor\",\n",
    "        \"output\": \"Structured data: object types, locations, confidence\",\n",
    "        \"intelligence\": \"High - recognizes 80+ object categories\",\n",
    "        \"response_time\": \"30+ FPS real-time AI processing\",\n",
    "        \"analogy\": \"Like a smart human observer with instant recognition\"\n",
    "    }\n",
    "}\n",
    "\n",
    "for camera_type, details in comparison.items():\n",
    "    print(f\"\\n{camera_type}:\")\n",
    "    for aspect, description in details.items():\n",
    "        aspect_name = aspect.replace('_', ' ').title()\n",
    "        print(f\"   {aspect_name}: {description}\")\n",
    "\n",
    "print(\"\\n\\nâš¡ THE REVOLUTIONARY IMX500 TECHNOLOGY:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "imx500_features = [\n",
    "    \"ğŸ§  On-Sensor AI Processing: Neural network runs directly on the camera chip\",\n",
    "    \"âš¡ Edge Computing: No internet or external computer needed\",\n",
    "    \"ğŸš€ Real-Time Speed: 30+ frames per second of AI analysis\",\n",
    "    \"ğŸ¯ Pre-Trained Intelligence: Already knows 80+ object types\",\n",
    "    \"ğŸ’ª Low Power: Efficient processing with minimal energy consumption\",\n",
    "    \"ğŸ”’ Privacy: All AI processing happens locally, not in the cloud\",\n",
    "    \"ğŸ“Š Structured Output: Provides coordinates, confidence, and object types\",\n",
    "    \"ğŸŒ Standard Interface: Works with regular Raspberry Pi camera commands\"\n",
    "]\n",
    "\n",
    "for feature in imx500_features:\n",
    "    print(f\"   {feature}\")\n",
    "\n",
    "print(\"\\n\\nğŸ§  THE AI PROCESSING PIPELINE YOU JUST SAW:\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "pipeline_steps = [\n",
    "    (\"1ï¸âƒ£ Light Capture\", \"Sensor converts photons to electrical signals\"),\n",
    "    (\"2ï¸âƒ£ Image Formation\", \"Raw pixel data formed into digital image\"),\n",
    "    (\"3ï¸âƒ£ AI Pre-processing\", \"Image optimized for neural network analysis\"),\n",
    "    (\"4ï¸âƒ£ Neural Network Processing\", \"MobileNet SSD analyzes image for objects\"),\n",
    "    (\"5ï¸âƒ£ Object Detection\", \"AI identifies objects and calculates confidence\"),\n",
    "    (\"6ï¸âƒ£ Post-processing\", \"Results filtered and formatted\"),\n",
    "    (\"7ï¸âƒ£ Visualization\", \"Bounding boxes and labels added to image\"),\n",
    "    (\"8ï¸âƒ£ Output Stream\", \"Enhanced video with AI annotations sent to you\")\n",
    "]\n",
    "\n",
    "for step, description in pipeline_steps:\n",
    "    print(f\"   {step}: {description}\")\n",
    "\n",
    "print(\"\\nâš¡ ALL 8 STEPS HAPPEN 30+ TIMES PER SECOND ON THE SENSOR!\")\n",
    "\n",
    "print(\"\\n\\nğŸ“Š WHAT THE AI CAN DETECT (COCO Dataset Objects):\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "object_categories = {\n",
    "    \"ğŸ‘¥ People & Animals\": [\"person\", \"cat\", \"dog\", \"bird\", \"horse\", \"sheep\", \"cow\"],\n",
    "    \"ğŸš— Vehicles\": [\"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\"],\n",
    "    \"ğŸ“± Electronics\": [\"tv\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\"],\n",
    "    \"ğŸ Food & Kitchen\": [\"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"banana\", \"apple\"],\n",
    "    \"ğŸ  Household Items\": [\"chair\", \"couch\", \"bed\", \"dining table\", \"toilet\", \"book\", \"clock\"]\n",
    "}\n",
    "\n",
    "for category, objects in object_categories.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    print(f\"   {', '.join(objects[:5])}{'...' if len(objects) > 5 else ''}\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ Total: 80 different object types the AI can recognize instantly!\")\n",
    "\n",
    "print(\"\\n\\nğŸ† WHAT YOU'VE ACCOMPLISHED:\")\n",
    "print(\"-\" * 30)\n",
    "achievements = [\n",
    "    \"âœ… Experienced the difference between traditional and AI cameras\",\n",
    "    \"âœ… Witnessed real-time edge AI processing in action\",\n",
    "    \"âœ… Understood on-sensor neural network computing\",\n",
    "    \"âœ… Saw object detection with confidence scores\",\n",
    "    \"âœ… Learned about the revolutionary IMX500 technology\",\n",
    "    \"âœ… Gained foundational knowledge for advanced AI applications\"\n",
    "]\n",
    "\n",
    "for achievement in achievements:\n",
    "    print(f\"   {achievement}\")\n",
    "\n",
    "print(\"\\nğŸ‰ You've just experienced cutting-edge AI technology!\")\n",
    "print(\"ğŸš€ This is the foundation for everything you'll build in this course!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ‰ Congratulations - You've Seen the Future!\n",
    "\n",
    "**Amazing work!** You've just experienced the **revolutionary difference** between traditional cameras and AI-powered vision systems.\n",
    "\n",
    "### ğŸ† What You've Accomplished\n",
    "\n",
    "âœ… **Witnessed AI Magic**: Seen real-time object detection in action\n",
    "\n",
    "âœ… **Understood Edge AI**: Experienced on-sensor neural network processing\n",
    "\n",
    "âœ… **Grasped the Difference**: Clearly see why AI cameras are revolutionary\n",
    "\n",
    "âœ… **Built Foundation**: Ready for advanced AI applications\n",
    "\n",
    "### ğŸ§  Key Insights You've Gained\n",
    "\n",
    "1. **Traditional cameras** are passive - they just capture pixels\n",
    "2. **AI cameras** are intelligent - they understand what they see\n",
    "3. **Edge AI processing** happens instantly, locally, without internet\n",
    "4. **Real-time analysis** at 30+ FPS is possible on tiny hardware\n",
    "5. **Structured intelligence** provides actionable data, not just images\n",
    "\n",
    "### ğŸŒŸ The Technology Revolution\n",
    "\n",
    "You've just used the **same core technology** that powers:\n",
    "- **Self-driving cars** (Tesla, Waymo)\n",
    "- **Smart security systems** (Ring, Nest)\n",
    "- **Industrial automation** (factory quality control)\n",
    "- **Healthcare monitoring** (patient safety systems)\n",
    "- **Retail innovation** (checkout-free stores)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸš€ Ready for Level 2?\n",
    "\n",
    "**You've completed Level 1!** ğŸ‰ You now understand:\n",
    "- What makes cameras \"intelligent\"\n",
    "- How AI processing works on the IMX500\n",
    "- The dramatic difference between passive and active vision\n",
    "- The foundation of modern computer vision systems\n",
    "\n",
    "### ğŸ“š Your Next Adventure\n",
    "\n",
    "**Level 2: First AI Detection** awaits!\n",
    "- Learn to interpret confidence scores and reliability\n",
    "- Conduct systematic experiments with AI detection\n",
    "- Master all 80+ detectable object types\n",
    "- Optimize AI performance for different scenarios\n",
    "\n",
    "### ğŸ¯ Ready to Dive Deeper?\n",
    "\n",
    "**Navigate to**: `../02_First_AI_Detection/Basic_Object_Detection.ipynb`\n",
    "\n",
    "**You're now ready to become an AI practitioner!**\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ’¡ What's Next in Your Journey\n",
    "\n",
    "```\n",
    "ğŸ Level 1: Getting Started          â† YOU ARE HERE! âœ…\n",
    "ğŸ§  Level 2: First AI Detection       â† NEXT: Real-time object recognition\n",
    "ğŸ”Š Level 3: Interactive AI           â† Hardware integration & alerts  \n",
    "ğŸš— Level 4: Smart Integration        â† Multi-sensor fusion systems\n",
    "ğŸ† Level 5: Real World Projects      â† Complete AI applications\n",
    "```\n",
    "\n",
    "**The foundation is set - now let's build amazing AI systems!** ğŸ¤–âœ¨"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",\n",
   "language": "python",\n",
   "name": "python3"\n",
  },\n  "language_info": {\n",
   "codemirror_mode": {\n",
    "name": "ipython",\n",
    "version": 3\n",
   },\n",
   "file_extension": ".py",\n",
   "mimetype": "text/x-python",\n",
   "name": "python",\n",
   "nbconvert_exporter": "python",\n",
   "pygments_lexer": "ipython3",\n",
   "version": "3.9.2"\n",
  }\n",
 },\n",
 "nbformat": 4,\n",
 "nbformat_minor": 4\n",
}