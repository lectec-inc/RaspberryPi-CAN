{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ§ª Detection Experiments: Testing AI Limits & Capabilities\n",
    "\n",
    "**Time to be a scientist!** ğŸ”¬ Let's systematically test what affects AI detection and discover the boundaries of what's possible.\n",
    "\n",
    "## ğŸ¯ What You'll Discover\n",
    "- How distance affects detection accuracy\n",
    "- The impact of lighting conditions\n",
    "- Object orientation and angle effects\n",
    "- Size limitations and optimal conditions\n",
    "- Environmental factors that help or hurt AI\n",
    "\n",
    "## ğŸ”¬ Scientific Method Applied to AI\n",
    "We'll use **controlled experiments** to understand AI behavior:\n",
    "1. **Hypothesis**: Make a prediction\n",
    "2. **Test**: Try it with the camera\n",
    "3. **Observe**: Record what happens\n",
    "4. **Analyze**: Understand why\n",
    "5. **Apply**: Use knowledge for better AI\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ Experiment Setup\n",
    "\n",
    "Let's prepare our experimental environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import cv2\n",
    "import numpy as np\n",
    "from IPython.display import display, clear_output, Image, HTML\n",
    "import ipywidgets as widgets\n",
    "import threading\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "# Experiment tracking variables\n",
    "experiment_results = []\n",
    "current_experiment = None\n",
    "\n",
    "print(\"ğŸ§ª AI DETECTION EXPERIMENT LAB\")\n",
    "print(\"=\" * 35)\n",
    "print(\"\\nğŸ”¬ Welcome, AI Researcher!\")\n",
    "print(\"\\nğŸ“‹ Available Experiments:\")\n",
    "print(\"   1. ğŸ“ Distance Testing\")\n",
    "print(\"   2. ğŸ’¡ Lighting Conditions\")\n",
    "print(\"   3. ğŸ”„ Object Orientation\")\n",
    "print(\"   4. ğŸ“ Size & Scale Effects\")\n",
    "print(\"   5. ğŸŒ«ï¸ Environmental Challenges\")\n",
    "print(\"   6. âš¡ Performance Optimization\")\n",
    "\n",
    "# Setup experiment controls\n",
    "experiment_selector = widgets.Dropdown(\n",
    "    options=[\n",
    "        ('ğŸ“ Distance Testing', 'distance'),\n",
    "        ('ğŸ’¡ Lighting Conditions', 'lighting'),\n",
    "        ('ğŸ”„ Object Orientation', 'orientation'),\n",
    "        ('ğŸ“ Size & Scale Effects', 'scale'),\n",
    "        ('ğŸŒ«ï¸ Environmental Challenges', 'environment'),\n",
    "        ('âš¡ Performance Optimization', 'performance')\n",
    "    ],\n",
    "    value='distance',\n",
    "    description='Experiment:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "start_experiment_btn = widgets.Button(\n",
    "    description='ğŸš€ Start Experiment',\n",
    "    button_style='success',\n",
    "    layout=widgets.Layout(width='150px', height='40px')\n",
    ")\n",
    "\n",
    "stop_experiment_btn = widgets.Button(\n",
    "    description='â¹ï¸ Stop',\n",
    "    button_style='danger',\n",
    "    layout=widgets.Layout(width='100px', height='40px')\n",
    ")\n",
    "\n",
    "experiment_output = widgets.Output()\n",
    "video_output = widgets.Output()\n",
    "\n",
    "display(widgets.VBox([\n",
    "    experiment_selector,\n",
    "    widgets.HBox([start_experiment_btn, stop_experiment_btn]),\n",
    "    experiment_output,\n",
    "    video_output\n",
    "]))\n",
    "\n",
    "print(\"\\nâœ… Experiment lab ready!\")\n",
    "print(\"\\nğŸ¯ Choose an experiment above and click 'Start Experiment'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment definitions and procedures\n",
    "EXPERIMENTS = {\n",
    "    'distance': {\n",
    "        'name': 'ğŸ“ Distance Testing Experiment',\n",
    "        'hypothesis': 'Objects closer to camera will have higher confidence scores',\n",
    "        'procedure': [\n",
    "            '1. Place object very close to camera (< 1 foot)',\n",
    "            '2. Slowly move object away from camera',\n",
    "            '3. Note confidence changes at different distances',\n",
    "            '4. Find maximum reliable detection distance'\n",
    "        ],\n",
    "        'what_to_observe': 'Confidence scores decreasing with distance',\n",
    "        'tips': 'Use a distinctive object like a coffee cup or book'\n",
    "    },\n",
    "    'lighting': {\n",
    "        'name': 'ğŸ’¡ Lighting Conditions Experiment',\n",
    "        'hypothesis': 'Better lighting improves detection accuracy and confidence',\n",
    "        'procedure': [\n",
    "            '1. Test in bright natural light',\n",
    "            '2. Test in dim indoor lighting',\n",
    "            '3. Test with artificial light sources',\n",
    "            '4. Test in shadows or backlighting'\n",
    "        ],\n",
    "        'what_to_observe': 'How confidence scores change with light levels',\n",
    "        'tips': 'Try positioning lamp or moving near window'\n",
    "    },\n",
    "    'orientation': {\n",
    "        'name': 'ğŸ”„ Object Orientation Experiment',\n",
    "        'hypothesis': 'Objects shown from typical viewing angles detect better',\n",
    "        'procedure': [\n",
    "            '1. Show object from normal viewing angle',\n",
    "            '2. Rotate object 90 degrees',\n",
    "            '3. Show object upside down',\n",
    "            '4. Show object from unusual angles'\n",
    "        ],\n",
    "        'what_to_observe': 'Which orientations give highest confidence',\n",
    "        'tips': 'Books, phones, and cups work great for this test'\n",
    "    },\n",
    "    'scale': {\n",
    "        'name': 'ğŸ“ Size & Scale Effects Experiment',\n",
    "        'hypothesis': 'Medium-sized objects in frame detect better than very large or tiny ones',\n",
    "        'procedure': [\n",
    "            '1. Fill entire frame with object (very close)',\n",
    "            '2. Show object taking ~50% of frame',\n",
    "            '3. Show object taking ~25% of frame',\n",
    "            '4. Show object very small in frame'\n",
    "        ],\n",
    "        'what_to_observe': 'Optimal size for detection confidence',\n",
    "        'tips': 'Use zoom or distance to control apparent size'\n",
    "    },\n",
    "    'environment': {\n",
    "        'name': 'ğŸŒ«ï¸ Environmental Challenges Experiment',\n",
    "        'hypothesis': 'Cluttered backgrounds and occlusion reduce detection performance',\n",
    "        'procedure': [\n",
    "            '1. Test with clean, simple background',\n",
    "            '2. Test with cluttered background',\n",
    "            '3. Test with similar objects nearby',\n",
    "            '4. Test with partial occlusion (object partially hidden)'\n",
    "        ],\n",
    "        'what_to_observe': 'How background complexity affects detection',\n",
    "        'tips': 'Try placing object on desk vs. in cluttered area'\n",
    "    },\n",
    "    'performance': {\n",
    "        'name': 'âš¡ Performance Optimization Experiment',\n",
    "        'hypothesis': 'Lower resolution and framerate can maintain accuracy while improving stability',\n",
    "        'procedure': [\n",
    "            '1. Test at full resolution (1920x1080)',\n",
    "            '2. Test at medium resolution (1280x720)',\n",
    "            '3. Test at lower framerate (15fps vs 30fps)',\n",
    "            '4. Monitor CPU temperature during tests'\n",
    "        ],\n",
    "        'what_to_observe': 'Performance vs accuracy trade-offs',\n",
    "        'tips': 'Check system temperature: vcgencmd measure_temp'\n",
    "    }\n",
    "}\n",
    "\n",
    "def start_experiment(experiment_type):\n",
    "    \"\"\"Start the selected experiment\"\"\"\n",
    "    global current_experiment\n",
    "    current_experiment = experiment_type\n",
    "    \n",
    "    exp_info = EXPERIMENTS[experiment_type]\n",
    "    \n",
    "    with experiment_output:\n",
    "        clear_output(wait=True)\n",
    "        print(f\"ğŸ§ª {exp_info['name']}\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"\\nğŸ¯ HYPOTHESIS: {exp_info['hypothesis']}\")\n",
    "        print(f\"\\nğŸ“‹ PROCEDURE:\")\n",
    "        for step in exp_info['procedure']:\n",
    "            print(f\"   {step}\")\n",
    "        print(f\"\\nğŸ‘€ WHAT TO OBSERVE: {exp_info['what_to_observe']}\")\n",
    "        print(f\"\\nğŸ’¡ TIPS: {exp_info['tips']}\")\n",
    "        print(f\"\\nğŸš€ Experiment starting in 3 seconds...\")\n",
    "        print(f\"\\nğŸ“Š Watch for confidence score changes in the video feed below!\")\n",
    "    \n",
    "    # Start video feed after short delay\n",
    "    time.sleep(3)\n",
    "    start_detection_feed(experiment_type)\n",
    "\n",
    "def start_detection_feed(experiment_type):\n",
    "    \"\"\"Start AI detection video feed for experiments\"\"\"\n",
    "    \n",
    "    # Choose resolution based on experiment\n",
    "    if experiment_type == 'performance':\n",
    "        width, height, fps = \"1280\", \"720\", \"20\"  # Lower for performance testing\n",
    "    else:\n",
    "        width, height, fps = \"1920\", \"1080\", \"30\"  # Full quality for other tests\n",
    "    \n",
    "    # Clean up existing processes\n",
    "    for p in (\"rpicam-vid\", \"rpicam-still\"):\n",
    "        subprocess.run([\"pkill\", \"-9\", p], stderr=subprocess.DEVNULL)\n",
    "    \n",
    "    def run_detection():\n",
    "        cmd = [\n",
    "            \"rpicam-vid\",\n",
    "            \"--inline\",\n",
    "            \"-t\", \"0\",\n",
    "            \"--width\", width,\n",
    "            \"--height\", height,\n",
    "            \"--framerate\", fps,\n",
    "            \"--codec\", \"mjpeg\",\n",
    "            \"--post-process-file\", \"/usr/share/rpi-camera-assets/imx500_mobilenet_ssd.json\",\n",
    "            \"-o\", \"-\"\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            \n",
    "            data = b\"\"\n",
    "            frame_count = 0\n",
    "            start_time = time.time()\n",
    "            \n",
    "            display_handle = None\n",
    "            \n",
    "            while current_experiment == experiment_type:\n",
    "                chunk = proc.stdout.read(4096)\n",
    "                if not chunk:\n",
    "                    break\n",
    "                    \n",
    "                data += chunk\n",
    "                \n",
    "                start = data.find(b'\\xff\\xd8')\n",
    "                end = data.find(b'\\xff\\xd9')\n",
    "                \n",
    "                if start != -1 and end != -1:\n",
    "                    jpg_data = data[start:end+2]\n",
    "                    data = data[end+2:]\n",
    "                    \n",
    "                    try:\n",
    "                        frame = cv2.imdecode(np.frombuffer(jpg_data, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "                        if frame is not None:\n",
    "                            _, display_jpg = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 85])\n",
    "                            \n",
    "                            with video_output:\n",
    "                                if display_handle is None:\n",
    "                                    display_handle = display(Image(data=display_jpg.tobytes()), display_id=True)\n",
    "                                else:\n",
    "                                    display_handle.update(Image(data=display_jpg.tobytes()))\n",
    "                            \n",
    "                            frame_count += 1\n",
    "                            \n",
    "                            # Update experiment status every 60 frames\n",
    "                            if frame_count % 60 == 0:\n",
    "                                elapsed = time.time() - start_time\n",
    "                                fps_actual = frame_count / elapsed\n",
    "                                \n",
    "                                with experiment_output:\n",
    "                                    # Keep existing content, just update status\n",
    "                                    print(f\"\\nâ±ï¸ Experiment Status: Running for {elapsed:.0f}s at {fps_actual:.1f} FPS\")\n",
    "                                    if experiment_type == 'performance':\n",
    "                                        # Show CPU temp for performance experiments\n",
    "                                        try:\n",
    "                                            temp_result = subprocess.run(['vcgencmd', 'measure_temp'], \n",
    "                                                                       capture_output=True, text=True)\n",
    "                                            if temp_result.returncode == 0:\n",
    "                                                temp = temp_result.stdout.strip().split('=')[1]\n",
    "                                                print(f\"ğŸŒ¡ï¸ CPU Temperature: {temp}\")\n",
    "                                        except:\n",
    "                                            pass\n",
    "                    except:\n",
    "                        continue\n",
    "                \n",
    "                time.sleep(0.001)\n",
    "                \n",
    "        except Exception as e:\n",
    "            with experiment_output:\n",
    "                print(f\"\\nâŒ Experiment error: {str(e)}\")\n",
    "        finally:\n",
    "            try:\n",
    "                proc.terminate()\n",
    "                proc.wait(timeout=2)\n",
    "            except:\n",
    "                proc.kill()\n",
    "    \n",
    "    # Run detection in separate thread\n",
    "    detection_thread = threading.Thread(target=run_detection, daemon=True)\n",
    "    detection_thread.start()\n",
    "\n",
    "def stop_experiment():\n",
    "    \"\"\"Stop current experiment\"\"\"\n",
    "    global current_experiment\n",
    "    current_experiment = None\n",
    "    \n",
    "    # Kill camera processes\n",
    "    for p in (\"rpicam-vid\", \"rpicam-still\"):\n",
    "        subprocess.run([\"pkill\", \"-9\", p], stderr=subprocess.DEVNULL)\n",
    "    \n",
    "    with experiment_output:\n",
    "        print(\"\\nâ¹ï¸ Experiment stopped\")\n",
    "        print(\"\\nğŸ“ Don't forget to record your observations!\")\n",
    "        print(\"\\nğŸ”¬ Ready for next experiment or analysis\")\n",
    "    \n",
    "    with video_output:\n",
    "        clear_output(wait=True)\n",
    "\n",
    "# Connect button handlers\n",
    "def on_start_click(button):\n",
    "    start_experiment(experiment_selector.value)\n",
    "\n",
    "def on_stop_click(button):\n",
    "    stop_experiment()\n",
    "\n",
    "start_experiment_btn.on_click(on_start_click)\n",
    "stop_experiment_btn.on_click(on_stop_click)\n",
    "\n",
    "print(\"\\nâœ… Experiment controls ready!\")\n",
    "print(\"\\nğŸ¯ Select an experiment type and click 'Start Experiment' to begin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Experiment Results Recording & Analysis\n",
    "\n",
    "Use this section to record your observations and analyze patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment results recording system\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"ğŸ“Š EXPERIMENT RESULTS LAB\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Sample results from common experiments\n",
    "sample_results = {\n",
    "    \"ğŸ“ Distance Testing\": {\n",
    "        \"observations\": {\n",
    "            \"Very Close (< 1 foot)\": \"95-99% confidence, object may be cropped\",\n",
    "            \"Optimal Range (1-4 feet)\": \"85-95% confidence, best detection\",\n",
    "            \"Medium Distance (4-8 feet)\": \"70-85% confidence, still reliable\",\n",
    "            \"Far Distance (8+ feet)\": \"40-70% confidence, depends on object size\",\n",
    "            \"Very Far (15+ feet)\": \"<40% confidence, unreliable\"\n",
    "        },\n",
    "        \"key_findings\": [\n",
    "            \"Optimal detection range: 1-6 feet\",\n",
    "            \"Large objects detectable further than small ones\",\n",
    "            \"Confidence drops exponentially with distance\"\n",
    "        ]\n",
    "    },\n",
    "    \"ğŸ’¡ Lighting Conditions\": {\n",
    "        \"observations\": {\n",
    "            \"Bright Natural Light\": \"90-95% confidence, excellent accuracy\",\n",
    "            \"Good Indoor Lighting\": \"80-90% confidence, very good\",\n",
    "            \"Dim Indoor Light\": \"60-80% confidence, acceptable\",\n",
    "            \"Shadows/Backlighting\": \"40-60% confidence, challenging\",\n",
    "            \"Very Dark\": \"<40% confidence, unreliable\"\n",
    "        },\n",
    "        \"key_findings\": [\n",
    "            \"Natural light gives best results\",\n",
    "            \"Shadows significantly impact confidence\",\n",
    "            \"Even overhead light improves detection dramatically\"\n",
    "        ]\n",
    "    },\n",
    "    \"ğŸ”„ Object Orientation\": {\n",
    "        \"observations\": {\n",
    "            \"Normal Viewing Angle\": \"85-95% confidence\",\n",
    "            \"45Â° Rotation\": \"75-85% confidence\",\n",
    "            \"90Â° Rotation\": \"60-75% confidence\",\n",
    "            \"Upside Down\": \"50-70% confidence\",\n",
    "            \"Extreme Angles\": \"30-50% confidence\"\n",
    "        },\n",
    "        \"key_findings\": [\n",
    "            \"AI trained on typical viewing angles\",\n",
    "            \"Some objects more orientation-sensitive than others\",\n",
    "            \"Symmetrical objects less affected by rotation\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Display sample results\n",
    "for experiment, results in sample_results.items():\n",
    "    print(f\"\\nğŸ§ª {experiment}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    print(\"\\nğŸ“‹ Typical Observations:\")\n",
    "    for condition, result in results[\"observations\"].items():\n",
    "        print(f\"   â€¢ {condition}: {result}\")\n",
    "    \n",
    "    print(\"\\nğŸ¯ Key Findings:\")\n",
    "    for finding in results[\"key_findings\"]:\n",
    "        print(f\"   âœ“ {finding}\")\n",
    "\n",
    "print(\"\\n\\nğŸ“ YOUR EXPERIMENT NOTES:\")\n",
    "print(\"=\" * 30)\n",
    "print(\"Use the space below to record your own observations:\")\n",
    "\n",
    "# Create interactive note-taking area\n",
    "notes_area = widgets.Textarea(\n",
    "    value=\"Experiment: \\nDate: {}\\n\\nObservations:\\n- \\n- \\n- \\n\\nConclusions:\\n- \\n- \\n\\nNext steps: \\n\".format(datetime.now().strftime(\"%Y-%m-%d %H:%M\")),\n",
    "    placeholder='Record your experiment observations here...',\n",
    "    description='Lab Notes:',\n",
    "    layout=widgets.Layout(width='100%', height='200px'),\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "save_notes_btn = widgets.Button(\n",
    "    description='ğŸ’¾ Save Notes',\n",
    "    button_style='info',\n",
    "    layout=widgets.Layout(width='120px')\n",
    ")\n",
    "\n",
    "def save_notes(button):\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"/tmp/ai_experiment_notes_{timestamp}.txt\"\n",
    "    \n",
    "    try:\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(notes_area.value)\n",
    "        print(f\"âœ… Notes saved to {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error saving notes: {e}\")\n",
    "\n",
    "save_notes_btn.on_click(save_notes)\n",
    "\n",
    "display(widgets.VBox([notes_area, save_notes_btn]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Quick Experiment Challenges\n",
    "\n",
    "Try these focused challenges to test specific aspects of AI detection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ† AI DETECTION CHALLENGES\")\n",
    "print(\"=\" * 30)\n",
    "print(\"\\nğŸ® Complete these challenges to master AI detection:\")\n",
    "\n",
    "challenges = [\n",
    "    {\n",
    "        \"title\": \"ğŸ¯ The Confidence Hunter\",\n",
    "        \"task\": \"Find an object that consistently gives >95% confidence\",\n",
    "        \"difficulty\": \"Easy\",\n",
    "        \"tips\": \"Try well-lit, distinctive objects like phones or cups\",\n",
    "        \"success_criteria\": \"Achieve >95% confidence for 10+ seconds\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"ğŸ“ The Distance Master\",\n",
    "        \"task\": \"Find the maximum distance for reliable detection\",\n",
    "        \"difficulty\": \"Medium\",\n",
    "        \"tips\": \"Start close and slowly move away while watching confidence\",\n",
    "        \"success_criteria\": \"Determine max distance for >70% confidence\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"ğŸŒ™ The Shadow Detective\",\n",
    "        \"task\": \"Get good detection in challenging lighting\",\n",
    "        \"difficulty\": \"Medium\",\n",
    "        \"tips\": \"Try different light sources and angles\",\n",
    "        \"success_criteria\": \"Achieve >80% confidence in dim conditions\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"ğŸ”„ The Orientation Optimizer\",\n",
    "        \"task\": \"Find the best angle for tricky objects\",\n",
    "        \"difficulty\": \"Medium\",\n",
    "        \"tips\": \"Test books, remotes, or phones at different angles\",\n",
    "        \"success_criteria\": \"Compare confidence at 5+ different angles\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"ğŸƒ The Speed Demon\",\n",
    "        \"task\": \"Test detection on moving objects\",\n",
    "        \"difficulty\": \"Hard\",\n",
    "        \"tips\": \"Move objects at different speeds across the frame\",\n",
    "        \"success_criteria\": \"Track object successfully while in motion\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"ğŸ­ The Impostor Hunter\",\n",
    "        \"task\": \"Find objects that fool the AI\",\n",
    "        \"difficulty\": \"Hard\",\n",
    "        \"tips\": \"Try objects that look similar to COCO dataset items\",\n",
    "        \"success_criteria\": \"Find 3+ objects that get misidentified\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for i, challenge in enumerate(challenges, 1):\n",
    "    difficulty_emoji = {\n",
    "        \"Easy\": \"ğŸŸ¢\",\n",
    "        \"Medium\": \"ğŸŸ¡\", \n",
    "        \"Hard\": \"ğŸ”´\"\n",
    "    }[challenge[\"difficulty\"]]\n",
    "    \n",
    "    print(f\"\\n{i}. {challenge['title']} {difficulty_emoji}\")\n",
    "    print(f\"   ğŸ“‹ Task: {challenge['task']}\")\n",
    "    print(f\"   ğŸ’¡ Tips: {challenge['tips']}\")\n",
    "    print(f\"   âœ… Success: {challenge['success_criteria']}\")\n",
    "\n",
    "print(\"\\n\\nğŸ… CHALLENGE TRACKING:\")\n",
    "print(\"-\" * 20)\n",
    "print(\"Mark your completed challenges:\")\n",
    "print(\"â–¡ Confidence Hunter\")\n",
    "print(\"â–¡ Distance Master\")\n",
    "print(\"â–¡ Shadow Detective\")\n",
    "print(\"â–¡ Orientation Optimizer\")\n",
    "print(\"â–¡ Speed Demon\")\n",
    "print(\"â–¡ Impostor Hunter\")\n",
    "\n",
    "print(\"\\nğŸ‰ Complete all 6 challenges to become an AI Detection Expert!\")\n",
    "print(\"\\nğŸ’ª Pro Tip: Document your results in the notes section above!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ Performance Analysis & Optimization Tips\n",
    "\n",
    "Learn how to optimize AI performance for different scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"âš¡ AI PERFORMANCE OPTIMIZATION GUIDE\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "print(\"\\nğŸ¯ OPTIMIZATION STRATEGIES:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "optimization_tips = {\n",
    "    \"ğŸ–¥ï¸ For Pi Zero 2W\": {\n",
    "        \"resolution\": \"Use 1280x720 for complex applications\",\n",
    "        \"framerate\": \"20fps is sufficient for most uses\",\n",
    "        \"cooling\": \"Add passive heatsink for sustained operation\",\n",
    "        \"os\": \"Use Pi OS Lite (64-bit) - no desktop\"\n",
    "    },\n",
    "    \"ğŸ“Š For Accuracy\": {\n",
    "        \"lighting\": \"Ensure good, even lighting\",\n",
    "        \"distance\": \"Keep objects 1-6 feet from camera\",\n",
    "        \"background\": \"Use simple, uncluttered backgrounds\",\n",
    "        \"stability\": \"Mount camera to reduce motion blur\"\n",
    "    },\n",
    "    \"âš¡ For Speed\": {\n",
    "        \"resolution\": \"Lower resolution = faster processing\",\n",
    "        \"roi\": \"Focus on specific region of interest\",\n",
    "        \"threshold\": \"Higher confidence threshold = fewer detections to process\",\n",
    "        \"objects\": \"Filter to only objects you care about\"\n",
    "    },\n",
    "    \"ğŸ”‹ For Battery Life\": {\n",
    "        \"framerate\": \"Reduce to 10-15fps for battery applications\",\n",
    "        \"resolution\": \"640x480 can be sufficient for basic detection\",\n",
    "        \"sleep\": \"Use detection intervals instead of continuous\",\n",
    "        \"gpio\": \"Power down unnecessary peripherals\"\n",
    "    }\n",
    "}\n",
    "\n",
    "for category, tips in optimization_tips.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for aspect, tip in tips.items():\n",
    "        print(f\"   â€¢ {aspect.title()}: {tip}\")\n",
    "\n",
    "print(\"\\n\\nğŸŒ¡ï¸ THERMAL MANAGEMENT:\")\n",
    "print(\"-\" * 25)\n",
    "print(\"Monitor CPU temperature to prevent throttling:\")\n",
    "print(\"\")\n",
    "print(\"# Check current temperature\")\n",
    "print(\"vcgencmd measure_temp\")\n",
    "print(\"\")\n",
    "print(\"# Temperature guidelines:\")\n",
    "print(\"â€¢ <60Â°C: Excellent\")\n",
    "print(\"â€¢ 60-70Â°C: Good\")\n",
    "print(\"â€¢ 70-80Â°C: Monitor closely\")\n",
    "print(\"â€¢ >80Â°C: Add cooling or reduce load\")\n",
    "\n",
    "print(\"\\n\\nğŸ“Š PERFORMANCE METRICS TO TRACK:\")\n",
    "print(\"-\" * 35)\n",
    "metrics = [\n",
    "    \"ğŸ–¼ï¸ Actual FPS achieved\",\n",
    "    \"ğŸŒ¡ï¸ CPU temperature\",\n",
    "    \"ğŸ“Š Average confidence scores\",\n",
    "    \"â±ï¸ Detection latency\",\n",
    "    \"ğŸ¯ Detection accuracy rate\",\n",
    "    \"ğŸ’¾ Memory usage\"\n",
    "]\n",
    "\n",
    "for metric in metrics:\n",
    "    print(f\"   {metric}\")\n",
    "\n",
    "print(\"\\n\\nğŸ”§ QUICK PERFORMANCE CHECK:\")\n",
    "print(\"-\" * 30)\n",
    "try:\n",
    "    # Check CPU temperature\n",
    "    temp_result = subprocess.run(['vcgencmd', 'measure_temp'], capture_output=True, text=True)\n",
    "    if temp_result.returncode == 0:\n",
    "        temp = temp_result.stdout.strip()\n",
    "        print(f\"ğŸŒ¡ï¸ Current CPU Temperature: {temp}\")\n",
    "        \n",
    "        temp_val = float(temp.split('=')[1].replace(\"'C\", \"\"))\n",
    "        if temp_val < 60:\n",
    "            print(\"   âœ… Excellent - No thermal concerns\")\n",
    "        elif temp_val < 70:\n",
    "            print(\"   ğŸŸ¡ Good - Normal operating temperature\")\n",
    "        elif temp_val < 80:\n",
    "            print(\"   ğŸŸ  Warm - Monitor during extended use\")\n",
    "        else:\n",
    "            print(\"   ğŸ”´ Hot - Consider adding cooling or reducing load\")\n",
    "    else:\n",
    "        print(\"âŒ Unable to read CPU temperature\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Temperature check failed: {e}\")\n",
    "\n",
    "# Check available memory\n",
    "try:\n",
    "    mem_result = subprocess.run(['free', '-h'], capture_output=True, text=True)\n",
    "    if mem_result.returncode == 0:\n",
    "        mem_lines = mem_result.stdout.strip().split('\\n')\n",
    "        if len(mem_lines) >= 2:\n",
    "            mem_info = mem_lines[1].split()\n",
    "            print(f\"ğŸ’¾ Memory: {mem_info[2]} used / {mem_info[1]} total\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Memory check failed: {e}\")\n",
    "\n",
    "print(\"\\nğŸ¯ Remember: Optimization is about finding the right balance for YOUR specific use case!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ‰ Experiment Conclusions\n",
    "\n",
    "Congratulations on completing your AI detection experiments! Let's summarize what you've learned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“ EXPERIMENT CONCLUSIONS & KEY LEARNINGS\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "key_discoveries = {\n",
    "    \"ğŸ” Detection Fundamentals\": [\n",
    "        \"AI confidence varies dramatically with conditions\",\n",
    "        \"Distance, lighting, and orientation all matter\",\n",
    "        \"Optimal detection zone: 1-6 feet with good lighting\",\n",
    "        \"Background complexity affects detection reliability\"\n",
    "    ],\n",
    "    \"âš¡ Performance Insights\": [\n",
    "        \"IMX500 does AI processing, Pi CPU stays cool\",\n",
    "        \"Resolution and framerate can be tuned for application\",\n",
    "        \"Pi Zero 2W can handle 30fps at 1080p for simple scenes\",\n",
    "        \"Thermal management important for sustained operation\"\n",
    "    ],\n",
    "    \"ğŸ¯ Practical Applications\": [\n",
    "        \"Choose confidence threshold based on use case\",\n",
    "        \"Environmental factors must be considered in design\",\n",
    "        \"Testing and validation essential for reliability\",\n",
    "        \"Optimization requires balancing multiple factors\"\n",
    "    ],\n",
    "    \"ğŸ§  AI Understanding\": [\n",
    "        \"AI has predictable strengths and limitations\",\n",
    "        \"Training data affects what AI can detect well\",\n",
    "        \"Confidence scores provide valuable reliability information\",\n",
    "        \"Real-world performance differs from lab conditions\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "for category, learnings in key_discoveries.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for learning in learnings:\n",
    "        print(f\"   âœ“ {learning}\")\n",
    "\n",
    "print(\"\\n\\nğŸš€ NEXT STEPS IN YOUR AI JOURNEY:\")\n",
    "print(\"-\" * 35)\n",
    "next_steps = [\n",
    "    \"ğŸ“š Study Object Types Guide to understand all 80+ detectable objects\",\n",
    "    \"ğŸ”Š Move to Level 3: Interactive AI with GPIO and buzzer alerts\",\n",
    "    \"ğŸš— Explore Level 4: Integration with VESC motor data\",\n",
    "    \"ğŸ—ï¸ Design Level 5: Your own real-world AI application\",\n",
    "    \"ğŸ”¬ Continue experimenting with different objects and scenarios\",\n",
    "    \"ğŸ“Š Practice choosing appropriate confidence thresholds\"\n",
    "]\n",
    "\n",
    "for step in next_steps:\n",
    "    print(f\"   {step}\")\n",
    "\n",
    "print(\"\\n\\nğŸ† EXPERIMENT MASTER ACHIEVEMENT UNLOCKED!\")\n",
    "print(\"=\" * 45)\n",
    "print(\"You now have hands-on experience with:\")\n",
    "print(\"   ğŸ”¬ Scientific method applied to AI\")\n",
    "print(\"   ğŸ“Š Systematic performance analysis\")\n",
    "print(\"   ğŸ¯ Optimization for real-world conditions\")\n",
    "print(\"   ğŸ§  Deep understanding of AI behavior\")\n",
    "\n",
    "print(\"\\nğŸ“ You're ready to build reliable AI applications!\")\n",
    "print(\"\\nğŸ’¡ Pro Tip: Keep experimenting! Every new scenario teaches you something about AI behavior.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ What's Next?\n",
    "\n",
    "Amazing work completing these detection experiments! You now have a **scientific understanding** of AI behavior.\n",
    "\n",
    "### ğŸ“š Continue Your AI Journey:\n",
    "\n",
    "**Next Notebook**: `Object_Types_Guide.ipynb`\n",
    "- Complete reference to all 80+ detectable objects\n",
    "- Tips for detecting specific object categories\n",
    "- Understanding the COCO dataset\n",
    "\n",
    "**Ready for Level 3?**: `../03_Interactive_AI/AI_with_Buzzer_Alerts.ipynb`\n",
    "- Make AI respond to the world with sound and GPIO!\n",
    "- Build your first interactive AI system\n",
    "- Learn hardware integration patterns\n",
    "\n",
    "### ğŸ¯ Key Achievements Unlocked\n",
    "\n",
    "âœ… **Scientific AI Analysis**: You can systematically test AI performance\n",
    "\n",
    "âœ… **Performance Optimization**: You understand the trade-offs and tuning parameters\n",
    "\n",
    "âœ… **Real-World Readiness**: You know how environmental factors affect AI\n",
    "\n",
    "âœ… **Reliability Assessment**: You can evaluate when AI results are trustworthy\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§  You're Now an AI Experimentalist!\n",
    "\n",
    "You have the skills to **test**, **validate**, and **optimize** AI systems for real-world deployment. This experimental mindset will serve you well as you build increasingly sophisticated AI applications! ğŸ¤–ğŸ”¬âœ¨"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}