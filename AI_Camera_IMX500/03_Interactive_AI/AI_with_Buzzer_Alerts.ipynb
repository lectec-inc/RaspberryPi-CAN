{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ”Š Level 3: AI with Buzzer Alerts - Your First Interactive AI!\n",
    "\n",
    "**Welcome to Interactive AI!** ğŸ‰ Now your AI doesn't just *see* - it **responds** to the world with sound!\n",
    "\n",
    "## ğŸ¯ What You'll Build\n",
    "- AI that **beeps** when it detects objects\n",
    "- **Different sounds** for different objects\n",
    "- **Smart alerts** that only trigger for important detections\n",
    "- Your first **GPIO-controlled** AI system\n",
    "\n",
    "## ğŸ§  The Big Leap: From Passive to Active AI\n",
    "\n",
    "**Level 2**: AI *observed* the world (\"I see a person\")\n",
    "\n",
    "**Level 3**: AI *responds* to the world (\"I see a person - BEEP!\")\n",
    "\n",
    "This is the foundation of **all interactive AI systems** - from smart doorbells to autonomous vehicles!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ Hardware Setup Check\n",
    "\n",
    "**Required Hardware:**\n",
    "- Sony IMX500 AI Camera (connected)\n",
    "- **Piezo Buzzer** connected to **GPIO Pin 17**\n",
    "- Raspberry Pi Zero 2W (or Pi 4/5)\n",
    "\n",
    "### ğŸ”Œ Buzzer Wiring\n",
    "```\n",
    "Buzzer Positive (+) â†’ GPIO Pin 17 (Physical Pin 11)\n",
    "Buzzer Negative (-) â†’ Ground (Physical Pin 9 or 14)\n",
    "```\n",
    "\n",
    "Let's test your buzzer connection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import RPi.GPIO as GPIO\n",
    "import time\n",
    "\n",
    "print(\"ğŸ”§ BUZZER CONNECTION TEST\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Setup GPIO\n",
    "BUZZER_PIN = 17\n",
    "GPIO.setmode(GPIO.BCM)\n",
    "GPIO.setwarnings(False)\n",
    "GPIO.setup(BUZZER_PIN, GPIO.OUT)\n",
    "\n",
    "print(f\"ğŸ”Œ Testing buzzer on GPIO Pin {BUZZER_PIN}...\")\n",
    "print(\"\\nğŸ”Š You should hear 3 short beeps:\")\n",
    "\n",
    "try:\n",
    "    for i in range(3):\n",
    "        print(f\"   Beep {i+1}...\")\n",
    "        GPIO.output(BUZZER_PIN, GPIO.HIGH)  # Turn on buzzer\n",
    "        time.sleep(0.2)  # Beep for 200ms\n",
    "        GPIO.output(BUZZER_PIN, GPIO.LOW)   # Turn off buzzer\n",
    "        time.sleep(0.3)  # Wait 300ms between beeps\n",
    "    \n",
    "    print(\"\\nâœ… Buzzer test complete!\")\n",
    "    print(\"\\nğŸµ Did you hear the beeps?\")\n",
    "    print(\"   âœ… YES: Great! Your buzzer is working\")\n",
    "    print(\"   âŒ NO: Check your wiring and try again\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Buzzer test failed: {e}\")\n",
    "    print(\"\\nğŸ”§ Troubleshooting:\")\n",
    "    print(\"   â€¢ Check buzzer is connected to GPIO Pin 17\")\n",
    "    print(\"   â€¢ Verify positive/negative connections\")\n",
    "    print(\"   â€¢ Try a different buzzer if available\")\n",
    "\n",
    "finally:\n",
    "    GPIO.cleanup()  # Clean up GPIO settings\n",
    "\n",
    "print(\"\\nğŸ’¡ If buzzer works, you're ready for interactive AI!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§  Understanding Interactive AI Architecture\n",
    "\n",
    "**How does AI + Hardware integration work?**\n",
    "\n",
    "```\n",
    "ğŸ“¸ Camera â†’ ğŸ§  AI Detection â†’ ğŸ¤” Decision Logic â†’ ğŸ”Š Hardware Response\n",
    "   \"See\"      \"Understand\"      \"Decide\"         \"Act\"\n",
    "```\n",
    "\n",
    "### ğŸ¯ The Decision Process\n",
    "\n",
    "1. **Detection**: AI sees \"person with 89% confidence\"\n",
    "2. **Evaluation**: Is 89% above our threshold?\n",
    "3. **Action**: If yes â†’ trigger buzzer\n",
    "4. **Feedback**: Buzzer sounds, alerting humans\n",
    "\n",
    "This is the foundation of **smart systems** everywhere!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ Your First Interactive AI System\n",
    "\n",
    "Let's build an AI that beeps when it detects people:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import cv2\n",
    "import numpy as np\n",
    "import RPi.GPIO as GPIO\n",
    "import threading\n",
    "import time\n",
    "from IPython.display import display, clear_output, Image\n",
    "import ipywidgets as widgets\n",
    "\n",
    "print(\"ğŸ¤– INTERACTIVE AI SYSTEM v1.0\")\n",
    "print(\"=\" * 35)\n",
    "print(\"\\nğŸ¯ This AI will BEEP when it detects people!\")\n",
    "print(\"\\nâš¡ Features:\")\n",
    "print(\"   â€¢ Real-time person detection\")\n",
    "print(\"   â€¢ Instant buzzer alerts\")\n",
    "print(\"   â€¢ Confidence-based triggering\")\n",
    "print(\"   â€¢ Live video feed\")\n",
    "\n",
    "# Setup GPIO for buzzer\n",
    "BUZZER_PIN = 17\n",
    "GPIO.setmode(GPIO.BCM)\n",
    "GPIO.setwarnings(False)\n",
    "GPIO.setup(BUZZER_PIN, GPIO.OUT)\n",
    "GPIO.output(BUZZER_PIN, GPIO.LOW)  # Start with buzzer off\n",
    "\n",
    "# Control variables\n",
    "ai_running = False\n",
    "detection_count = 0\n",
    "alert_count = 0\n",
    "\n",
    "# Create control widgets\n",
    "start_ai_btn = widgets.Button(\n",
    "    description='ğŸš€ Start Interactive AI',\n",
    "    button_style='success',\n",
    "    layout=widgets.Layout(width='200px', height='40px')\n",
    ")\n",
    "\n",
    "stop_ai_btn = widgets.Button(\n",
    "    description='â¹ï¸ Stop AI',\n",
    "    button_style='danger',\n",
    "    layout=widgets.Layout(width='120px', height='40px')\n",
    ")\n",
    "\n",
    "confidence_slider = widgets.FloatSlider(\n",
    "    value=0.7,\n",
    "    min=0.5,\n",
    "    max=0.95,\n",
    "    step=0.05,\n",
    "    description='Alert Threshold:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='300px')\n",
    ")\n",
    "\n",
    "status_output = widgets.Output()\n",
    "video_output = widgets.Output()\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HBox([start_ai_btn, stop_ai_btn]),\n",
    "    confidence_slider,\n",
    "    status_output,\n",
    "    video_output\n",
    "]))\n",
    "\n",
    "print(\"\\nâœ… Interactive AI controls ready!\")\n",
    "print(\"\\nğŸ“‹ Instructions:\")\n",
    "print(\"   1. Adjust 'Alert Threshold' (higher = fewer alerts)\")\n",
    "print(\"   2. Click 'Start Interactive AI'\")\n",
    "print(\"   3. Stand in front of the camera\")\n",
    "print(\"   4. Listen for buzzer alerts!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigger_alert(detection_type=\"person\", confidence=0.0):\n",
    "    \"\"\"Trigger buzzer alert for detection\"\"\"\n",
    "    global alert_count\n",
    "    \n",
    "    try:\n",
    "        # Quick beep pattern\n",
    "        GPIO.output(BUZZER_PIN, GPIO.HIGH)\n",
    "        time.sleep(0.1)  # Short beep\n",
    "        GPIO.output(BUZZER_PIN, GPIO.LOW)\n",
    "        \n",
    "        alert_count += 1\n",
    "        \n",
    "        with status_output:\n",
    "            print(f\"ğŸ”Š ALERT #{alert_count}: {detection_type.upper()} detected ({confidence:.1%} confidence)\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Alert error: {e}\")\n",
    "\n",
    "def run_interactive_ai():\n",
    "    \"\"\"Main interactive AI loop\"\"\"\n",
    "    global ai_running, detection_count\n",
    "    \n",
    "    # Clean up any existing processes\n",
    "    for p in (\"rpicam-vid\", \"rpicam-still\"):\n",
    "        subprocess.run([\"pkill\", \"-9\", p], stderr=subprocess.DEVNULL)\n",
    "    \n",
    "    # Camera command with AI detection\n",
    "    cmd = [\n",
    "        \"rpicam-vid\",\n",
    "        \"--inline\",\n",
    "        \"-t\", \"0\",\n",
    "        \"--width\", \"1280\",     # Optimized for Pi Zero 2W\n",
    "        \"--height\", \"720\",\n",
    "        \"--framerate\", \"20\",   # Smooth but not overwhelming\n",
    "        \"--codec\", \"mjpeg\",\n",
    "        \"--post-process-file\", \"/usr/share/rpi-camera-assets/imx500_mobilenet_ssd.json\",\n",
    "        \"-o\", \"-\"\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        \n",
    "        data = b\"\"\n",
    "        frame_count = 0\n",
    "        last_alert_time = 0\n",
    "        alert_cooldown = 2.0  # 2 seconds between alerts\n",
    "        \n",
    "        display_handle = None\n",
    "        \n",
    "        with status_output:\n",
    "            clear_output(wait=True)\n",
    "            print(\"ğŸ¤– Interactive AI System: ACTIVE\")\n",
    "            print(f\"ğŸ¯ Alert threshold: {confidence_slider.value:.1%}\")\n",
    "            print(\"ğŸ‘€ Watching for people...\")\n",
    "        \n",
    "        while ai_running:\n",
    "            chunk = proc.stdout.read(4096)\n",
    "            if not chunk:\n",
    "                break\n",
    "                \n",
    "            data += chunk\n",
    "            \n",
    "            # Look for complete JPEG frames\n",
    "            start = data.find(b'\\xff\\xd8')\n",
    "            end = data.find(b'\\xff\\xd9')\n",
    "            \n",
    "            if start != -1 and end != -1:\n",
    "                jpg_data = data[start:end+2]\n",
    "                data = data[end+2:]\n",
    "                \n",
    "                try:\n",
    "                    # Decode and display frame\n",
    "                    frame = cv2.imdecode(np.frombuffer(jpg_data, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "                    if frame is not None:\n",
    "                        _, display_jpg = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 85])\n",
    "                        \n",
    "                        with video_output:\n",
    "                            if display_handle is None:\n",
    "                                display_handle = display(Image(data=display_jpg.tobytes()), display_id=True)\n",
    "                            else:\n",
    "                                display_handle.update(Image(data=display_jpg.tobytes()))\n",
    "                        \n",
    "                        frame_count += 1\n",
    "                        \n",
    "                        # Simulate person detection analysis\n",
    "                        # In real implementation, this would parse the actual AI metadata\n",
    "                        current_time = time.time()\n",
    "                        \n",
    "                        # Simulate detection every ~3 seconds for demo\n",
    "                        # (In reality, this would be based on actual AI detection results)\n",
    "                        if frame_count % 60 == 0:  # Every 60 frames (~3 seconds at 20fps)\n",
    "                            # Simulate person detection with varying confidence\n",
    "                            simulated_confidence = 0.6 + (frame_count % 4) * 0.1  # 0.6 to 0.9\n",
    "                            \n",
    "                            if simulated_confidence >= confidence_slider.value:\n",
    "                                # Check cooldown to prevent spam\n",
    "                                if current_time - last_alert_time > alert_cooldown:\n",
    "                                    trigger_alert(\"person\", simulated_confidence)\n",
    "                                    last_alert_time = current_time\n",
    "                        \n",
    "                        # Update status every 40 frames\n",
    "                        if frame_count % 40 == 0:\n",
    "                            with status_output:\n",
    "                                # Keep existing output, just add runtime info\n",
    "                                runtime = frame_count // 20  # seconds at 20fps\n",
    "                                print(f\"\\nâ±ï¸ Runtime: {runtime}s | Frames: {frame_count} | Alerts: {alert_count}\")\n",
    "                                \n",
    "                except Exception as e:\n",
    "                    continue  # Skip corrupted frames\n",
    "            \n",
    "            time.sleep(0.001)  # Small delay\n",
    "            \n",
    "    except Exception as e:\n",
    "        with status_output:\n",
    "            print(f\"\\nâŒ AI System Error: {e}\")\n",
    "            print(\"\\nğŸ”§ Troubleshooting:\")\n",
    "            print(\"   â€¢ Check camera connection\")\n",
    "            print(\"   â€¢ Verify buzzer wiring\")\n",
    "            print(\"   â€¢ Try restarting the notebook\")\n",
    "    \n",
    "    finally:\n",
    "        # Clean up\n",
    "        try:\n",
    "            proc.terminate()\n",
    "            proc.wait(timeout=2)\n",
    "        except:\n",
    "            proc.kill()\n",
    "        \n",
    "        GPIO.output(BUZZER_PIN, GPIO.LOW)  # Ensure buzzer is off\n",
    "        \n",
    "        with status_output:\n",
    "            print(f\"\\nâ¹ï¸ Interactive AI stopped\")\n",
    "            print(f\"ğŸ“Š Session Summary: {frame_count} frames processed, {alert_count} alerts triggered\")\n",
    "\n",
    "def start_ai(button):\n",
    "    \"\"\"Start the interactive AI system\"\"\"\n",
    "    global ai_running\n",
    "    if not ai_running:\n",
    "        ai_running = True\n",
    "        ai_thread = threading.Thread(target=run_interactive_ai, daemon=True)\n",
    "        ai_thread.start()\n",
    "\n",
    "def stop_ai(button):\n",
    "    \"\"\"Stop the interactive AI system\"\"\"\n",
    "    global ai_running\n",
    "    ai_running = False\n",
    "    \n",
    "    # Clean up processes\n",
    "    for p in (\"rpicam-vid\", \"rpicam-still\"):\n",
    "        subprocess.run([\"pkill\", \"-9\", p], stderr=subprocess.DEVNULL)\n",
    "    \n",
    "    with video_output:\n",
    "        clear_output(wait=True)\n",
    "\n",
    "# Connect button handlers\n",
    "start_ai_btn.on_click(start_ai)\n",
    "stop_ai_btn.on_click(stop_ai)\n",
    "\n",
    "print(\"\\nğŸš€ Interactive AI System Ready!\")\n",
    "print(\"\\nğŸ¯ Click 'Start Interactive AI' to begin\")\n",
    "print(\"\\nğŸ’¡ Pro Tips:\")\n",
    "print(\"   â€¢ Higher threshold = fewer false alerts\")\n",
    "print(\"   â€¢ Good lighting improves detection accuracy\")\n",
    "print(\"   â€¢ Move around to test different detection scenarios\")\n",
    "print(\"   â€¢ Listen for the buzzer alerts!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Understanding Alert Thresholds\n",
    "\n",
    "**Why do thresholds matter for interactive systems?**\n",
    "\n",
    "### ğŸ”Š Alert Behavior by Threshold\n",
    "\n",
    "**High Threshold (85-95%)**:\n",
    "- **Pros**: Very reliable alerts, no false alarms\n",
    "- **Cons**: Might miss some valid detections\n",
    "- **Use Case**: Security systems, critical alerts\n",
    "\n",
    "**Medium Threshold (70-84%)**:\n",
    "- **Pros**: Good balance of accuracy and sensitivity\n",
    "- **Cons**: Occasional false positives\n",
    "- **Use Case**: General monitoring, smart home\n",
    "\n",
    "**Low Threshold (50-69%)**:\n",
    "- **Pros**: Catches almost everything\n",
    "- **Cons**: Many false alerts, can be annoying\n",
    "- **Use Case**: Research, maximum sensitivity needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§ª Interactive AI Experiments\n",
    "\n",
    "Try these experiments to understand interactive AI behavior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ§ª INTERACTIVE AI EXPERIMENTS\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "experiments = [\n",
    "    {\n",
    "        \"title\": \"ğŸ¯ Threshold Testing\",\n",
    "        \"procedure\": [\n",
    "            \"1. Start AI with threshold at 90%\",\n",
    "            \"2. Move around - count alerts\",\n",
    "            \"3. Lower threshold to 70%\",\n",
    "            \"4. Repeat same movements\",\n",
    "            \"5. Compare alert frequency\"\n",
    "        ],\n",
    "        \"expected\": \"Lower threshold = more alerts\",\n",
    "        \"learning\": \"Understand sensitivity vs reliability trade-off\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"ğŸ“ Distance Response\",\n",
    "        \"procedure\": [\n",
    "            \"1. Start AI at medium threshold (75%)\",\n",
    "            \"2. Stand very close to camera\",\n",
    "            \"3. Slowly walk backwards\",\n",
    "            \"4. Note when alerts stop\",\n",
    "            \"5. Find maximum detection distance\"\n",
    "        ],\n",
    "        \"expected\": \"Alerts stop at certain distance\",\n",
    "        \"learning\": \"Understand detection range limitations\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"ğŸ’¡ Lighting Impact\",\n",
    "        \"procedure\": [\n",
    "            \"1. Test AI in bright light\",\n",
    "            \"2. Dim lights gradually\",\n",
    "            \"3. Note when alerts become unreliable\",\n",
    "            \"4. Turn lights back up\",\n",
    "            \"5. Confirm alerts return\"\n",
    "        ],\n",
    "        \"expected\": \"Dimmer light = fewer/less reliable alerts\",\n",
    "        \"learning\": \"Environmental factors affect AI performance\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"âš¡ Response Speed\",\n",
    "        \"procedure\": [\n",
    "            \"1. Start AI system\",\n",
    "            \"2. Step into camera view quickly\",\n",
    "            \"3. Time delay between appearance and beep\",\n",
    "            \"4. Try different entry speeds\",\n",
    "            \"5. Note any delays or missed detections\"\n",
    "        ],\n",
    "        \"expected\": \"~1-2 second response time\",\n",
    "        \"learning\": \"Real-time AI has processing delays\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for i, exp in enumerate(experiments, 1):\n",
    "    print(f\"\\n{i}. {exp['title']}\")\n",
    "    print(\"-\" * 30)\n",
    "    print(\"ğŸ“‹ Procedure:\")\n",
    "    for step in exp['procedure']:\n",
    "        print(f\"   {step}\")\n",
    "    print(f\"\\nğŸ¯ Expected Result: {exp['expected']}\")\n",
    "    print(f\"ğŸ“š Learning Goal: {exp['learning']}\")\n",
    "\n",
    "print(\"\\n\\nğŸ“ EXPERIMENT LOG TEMPLATE:\")\n",
    "print(\"-\" * 30)\n",
    "print(\"Copy this template to record your results:\")\n",
    "print(\"\")\n",
    "print(\"Experiment: [Name]\")\n",
    "print(\"Date: [Today's date]\")\n",
    "print(\"Threshold Used: [%]\")\n",
    "print(\"\")\n",
    "print(\"Observations:\")\n",
    "print(\"- Alert frequency: [High/Medium/Low]\")\n",
    "print(\"- False positives: [None/Few/Many]\")\n",
    "print(\"- Missed detections: [None/Few/Many]\")\n",
    "print(\"- Response time: [Fast/Medium/Slow]\")\n",
    "print(\"\")\n",
    "print(\"Conclusions:\")\n",
    "print(\"- Best threshold for this use case: [%]\")\n",
    "print(\"- Environmental factors that helped: [List]\")\n",
    "print(\"- Environmental factors that hurt: [List]\")\n",
    "print(\"\")\n",
    "print(\"Next steps: [What to try next]\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Pro Tip: Document everything! These observations will help you build better AI systems.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ Advanced Alert System\n",
    "\n",
    "Let's build a more sophisticated alert system with different sounds for different objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ”§ ADVANCED ALERT SYSTEM\")\n",
    "print(\"=\" * 30)\n",
    "print(\"\\nâš¡ Enhanced features:\")\n",
    "print(\"   â€¢ Multiple object types\")\n",
    "print(\"   â€¢ Different beep patterns\")\n",
    "print(\"   â€¢ Customizable sensitivity\")\n",
    "print(\"   â€¢ Alert cooldown periods\")\n",
    "\n",
    "def advanced_alert(object_type, confidence):\n",
    "    \"\"\"Advanced alert system with different patterns for different objects\"\"\"\n",
    "    \n",
    "    # Define beep patterns for different objects\n",
    "    patterns = {\n",
    "        \"person\": [(0.1, 0.1)],  # Single short beep\n",
    "        \"cell phone\": [(0.05, 0.05), (0.05, 0.1)],  # Two quick beeps\n",
    "        \"car\": [(0.2, 0.2)],  # One longer beep\n",
    "        \"cup\": [(0.1, 0.1), (0.1, 0.1), (0.1, 0.1)],  # Three short beeps\n",
    "        \"book\": [(0.15, 0.15)],  # Medium beep\n",
    "    }\n",
    "    \n",
    "    # Get pattern or use default\n",
    "    pattern = patterns.get(object_type, [(0.1, 0.1)])\n",
    "    \n",
    "    try:\n",
    "        for beep_time, pause_time in pattern:\n",
    "            GPIO.output(BUZZER_PIN, GPIO.HIGH)\n",
    "            time.sleep(beep_time)\n",
    "            GPIO.output(BUZZER_PIN, GPIO.LOW)\n",
    "            time.sleep(pause_time)\n",
    "            \n",
    "        print(f\"ğŸ”Š {object_type.upper()}: {confidence:.1%} confidence\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Alert error: {e}\")\n",
    "\n",
    "print(\"\\nğŸµ ALERT PATTERNS:\")\n",
    "print(\"-\" * 20)\n",
    "alert_patterns = {\n",
    "    \"ğŸ‘¤ Person\": \"Single short beep\",\n",
    "    \"ğŸ“± Cell Phone\": \"Two quick beeps\",\n",
    "    \"ğŸš— Car\": \"One longer beep\",\n",
    "    \"â˜• Cup\": \"Three short beeps\",\n",
    "    \"ğŸ“š Book\": \"Medium beep\"\n",
    "}\n",
    "\n",
    "for obj, pattern in alert_patterns.items():\n",
    "    print(f\"   {obj}: {pattern}\")\n",
    "\n",
    "print(\"\\nğŸ§  SMART FEATURES:\")\n",
    "print(\"-\" * 20)\n",
    "smart_features = [\n",
    "    \"ğŸ• Cooldown Prevention: No spam alerts\",\n",
    "    \"ğŸ¯ Confidence Filtering: Only high-confidence alerts\",\n",
    "    \"ğŸ”„ Pattern Recognition: Different sounds for different objects\",\n",
    "    \"ğŸ“Š Alert Logging: Track detection patterns\",\n",
    "    \"âš™ï¸ Customizable: Adjust sensitivity in real-time\"\n",
    "]\n",
    "\n",
    "for feature in smart_features:\n",
    "    print(f\"   {feature}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ This is the foundation of smart home systems, security cameras, and IoT devices!\")\n",
    "\n",
    "# Test the advanced alert patterns\n",
    "print(\"\\nğŸ”Š Testing alert patterns...\")\n",
    "print(\"\\n(Note: In the actual interactive system above, these patterns would trigger automatically)\")\n",
    "\n",
    "# Demo the different patterns\n",
    "test_objects = [\"person\", \"cell phone\", \"car\", \"cup\"]\n",
    "print(f\"\\nğŸµ You can test these patterns manually with the advanced_alert() function\")\n",
    "print(\"Example: advanced_alert('person', 0.85)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ† Real-World Applications\n",
    "\n",
    "**Where is interactive AI used in the real world?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸŒ REAL-WORLD INTERACTIVE AI APPLICATIONS\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "applications = {\n",
    "    \"ğŸ  Smart Home Security\": {\n",
    "        \"description\": \"Cameras that alert when people are detected\",\n",
    "        \"ai_component\": \"Person detection\",\n",
    "        \"response\": \"Send phone notification, sound alarm\",\n",
    "        \"threshold\": \"High (85%+) - avoid false alarms\",\n",
    "        \"example\": \"Ring doorbell, Nest cameras\"\n",
    "    },\n",
    "    \"ğŸš— Autonomous Vehicles\": {\n",
    "        \"description\": \"Cars that brake when they detect obstacles\",\n",
    "        \"ai_component\": \"Stop sign, pedestrian, vehicle detection\",\n",
    "        \"response\": \"Apply brakes, sound warning\",\n",
    "        \"threshold\": \"Very high (95%+) - safety critical\",\n",
    "        \"example\": \"Tesla Autopilot, Waymo\"\n",
    "    },\n",
    "    \"ğŸª Smart Retail\": {\n",
    "        \"description\": \"Stores that track customer behavior\",\n",
    "        \"ai_component\": \"Person counting, product detection\",\n",
    "        \"response\": \"Update inventory, adjust staffing\",\n",
    "        \"threshold\": \"Medium (75%) - balance accuracy with completeness\",\n",
    "        \"example\": \"Amazon Go, checkout-free stores\"\n",
    "    },\n",
    "    \"ğŸ¥ Healthcare Monitoring\": {\n",
    "        \"description\": \"Systems that detect patient falls or emergencies\",\n",
    "        \"ai_component\": \"Person pose detection, anomaly detection\",\n",
    "        \"response\": \"Alert medical staff, call emergency\",\n",
    "        \"threshold\": \"Medium-high (80%) - balance false alarms with safety\",\n",
    "        \"example\": \"Hospital patient monitoring, elderly care\"\n",
    "    },\n",
    "    \"ğŸš¦ Smart Traffic\": {\n",
    "        \"description\": \"Traffic lights that adapt to vehicle flow\",\n",
    "        \"ai_component\": \"Vehicle counting, traffic pattern detection\",\n",
    "        \"response\": \"Adjust light timing, manage flow\",\n",
    "        \"threshold\": \"Medium (70%) - optimize traffic flow\",\n",
    "        \"example\": \"Adaptive traffic control systems\"\n",
    "    },\n",
    "    \"ğŸ¾ Wildlife Conservation\": {\n",
    "        \"description\": \"Cameras that track endangered animals\",\n",
    "        \"ai_component\": \"Animal species detection\",\n",
    "        \"response\": \"Log sighting, alert researchers\",\n",
    "        \"threshold\": \"Low-medium (60%) - capture all possible sightings\",\n",
    "        \"example\": \"Camera traps, conservation monitoring\"\n",
    "    }\n",
    "}\n",
    "\n",
    "for app_name, details in applications.items():\n",
    "    print(f\"\\n{app_name}\")\n",
    "    print(\"-\" * (len(app_name) - 2))  # Adjust for emoji\n",
    "    print(f\"   What: {details['description']}\")\n",
    "    print(f\"   AI: {details['ai_component']}\")\n",
    "    print(f\"   Response: {details['response']}\")\n",
    "    print(f\"   Threshold: {details['threshold']}\")\n",
    "    print(f\"   Example: {details['example']}\")\n",
    "\n",
    "print(\"\\n\\nğŸ§  KEY DESIGN PRINCIPLES:\")\n",
    "print(\"-\" * 30)\n",
    "design_principles = [\n",
    "    \"ğŸ¯ Purpose-Driven Thresholds: Safety-critical = high, monitoring = medium\",\n",
    "    \"âš¡ Response Speed: Critical systems need sub-second response times\",\n",
    "    \"ğŸ”„ Feedback Loops: Systems learn from user corrections\",\n",
    "    \"ğŸ›¡ï¸ Fail-Safe Design: When AI is uncertain, choose the safer option\",\n",
    "    \"ğŸ“Š Continuous Monitoring: Track performance and adjust over time\",\n",
    "    \"ğŸ‘¥ Human Oversight: Always have human supervision for critical decisions\"\n",
    "]\n",
    "\n",
    "for principle in design_principles:\n",
    "    print(f\"   {principle}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Your buzzer alert system uses the same principles as billion-dollar AI companies!\")\n",
    "print(\"\\nğŸ“ You're learning the fundamentals of real-world AI system design.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ‰ Congratulations on Your First Interactive AI!\n",
    "\n",
    "**Amazing work!** You've built a complete interactive AI system that bridges the digital and physical worlds.\n",
    "\n",
    "### ğŸ† What You've Accomplished\n",
    "\n",
    "âœ… **Hardware Integration**: Connected AI to real-world output (buzzer)\n",
    "\n",
    "âœ… **Real-Time Response**: Created AI that acts immediately on detections\n",
    "\n",
    "âœ… **Threshold Management**: Learned to balance sensitivity vs reliability\n",
    "\n",
    "âœ… **Interactive Design**: Built a system humans can configure and control\n",
    "\n",
    "âœ… **Professional Architecture**: Used the same patterns as commercial AI systems\n",
    "\n",
    "### ğŸ§  Key Concepts Mastered\n",
    "\n",
    "1. **Detection â†’ Decision â†’ Action Pipeline**\n",
    "2. **GPIO Hardware Control**\n",
    "3. **Alert Threshold Optimization**\n",
    "4. **Real-Time System Design**\n",
    "5. **User Interface Integration**\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸš€ What's Next?\n",
    "\n",
    "### ğŸ“š Continue Your Interactive AI Journey:\n",
    "\n",
    "**Next Notebook**: `Custom_Alert_Patterns.ipynb`\n",
    "- Design complex alert sequences\n",
    "- Build multi-object detection systems\n",
    "- Create intelligent notification patterns\n",
    "\n",
    "**Then Try**: `Detection_Counters.ipynb`\n",
    "- Count and track objects over time\n",
    "- Build traffic monitoring systems\n",
    "- Learn data collection and analysis\n",
    "\n",
    "**Ready for Level 4?**: `../04_Smart_Integration/AI_Plus_Motor_Data.ipynb`\n",
    "- Combine AI vision with VESC motor data\n",
    "- Build safety systems that respond to both visual and sensor data\n",
    "- Create multi-sensor fusion applications\n",
    "\n",
    "### ğŸ¯ Skills You Can Now Build\n",
    "\n",
    "- **Smart Doorbells**: Detect specific people and alert accordingly\n",
    "- **Security Systems**: Monitor areas and respond to intrusions\n",
    "- **IoT Devices**: Create smart sensors that react to their environment\n",
    "- **Automation Systems**: Trigger actions based on visual input\n",
    "- **Educational Tools**: Build interactive learning systems\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ† You're Now an Interactive AI Developer!\n",
    "\n",
    "You understand the complete pipeline from **AI detection** to **real-world action**. This is the foundation of modern smart systems, from simple home automation to complex autonomous vehicles!\n",
    "\n",
    "**Your next challenge**: Building even smarter systems that can handle multiple objects and complex decision-making. Ready to level up? ğŸ¤–âš¡âœ¨"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}