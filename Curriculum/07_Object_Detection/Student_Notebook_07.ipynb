{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ¤– Module 7: Live Object Detection\n",
    "\n",
    "Today, you will activate the AI camera and see the world through the eyes of a machine. This is your first time working with a live neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Your Mission\n",
    "\n",
    "Your goal is to build a **live object detection system**. You will start the camera, run the AI model, and draw bounding boxes around all the objects it recognizes in real-time. You will test the AI's capabilities and its limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The COCO Dataset\n",
    "The AI model you're using was trained on the COCO dataset, which includes 80 common object categories. Here are a few you can find in the classroom:\n",
    "* person\n",
    "* laptop\n",
    "* mouse\n",
    "* remote\n",
    "* keyboard\n",
    "* cell phone\n",
    "* book\n",
    "* clock\n",
    "* chair\n",
    "* potted plant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Camera Setup\n",
    "\n",
    "First, we need to import a new, more advanced API for interacting with the AI camera and initialize the video feed. This code is more complex as it manages a real-time video stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../../')) # Look for student_api in root\n",
    "from student_api import AIStudentAPI # Load the NEW AI API\n",
    "import cv2 # OpenCV for image manipulation\n",
    "from IPython.display import display, Image # For displaying images in notebook\n",
    "import time\n",
    "\n",
    "# Create API object\n",
    "api = AIStudentAPI()\n",
    "print(\"AI API created. Please wait for camera initialization...\")\n",
    "\n",
    "# This can take 10-20 seconds on the first run\n",
    "api.start_camera()\n",
    "\n",
    "print(\"âœ… Camera is live!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Live Detection\n",
    "\n",
    "Now for the exciting part. The code below creates a loop that grabs a frame from the camera, runs detection, draws the results, and displays it. Press the 'Interrupt' (square) button in the toolbar to stop the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    while True:\n",
    "        # Get the latest frame and detections from the camera\n",
    "        frame, detections = api.get_frame_and_detections()\n",
    "\n",
    "        # Draw bounding boxes on the frame\n",
    "        for detection in detections:\n",
    "            label = detection['label']\n",
    "            confidence = detection['confidence']\n",
    "            box = detection['box']\n",
    "            \n",
    "            # Get box coordinates\n",
    "            x, y, w, h = box\n",
    "            \n",
    "            # Draw the box\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (4, 23, 115), 2) # BGR color for the box\n",
    "            \n",
    "            # Create the label text\n",
    "            text = f'{label}: {confidence:.2f}'\n",
    "            \n",
    "            # Put the label on the image\n",
    "            cv2.putText(frame, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (4, 23, 115), 2)\n",
    "\n",
    "        # Display the frame in the notebook\n",
    "        _, img_encoded = cv2.imencode('.jpeg', frame)\n",
    "        display(Image(data=img_encoded.tobytes()))\n",
    "        \n",
    "        # Clear the previous output to create a real-time feel\n",
    "        clear_output(wait=True)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nStream stopped.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE: Test the Detector\n",
    "Run the live feed and point it at 5 different objects from the COCO list. Record what was detected and the confidence score.\n",
    "\n",
    "1. Object: \n",
    "2. Object: \n",
    "3. Object: \n",
    "4. Object: \n",
    "5. Object: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE: Find an undetected object\n",
    "Find an object that IS in the COCO list but the AI failed to detect. Why do you think it failed? (Hint: Lighting, angle, distance?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Filtering\n",
    "\n",
    "You probably saw many incorrect or low-confidence boxes. Let's filter them out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE: Add a Confidence Threshold\n",
    "Copy the live detection code from Section 3 into the cell below. Modify it by adding an `if` statement inside the `for` loop to only draw boxes for detections with a `confidence` **greater than 0.75**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your filtered detection code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE: Filter by Label\n",
    "Now, modify your code again to only show detections for the `'person'` label. This is very useful for safety systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your person-only detection code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Knowledge Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE: Short Answer\n",
    "What are three factors that can make object detection less accurate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// 1. \n",
    "// 2. \n",
    "// 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE: Short Answer\n",
    "Why can't the AI detect a water bottle, even if it's clearly visible?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Congratulations! You've completed Module 7.\n",
    "Remember to stop the camera to release the resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanly stop the API connection\n",
    "if 'api' in locals():\n",
    "    api.stop_camera()\n",
    "    print(\"Camera stopped.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
