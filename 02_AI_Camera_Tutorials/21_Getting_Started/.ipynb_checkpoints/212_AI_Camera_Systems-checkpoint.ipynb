{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Camera Systems\n",
    "\n",
    "## Traditional Cameras vs AI Cameras\n",
    "\n",
    "**Traditional Digital Cameras**:\n",
    "- Capture light and convert it to pixels\n",
    "- Store images as files (JPG, PNG)\n",
    "- Require separate computer to analyze images\n",
    "- Can only tell you about colors and brightness\n",
    "\n",
    "**AI-Enabled Cameras**:\n",
    "- Capture light AND understand what they see\n",
    "- Identify objects, people, and actions in real-time\n",
    "- Process intelligence directly on the camera\n",
    "- Provide structured data: \"person at location (240, 180) with 87% confidence\"\n",
    "\n",
    "The difference is like having eyes versus having eyes plus a brain that understands what you're looking at.\n",
    "\n",
    "## Object Detection Fundamentals\n",
    "\n",
    "Object detection is the core technology that makes cameras \"smart.\" It answers two key questions:\n",
    "\n",
    "1. **What is in the image?** (Classification)\n",
    "2. **Where is it located?** (Localization)\n",
    "\n",
    "### How Object Detection Works\n",
    "\n",
    "**Step 1: Feature Extraction**\n",
    "- Neural network scans the entire image\n",
    "- Identifies basic features: edges, corners, textures\n",
    "- Combines features into more complex patterns\n",
    "\n",
    "**Step 2: Object Recognition**\n",
    "- Matches patterns against learned examples\n",
    "- Calculates probability for each object type\n",
    "- Determines most likely classification\n",
    "\n",
    "**Step 3: Location Detection**\n",
    "- Identifies where objects are in the image\n",
    "- Creates bounding boxes around detected objects\n",
    "- Records precise pixel coordinates\n",
    "\n",
    "**Step 4: Results Output**\n",
    "- Combines classification + location + confidence\n",
    "- Example: \"person\" at (120, 200, 180, 280) with 0.91 confidence\n",
    "- Format: [x_min, y_min, x_max, y_max]\n",
    "\n",
    "## The IMX500 Advantage: Edge AI\n",
    "\n",
    "Your camera uses the Sony IMX500 sensor - a breakthrough in AI technology.\n",
    "\n",
    "### Traditional AI Setup Problems\n",
    "- Images sent to powerful computer or cloud\n",
    "- Processing takes 100-500 milliseconds\n",
    "- Requires internet connection\n",
    "- Uses lots of power (50-200 watts)\n",
    "- Expensive ($1000+ for AI processing hardware)\n",
    "\n",
    "### IMX500 Edge AI Solutions\n",
    "- AI processing built directly into the camera sensor\n",
    "- Results in 33 milliseconds (30 frames per second)\n",
    "- Works completely offline\n",
    "- Uses under 2 watts of power\n",
    "- Complete system costs under $100\n",
    "\n",
    "**Edge AI** means the intelligence is at the \"edge\" of the network - right where the data is captured, not in a distant data center."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Exercise: Understanding Detection Results\n",
    "\n",
    "Let's simulate how your AI camera provides detection results and learn to interpret the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Detection Results Simulator\n",
    "# This shows you exactly what your AI camera outputs\n",
    "\n",
    "import random\n",
    "\n",
    "def simulate_camera_detection():\n",
    "    \"\"\"Simulate IMX500 AI camera detection results\"\"\"\n",
    "    \n",
    "    # Simulate a realistic scene\n",
    "    detections = [\n",
    "        {\n",
    "            \"class\": \"person\",\n",
    "            \"confidence\": 0.91,\n",
    "            \"bbox\": [120, 80, 200, 240]  # [x_min, y_min, x_max, y_max]\n",
    "        },\n",
    "        {\n",
    "            \"class\": \"car\",\n",
    "            \"confidence\": 0.87,\n",
    "            \"bbox\": [300, 150, 480, 220]\n",
    "        },\n",
    "        {\n",
    "            \"class\": \"bicycle\",\n",
    "            \"confidence\": 0.73,\n",
    "            \"bbox\": [50, 160, 110, 200]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(\"IMX500 AI Camera Detection Results\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Frame processed in: 33ms (30 FPS)\")\n",
    "    print(f\"Objects detected: {len(detections)}\")\n",
    "    print()\n",
    "    \n",
    "    for i, detection in enumerate(detections, 1):\n",
    "        print(f\"Detection {i}:\")\n",
    "        print(f\"  Object: {detection['class']}\")\n",
    "        print(f\"  Confidence: {detection['confidence']:.2f} ({int(detection['confidence']*100)}%)\")\n",
    "        print(f\"  Bounding Box: {detection['bbox']}\")\n",
    "        \n",
    "        # Calculate size and position\n",
    "        x_min, y_min, x_max, y_max = detection['bbox']\n",
    "        width = x_max - x_min\n",
    "        height = y_max - y_min\n",
    "        center_x = x_min + width // 2\n",
    "        center_y = y_min + height // 2\n",
    "        \n",
    "        print(f\"  Size: {width}x{height} pixels\")\n",
    "        print(f\"  Center: ({center_x}, {center_y})\")\n",
    "        print()\n",
    "    \n",
    "    return detections\n",
    "\n",
    "# Run simulation\n",
    "results = simulate_camera_detection()\n",
    "\n",
    "print(\"Understanding the Data:\")\n",
    "print(\"• Bounding box [x_min, y_min, x_max, y_max] defines rectangle around object\")\n",
    "print(\"• Confidence 0.0-1.0 tells you how certain the AI is\")\n",
    "print(\"• Higher confidence = more reliable detection\")\n",
    "print(\"• You can filter detections by minimum confidence threshold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Exercise: Detection Filtering\n",
    "\n",
    "In real applications, you'll often want to filter detections based on confidence levels to reduce false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detection Filtering Exercise\n",
    "# Learn how confidence thresholds affect results\n",
    "\n",
    "def filter_detections(detections, confidence_threshold):\n",
    "    \"\"\"Filter detections by confidence threshold\"\"\"\n",
    "    return [d for d in detections if d['confidence'] >= confidence_threshold]\n",
    "\n",
    "# Sample detections with varying confidence levels\n",
    "all_detections = [\n",
    "    {\"class\": \"person\", \"confidence\": 0.95, \"bbox\": [100, 50, 150, 200]},\n",
    "    {\"class\": \"car\", \"confidence\": 0.88, \"bbox\": [200, 100, 350, 180]},\n",
    "    {\"class\": \"bicycle\", \"confidence\": 0.72, \"bbox\": [50, 150, 90, 190]},\n",
    "    {\"class\": \"dog\", \"confidence\": 0.45, \"bbox\": [300, 180, 340, 220]},\n",
    "    {\"class\": \"person\", \"confidence\": 0.31, \"bbox\": [400, 80, 420, 160]}\n",
    "]\n",
    "\n",
    "print(\"Detection Filtering Demonstration\")\n",
    "print(\"=\" * 35)\n",
    "print(f\"Total raw detections: {len(all_detections)}\")\n",
    "print()\n",
    "\n",
    "# Test different confidence thresholds\n",
    "thresholds = [0.9, 0.7, 0.5, 0.3]\n",
    "\n",
    "for threshold in thresholds:\n",
    "    filtered = filter_detections(all_detections, threshold)\n",
    "    print(f\"Confidence threshold: {threshold} ({int(threshold*100)}%)\")\n",
    "    print(f\"Detections kept: {len(filtered)}\")\n",
    "    \n",
    "    if filtered:\n",
    "        print(\"Objects:\")\n",
    "        for detection in filtered:\n",
    "            conf_percent = int(detection['confidence'] * 100)\n",
    "            print(f\"  • {detection['class']} ({conf_percent}%)\")\n",
    "    else:\n",
    "        print(\"No detections meet threshold\")\n",
    "    print()\n",
    "\n",
    "print(\"Threshold Selection Guide:\")\n",
    "print(\"• High threshold (0.8-0.9): Fewer false positives, might miss real objects\")\n",
    "print(\"• Medium threshold (0.6-0.7): Balanced accuracy and detection rate\")\n",
    "print(\"• Low threshold (0.3-0.5): Catches more objects, more false positives\")\n",
    "print(\"• Choose based on your application's needs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-World Applications\n",
    "\n",
    "AI cameras like yours are being used in many industries:\n",
    "\n",
    "**Smart Home Security**:\n",
    "- Detect people approaching doors\n",
    "- Distinguish between family members and strangers\n",
    "- Alert when packages are delivered\n",
    "\n",
    "**Retail and Business**:\n",
    "- Count customers entering stores\n",
    "- Monitor checkout areas for theft\n",
    "- Analyze customer behavior patterns\n",
    "\n",
    "**Transportation**:\n",
    "- Traffic flow monitoring\n",
    "- Parking space detection\n",
    "- License plate recognition\n",
    "\n",
    "**Healthcare and Safety**:\n",
    "- Fall detection for elderly care\n",
    "- PPE compliance monitoring\n",
    "- Social distancing enforcement\n",
    "\n",
    "**Manufacturing**:\n",
    "- Quality control inspection\n",
    "- Worker safety monitoring\n",
    "- Equipment status detection\n",
    "\n",
    "## Technical Specifications\n",
    "\n",
    "**Your IMX500 Camera System**:\n",
    "- **Sensor**: 12.3 megapixel CMOS with AI accelerator\n",
    "- **AI Model**: MobileNet SSD (Single Shot Detector)\n",
    "- **Object Classes**: 80 different types (people, vehicles, animals, objects)\n",
    "- **Processing Speed**: 30+ frames per second\n",
    "- **Accuracy**: Professional grade (mAP ~75%)\n",
    "- **Power Usage**: Under 2 watts total\n",
    "- **Connectivity**: Standard Raspberry Pi camera interface\n",
    "\n",
    "## Key Concepts Summary\n",
    "\n",
    "**Object Detection**: AI technology that identifies and locates objects in images\n",
    "\n",
    "**Bounding Boxes**: Rectangular coordinates that show where objects are located\n",
    "\n",
    "**Confidence Scores**: Numbers (0-1) indicating how certain the AI is about each detection\n",
    "\n",
    "**Edge AI**: Processing AI directly on the device instead of in the cloud\n",
    "\n",
    "**Confidence Thresholds**: Minimum confidence levels for accepting detections\n",
    "\n",
    "## What's Next?\n",
    "\n",
    "You now understand how AI cameras work and what makes your IMX500 special. Next, we'll set up your hardware and verify everything is working correctly.\n",
    "\n",
    "**Next notebook**: `213_Camera_Setup_Check.ipynb` - Setting Up Your AI Camera System"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
