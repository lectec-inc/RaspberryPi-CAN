{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live Camera Feed\n",
    "\n",
    "## From Theory to Practice\n",
    "\n",
    "In the previous lessons, you learned how light becomes intelligence:\n",
    "1. **Photons** hit the camera sensor\n",
    "2. **Photodiodes** convert light to electrical signals\n",
    "3. **Digital pixels** represent the image as numbers\n",
    "4. **Neural networks** process patterns in the pixel data\n",
    "5. **AI outputs** structured understanding of what it sees\n",
    "\n",
    "Now you'll see this process happening in real-time. Your camera is capturing 30 frames per second, and while this preview shows the raw images, the IMX500 sensor is simultaneously running AI processing on every frame.\n",
    "\n",
    "## What You're Observing\n",
    "\n",
    "The live feed below demonstrates several key concepts:\n",
    "\n",
    "**Real-time Processing**: Images are captured, processed, and displayed continuously\n",
    "\n",
    "**Digital Image Formation**: Each frame contains hundreds of thousands of pixels with RGB color values\n",
    "\n",
    "**System Integration**: Camera hardware, software drivers, and display work together seamlessly\n",
    "\n",
    "**Edge Computing**: All processing happens locally on your Raspberry Pi - no internet required\n",
    "\n",
    "While you're seeing the visual output, remember that your IMX500 sensor is simultaneously analyzing each frame for objects, calculating confidence scores, and determining bounding box coordinates - just like we discussed in the previous lessons.\n",
    "\n",
    "## Live Camera Preview\n",
    "\n",
    "Run the cell below to start your live camera feed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import cv2\n",
    "import numpy as np\n",
    "from IPython.display import display, clear_output, Image\n",
    "import ipywidgets as widgets\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# Stop button in notebook\n",
    "stopButton = widgets.ToggleButton(\n",
    "    value=False,\n",
    "    description='Stop Preview',\n",
    "    button_style='danger',\n",
    "    icon='square'\n",
    ")\n",
    "\n",
    "display(stopButton)\n",
    "\n",
    "def camera_preview():\n",
    "    # Use libcamera-vid to stream MJPEG into stdout\n",
    "    cmd = [\n",
    "        \"libcamera-vid\",\n",
    "        \"--inline\",           # Needed for streaming\n",
    "        \"-t\", \"0\",            # No timeout\n",
    "        \"--width\", \"640\",\n",
    "        \"--height\", \"480\",\n",
    "        \"--codec\", \"mjpeg\",\n",
    "        \"-o\", \"-\"             # Output to stdout\n",
    "    ]\n",
    "    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.DEVNULL)\n",
    "\n",
    "    data = b\"\"\n",
    "    display_handle = display(None, display_id=True)\n",
    "\n",
    "    while not stopButton.value:\n",
    "        chunk = proc.stdout.read(1024)\n",
    "        if not chunk:\n",
    "            break\n",
    "        data += chunk\n",
    "        a = data.find(b'\\xff\\xd8')  # JPEG start\n",
    "        b = data.find(b'\\xff\\xd9')  # JPEG end\n",
    "        if a != -1 and b != -1:\n",
    "            jpg = data[a:b+2]\n",
    "            data = data[b+2:]\n",
    "            frame = cv2.imdecode(np.frombuffer(jpg, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "            _, jpeg = cv2.imencode('.jpg', frame)\n",
    "            display_handle.update(Image(data=jpeg.tobytes()))\n",
    "    proc.terminate()\n",
    "\n",
    "# Start preview in a separate thread\n",
    "print(\"It takes 15-30 Seconds for the camera feed to begin the first time.\")\n",
    "threading.Thread(target=camera_preview, daemon=True).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding What Just Happened\n",
    "\n",
    "### Technical Process\n",
    "1. **libcamera-vid** captures raw image data from the IMX500 sensor\n",
    "2. **MJPEG codec** compresses each frame for efficient transmission\n",
    "3. **OpenCV** decodes the compressed images back into pixel arrays\n",
    "4. **Jupyter display** shows the processed frames in real-time\n",
    "\n",
    "### AI Processing Reality\n",
    "While you see the visual feed, remember that simultaneously:\n",
    "- The IMX500's built-in neural network is analyzing every frame\n",
    "- Object detection algorithms are running at 30+ FPS\n",
    "- Confidence scores and bounding boxes are being calculated\n",
    "- All processing happens in under 33 milliseconds per frame\n",
    "\n",
    "### System Verification\n",
    "If your camera feed is working smoothly, your system is ready for AI applications. You've verified:\n",
    "- ✅ Camera hardware is functioning\n",
    "- ✅ Software drivers are properly installed\n",
    "- ✅ Image processing pipeline works correctly\n",
    "- ✅ Real-time performance meets requirements\n",
    "\n",
    "## Connecting to Previous Learning\n",
    "\n",
    "This live feed demonstrates the concepts from lessons 211 and 212:\n",
    "\n",
    "**From 211 - Introduction to AI**:\n",
    "- Light photons are being captured and converted to digital pixels\n",
    "- The sensor processes this data through its neural network\n",
    "- What you see visually is just the raw image; the AI \"sees\" objects and patterns\n",
    "\n",
    "**From 212 - AI Camera Systems**:\n",
    "- This is Edge AI in action - processing happens locally on the sensor\n",
    "- Real-time performance (30 FPS) demonstrates the IMX500's capabilities\n",
    "- Each frame could produce object detections with confidence scores and locations\n",
    "\n",
    "## What's Next?\n",
    "\n",
    "Now that your camera system is verified and working, you're ready to move beyond raw video to actual AI detection. In the next lesson, we'll add the AI layer to see object detection results overlaid on the live video feed.\n",
    "\n",
    "**Next notebook**: AI Object Detection in Real-Time - where you'll see bounding boxes, confidence scores, and object labels appear automatically over your live video."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
