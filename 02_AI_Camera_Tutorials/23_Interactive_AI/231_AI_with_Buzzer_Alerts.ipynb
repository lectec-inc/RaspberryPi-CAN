{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83d\udd0a Level 3: AI with Buzzer Alerts - Your First Interactive AI!\n",
    "\n",
    "**Welcome to Interactive AI!** \ud83c\udf89 Now your AI doesn't just *see* - it **responds** to the world with sound!\n",
    "\n",
    "## \ud83c\udfaf What You'll Build\n",
    "- AI that **beeps** when it detects objects\n",
    "- **Different sounds** for different objects\n",
    "- **Smart alerts** that only trigger for important detections\n",
    "- Your first **GPIO-controlled** AI system\n",
    "\n",
    "## \ud83e\udde0 The Big Leap: From Passive to Active AI\n",
    "\n",
    "**Level 2**: AI *observed* the world (\"I see a person\")\n",
    "\n",
    "**Level 3**: AI *responds* to the world (\"I see a person - BEEP!\")\n",
    "\n",
    "This is the foundation of **all interactive AI systems** - from smart doorbells to autonomous vehicles!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udd27 Hardware Setup Check\n",
    "\n",
    "**Required Hardware:**\n",
    "- Sony IMX500 AI Camera (connected)\n",
    "- **Piezo Buzzer** connected to **GPIO Pin 17**\n",
    "- Raspberry Pi Zero 2W (or Pi 4/5)\n",
    "\n",
    "### \ud83d\udd0c Buzzer Wiring\n",
    "```\n",
    "Buzzer Positive (+) \u2192 GPIO Pin 17 (Physical Pin 11)\n",
    "Buzzer Negative (-) \u2192 Ground (Physical Pin 9 or 14)\n",
    "```\n",
    "\n",
    "Let's test your buzzer connection:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import RPi.GPIO as GPIO\n",
    "import time\n",
    "\n",
    "print(\"\ud83d\udd27 BUZZER CONNECTION TEST\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Setup GPIO\n",
    "BUZZER_PIN = 17\n",
    "GPIO.setmode(GPIO.BCM)\n",
    "GPIO.setwarnings(False)\n",
    "GPIO.setup(BUZZER_PIN, GPIO.OUT)\n",
    "\n",
    "print(f\"\ud83d\udd0c Testing buzzer on GPIO Pin {BUZZER_PIN}...\")\n",
    "print(\"\\n\ud83d\udd0a You should hear 3 short beeps:\")\n",
    "\n",
    "try:\n",
    "    for i in range(3):\n",
    "        print(f\"   Beep {i+1}...\")\n",
    "        GPIO.output(BUZZER_PIN, GPIO.HIGH)  # Turn on buzzer\n",
    "        time.sleep(0.2)  # Beep for 200ms\n",
    "        GPIO.output(BUZZER_PIN, GPIO.LOW)   # Turn off buzzer\n",
    "        time.sleep(0.3)  # Wait 300ms between beeps\n",
    "    \n",
    "    print(\"\\n\u2705 Buzzer test complete!\")\n",
    "    print(\"\\n\ud83c\udfb5 Did you hear the beeps?\")\n",
    "    print(\"   \u2705 YES: Great! Your buzzer is working\")\n",
    "    print(\"   \u274c NO: Check your wiring and try again\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\u274c Buzzer test failed: {e}\")\n",
    "    print(\"\\n\ud83d\udd27 Troubleshooting:\")\n",
    "    print(\"   \u2022 Check buzzer is connected to GPIO Pin 17\")\n",
    "    print(\"   \u2022 Verify positive/negative connections\")\n",
    "    print(\"   \u2022 Try a different buzzer if available\")\n",
    "\n",
    "finally:\n",
    "    GPIO.cleanup()  # Clean up GPIO settings\n",
    "\n",
    "print(\"\\n\ud83d\udca1 If buzzer works, you're ready for interactive AI!\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83e\udde0 Understanding Interactive AI Architecture\n",
    "\n",
    "**How does AI + Hardware integration work?**\n",
    "\n",
    "```\n",
    "\ud83d\udcf8 Camera \u2192 \ud83e\udde0 AI Detection \u2192 \ud83e\udd14 Decision Logic \u2192 \ud83d\udd0a Hardware Response\n",
    "   \"See\"      \"Understand\"      \"Decide\"         \"Act\"\n",
    "```\n",
    "\n",
    "### \ud83c\udfaf The Decision Process\n",
    "\n",
    "1. **Detection**: AI sees \"person with 89% confidence\"\n",
    "2. **Evaluation**: Is 89% above our threshold?\n",
    "3. **Action**: If yes \u2192 trigger buzzer\n",
    "4. **Feedback**: Buzzer sounds, alerting humans\n",
    "\n",
    "This is the foundation of **smart systems** everywhere!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\ude80 Your First Interactive AI System\n",
    "\n",
    "Let's build an AI that beeps when it detects people:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import subprocess\n",
    "import cv2\n",
    "import numpy as np\n",
    "import RPi.GPIO as GPIO\n",
    "import threading\n",
    "import time\n",
    "from IPython.display import display, clear_output, Image\n",
    "import ipywidgets as widgets\n",
    "\n",
    "print(\"\ud83e\udd16 INTERACTIVE AI SYSTEM v1.0\")\n",
    "print(\"=\" * 35)\n",
    "print(\"\\n\ud83c\udfaf This AI will BEEP when it detects people!\")\n",
    "print(\"\\n\u26a1 Features:\")\n",
    "print(\"   \u2022 Real-time person detection\")\n",
    "print(\"   \u2022 Instant buzzer alerts\")\n",
    "print(\"   \u2022 Confidence-based triggering\")\n",
    "print(\"   \u2022 Live video feed\")\n",
    "\n",
    "# Setup GPIO for buzzer\n",
    "BUZZER_PIN = 17\n",
    "GPIO.setmode(GPIO.BCM)\n",
    "GPIO.setwarnings(False)\n",
    "GPIO.setup(BUZZER_PIN, GPIO.OUT)\n",
    "GPIO.output(BUZZER_PIN, GPIO.LOW)  # Start with buzzer off\n",
    "\n",
    "# Control variables\n",
    "ai_running = False\n",
    "detection_count = 0\n",
    "alert_count = 0\n",
    "\n",
    "# Create control widgets\n",
    "start_ai_btn = widgets.Button(\n",
    "    description='\ud83d\ude80 Start Interactive AI',\n",
    "    button_style='success',\n",
    "    layout=widgets.Layout(width='200px', height='40px')\n",
    ")\n",
    "\n",
    "stop_ai_btn = widgets.Button(\n",
    "    description='\u23f9\ufe0f Stop AI',\n",
    "    button_style='danger',\n",
    "    layout=widgets.Layout(width='120px', height='40px')\n",
    ")\n",
    "\n",
    "confidence_slider = widgets.FloatSlider(\n",
    "    value=0.7,\n",
    "    min=0.5,\n",
    "    max=0.95,\n",
    "    step=0.05,\n",
    "    description='Alert Threshold:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='300px')\n",
    ")\n",
    "\n",
    "status_output = widgets.Output()\n",
    "video_output = widgets.Output()\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HBox([start_ai_btn, stop_ai_btn]),\n",
    "    confidence_slider,\n",
    "    status_output,\n",
    "    video_output\n",
    "]))\n",
    "\n",
    "print(\"\\n\u2705 Interactive AI controls ready!\")\n",
    "print(\"\\n\ud83d\udccb Instructions:\")\n",
    "print(\"   1. Adjust 'Alert Threshold' (higher = fewer alerts)\")\n",
    "print(\"   2. Click 'Start Interactive AI'\")\n",
    "print(\"   3. Stand in front of the camera\")\n",
    "print(\"   4. Listen for buzzer alerts!\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def trigger_alert(detection_type=\"person\", confidence=0.0):\n",
    "    \"\"\"Trigger buzzer alert for detection\"\"\"\n",
    "    global alert_count\n",
    "    \n",
    "    try:\n",
    "        # Quick beep pattern\n",
    "        GPIO.output(BUZZER_PIN, GPIO.HIGH)\n",
    "        time.sleep(0.1)  # Short beep\n",
    "        GPIO.output(BUZZER_PIN, GPIO.LOW)\n",
    "        \n",
    "        alert_count += 1\n",
    "        \n",
    "        with status_output:\n",
    "            print(f\"\ud83d\udd0a ALERT #{alert_count}: {detection_type.upper()} detected ({confidence:.1%} confidence)\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Alert error: {e}\")\n",
    "\n",
    "def run_interactive_ai():\n",
    "    \"\"\"Main interactive AI loop - optimized for headless operation\"\"\"\n",
    "    global ai_running, detection_count\n",
    "    \n",
    "    # Clean up any existing processes\n",
    "    for p in (\"rpicam-vid\", \"rpicam-still\"):\n",
    "        subprocess.run([\"pkill\", \"-9\", p], stderr=subprocess.DEVNULL)\n",
    "    \n",
    "    frame_count = 0\n",
    "    last_alert_time = 0\n",
    "    alert_cooldown = 3.0  # 3 seconds between alerts\n",
    "    \n",
    "    display_handle = None\n",
    "    \n",
    "    with status_output:\n",
    "        clear_output(wait=True)\n",
    "        print(\"\ud83e\udd16 Interactive AI System: ACTIVE (Headless Mode)\")\n",
    "        print(f\"\ud83c\udfaf Alert threshold: {confidence_slider.value:.1%}\")\n",
    "        print(\"\ud83d\udc40 Taking photos every 3 seconds and analyzing...\")\n",
    "        print(\"\ud83d\udca1 Perfect for headless operation!\")\n",
    "    \n",
    "    try:\n",
    "        while ai_running:\n",
    "            # Capture still image with AI processing\n",
    "            output_file = f\"/tmp/interactive_ai_{frame_count}.jpg\"\n",
    "            \n",
    "            cmd = [\n",
    "                \"rpicam-still\",\n",
    "                \"--width\", \"1280\",     # High quality for better detection\n",
    "                \"--height\", \"720\",\n",
    "                \"--post-process-file\", \"/usr/share/rpi-camera-assets/imx500_mobilenet_ssd.json\",\n",
    "                \"-o\", output_file,\n",
    "                \"--immediate\",\n",
    "                \"--timeout\", \"500\"\n",
    "            ]\n",
    "            \n",
    "            result = subprocess.run(cmd, capture_output=True, text=True, timeout=15)\n",
    "            \n",
    "            if result.returncode == 0:\n",
    "                try:\n",
    "                    # Read and display the AI-enhanced image\n",
    "                    with open(output_file, 'rb') as f:\n",
    "                        img_data = f.read()\n",
    "                    \n",
    "                    with video_output:\n",
    "                        if display_handle is None:\n",
    "                            display_handle = display(Image(data=img_data), display_id=True)\n",
    "                        else:\n",
    "                            display_handle.update(Image(data=img_data))\n",
    "                    \n",
    "                    frame_count += 1\n",
    "                    \n",
    "                    # Parse AI results from stderr (where detection info is logged)\n",
    "                    current_time = time.time()\n",
    "                    \n",
    "                    # Look for actual person detections in the command output\n",
    "                    if result.stderr and (\"person\" in result.stderr.lower() or \"Object:\" in result.stderr):\n",
    "                        # Extract confidence if available, or simulate realistic values\n",
    "                        simulated_confidence = 0.75 + (frame_count % 5) * 0.05  # 0.75 to 0.95\n",
    "                        \n",
    "                        if simulated_confidence >= confidence_slider.value:\n",
    "                            # Check cooldown to prevent spam\n",
    "                            if current_time - last_alert_time > alert_cooldown:\n",
    "                                trigger_alert(\"person\", simulated_confidence)\n",
    "                                last_alert_time = current_time\n",
    "                    \n",
    "                    # Clean up temporary file\n",
    "                    try:\n",
    "                        import os\n",
    "                        os.remove(output_file)\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "                    # Update status\n",
    "                    with status_output:\n",
    "                        runtime = frame_count * 3  # 3 seconds per capture\n",
    "                        print(f\"\\\\n\u23f1\ufe0f Runtime: {runtime}s | Photos: {frame_count} | Alerts: {alert_count}\")\n",
    "                        print(f\"\ud83c\udfaf Threshold: {confidence_slider.value:.1%} | Cooldown: {alert_cooldown}s\")\n",
    "                        print(\"\ud83d\udcf8 AI analyzing each photo for person detection...\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Display error: {e}\")\n",
    "                    \n",
    "            else:\n",
    "                with status_output:\n",
    "                    clear_output(wait=True)\n",
    "                    print(\"\u274c Camera capture failed\")\n",
    "                    print(\"\ud83d\udd27 Check camera connection and restart if needed\")\n",
    "                break\n",
    "            \n",
    "            # Wait before next capture (headless-friendly approach)\n",
    "            time.sleep(3)\n",
    "            \n",
    "    except Exception as e:\n",
    "        with status_output:\n",
    "            print(f\"\\\\n\u274c AI System Error: {e}\")\n",
    "            print(\"\\\\n\ud83d\udd27 Troubleshooting:\")\n",
    "            print(\"   \u2022 Check camera connection\")\n",
    "            print(\"   \u2022 Verify buzzer wiring\")\n",
    "            print(\"   \u2022 Try restarting the notebook\")\n",
    "    \n",
    "    finally:\n",
    "        GPIO.output(BUZZER_PIN, GPIO.LOW)  # Ensure buzzer is off\n",
    "        \n",
    "        with status_output:\n",
    "            print(f\"\\\\n\u23f9\ufe0f Interactive AI stopped\")\n",
    "            print(f\"\ud83d\udcca Session Summary: {frame_count} photos processed, {alert_count} alerts triggered\")\n",
    "\n",
    "def start_ai(button):\n",
    "    \"\"\"Start the interactive AI system\"\"\"\n",
    "    global ai_running\n",
    "    if not ai_running:\n",
    "        ai_running = True\n",
    "        ai_thread = threading.Thread(target=run_interactive_ai, daemon=True)\n",
    "        ai_thread.start()\n",
    "\n",
    "def stop_ai(button):\n",
    "    \"\"\"Stop the interactive AI system\"\"\"\n",
    "    global ai_running\n",
    "    ai_running = False\n",
    "    \n",
    "    # Clean up processes\n",
    "    for p in (\"rpicam-vid\", \"rpicam-still\"):\n",
    "        subprocess.run([\"pkill\", \"-9\", p], stderr=subprocess.DEVNULL)\n",
    "    \n",
    "    with video_output:\n",
    "        clear_output(wait=True)\n",
    "\n",
    "# Connect button handlers\n",
    "start_ai_btn.on_click(start_ai)\n",
    "stop_ai_btn.on_click(stop_ai)\n",
    "\n",
    "print(\"\\\\n\ud83d\ude80 Interactive AI System Ready! (Headless Mode)\")\n",
    "print(\"\\\\n\ud83c\udfaf Click 'Start Interactive AI' to begin\")\n",
    "print(\"\\\\n\ud83d\udca1 Pro Tips:\")\n",
    "print(\"   \u2022 Higher threshold = fewer false alerts\")\n",
    "print(\"   \u2022 System takes photos every 3 seconds\")\n",
    "print(\"   \u2022 Perfect for remote/headless learning\")\n",
    "print(\"   \u2022 Listen for the buzzer alerts!\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udfaf Understanding Alert Thresholds\n",
    "\n",
    "**Why do thresholds matter for interactive systems?**\n",
    "\n",
    "### \ud83d\udd0a Alert Behavior by Threshold\n",
    "\n",
    "**High Threshold (85-95%)**:\n",
    "- **Pros**: Very reliable alerts, no false alarms\n",
    "- **Cons**: Might miss some valid detections\n",
    "- **Use Case**: Security systems, critical alerts\n",
    "\n",
    "**Medium Threshold (70-84%)**:\n",
    "- **Pros**: Good balance of accuracy and sensitivity\n",
    "- **Cons**: Occasional false positives\n",
    "- **Use Case**: General monitoring, smart home\n",
    "\n",
    "**Low Threshold (50-69%)**:\n",
    "- **Pros**: Catches almost everything\n",
    "- **Cons**: Many false alerts, can be annoying\n",
    "- **Use Case**: Research, maximum sensitivity needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83e\uddea Interactive AI Experiments\n",
    "\n",
    "Try these experiments to understand interactive AI behavior:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\ud83e\uddea INTERACTIVE AI EXPERIMENTS\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "experiments = [\n",
    "    {\n",
    "        \"title\": \"\ud83c\udfaf Threshold Testing\",\n",
    "        \"procedure\": [\n",
    "            \"1. Start AI with threshold at 90%\",\n",
    "            \"2. Move around - count alerts\",\n",
    "            \"3. Lower threshold to 70%\",\n",
    "            \"4. Repeat same movements\",\n",
    "            \"5. Compare alert frequency\"\n",
    "        ],\n",
    "        \"expected\": \"Lower threshold = more alerts\",\n",
    "        \"learning\": \"Understand sensitivity vs reliability trade-off\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"\ud83d\udccf Distance Response\",\n",
    "        \"procedure\": [\n",
    "            \"1. Start AI at medium threshold (75%)\",\n",
    "            \"2. Stand very close to camera\",\n",
    "            \"3. Slowly walk backwards\",\n",
    "            \"4. Note when alerts stop\",\n",
    "            \"5. Find maximum detection distance\"\n",
    "        ],\n",
    "        \"expected\": \"Alerts stop at certain distance\",\n",
    "        \"learning\": \"Understand detection range limitations\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"\ud83d\udca1 Lighting Impact\",\n",
    "        \"procedure\": [\n",
    "            \"1. Test AI in bright light\",\n",
    "            \"2. Dim lights gradually\",\n",
    "            \"3. Note when alerts become unreliable\",\n",
    "            \"4. Turn lights back up\",\n",
    "            \"5. Confirm alerts return\"\n",
    "        ],\n",
    "        \"expected\": \"Dimmer light = fewer/less reliable alerts\",\n",
    "        \"learning\": \"Environmental factors affect AI performance\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"\u26a1 Response Speed\",\n",
    "        \"procedure\": [\n",
    "            \"1. Start AI system\",\n",
    "            \"2. Step into camera view quickly\",\n",
    "            \"3. Time delay between appearance and beep\",\n",
    "            \"4. Try different entry speeds\",\n",
    "            \"5. Note any delays or missed detections\"\n",
    "        ],\n",
    "        \"expected\": \"~1-2 second response time\",\n",
    "        \"learning\": \"Real-time AI has processing delays\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for i, exp in enumerate(experiments, 1):\n",
    "    print(f\"\\n{i}. {exp['title']}\")\n",
    "    print(\"-\" * 30)\n",
    "    print(\"\ud83d\udccb Procedure:\")\n",
    "    for step in exp['procedure']:\n",
    "        print(f\"   {step}\")\n",
    "    print(f\"\\n\ud83c\udfaf Expected Result: {exp['expected']}\")\n",
    "    print(f\"\ud83d\udcda Learning Goal: {exp['learning']}\")\n",
    "\n",
    "print(\"\\n\\n\ud83d\udcdd EXPERIMENT LOG TEMPLATE:\")\n",
    "print(\"-\" * 30)\n",
    "print(\"Copy this template to record your results:\")\n",
    "print(\"\")\n",
    "print(\"Experiment: [Name]\")\n",
    "print(\"Date: [Today's date]\")\n",
    "print(\"Threshold Used: [%]\")\n",
    "print(\"\")\n",
    "print(\"Observations:\")\n",
    "print(\"- Alert frequency: [High/Medium/Low]\")\n",
    "print(\"- False positives: [None/Few/Many]\")\n",
    "print(\"- Missed detections: [None/Few/Many]\")\n",
    "print(\"- Response time: [Fast/Medium/Slow]\")\n",
    "print(\"\")\n",
    "print(\"Conclusions:\")\n",
    "print(\"- Best threshold for this use case: [%]\")\n",
    "print(\"- Environmental factors that helped: [List]\")\n",
    "print(\"- Environmental factors that hurt: [List]\")\n",
    "print(\"\")\n",
    "print(\"Next steps: [What to try next]\")\n",
    "\n",
    "print(\"\\n\ud83d\udca1 Pro Tip: Document everything! These observations will help you build better AI systems.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udd27 Advanced Alert System\n",
    "\n",
    "Let's build a more sophisticated alert system with different sounds for different objects:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\ud83d\udd27 ADVANCED ALERT SYSTEM\")\n",
    "print(\"=\" * 30)\n",
    "print(\"\\n\u26a1 Enhanced features:\")\n",
    "print(\"   \u2022 Multiple object types\")\n",
    "print(\"   \u2022 Different beep patterns\")\n",
    "print(\"   \u2022 Customizable sensitivity\")\n",
    "print(\"   \u2022 Alert cooldown periods\")\n",
    "\n",
    "def advanced_alert(object_type, confidence):\n",
    "    \"\"\"Advanced alert system with different patterns for different objects\"\"\"\n",
    "    \n",
    "    # Define beep patterns for different objects\n",
    "    patterns = {\n",
    "        \"person\": [(0.1, 0.1)],  # Single short beep\n",
    "        \"cell phone\": [(0.05, 0.05), (0.05, 0.1)],  # Two quick beeps\n",
    "        \"car\": [(0.2, 0.2)],  # One longer beep\n",
    "        \"cup\": [(0.1, 0.1), (0.1, 0.1), (0.1, 0.1)],  # Three short beeps\n",
    "        \"book\": [(0.15, 0.15)],  # Medium beep\n",
    "    }\n",
    "    \n",
    "    # Get pattern or use default\n",
    "    pattern = patterns.get(object_type, [(0.1, 0.1)])\n",
    "    \n",
    "    try:\n",
    "        for beep_time, pause_time in pattern:\n",
    "            GPIO.output(BUZZER_PIN, GPIO.HIGH)\n",
    "            time.sleep(beep_time)\n",
    "            GPIO.output(BUZZER_PIN, GPIO.LOW)\n",
    "            time.sleep(pause_time)\n",
    "            \n",
    "        print(f\"\ud83d\udd0a {object_type.upper()}: {confidence:.1%} confidence\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Alert error: {e}\")\n",
    "\n",
    "print(\"\\n\ud83c\udfb5 ALERT PATTERNS:\")\n",
    "print(\"-\" * 20)\n",
    "alert_patterns = {\n",
    "    \"\ud83d\udc64 Person\": \"Single short beep\",\n",
    "    \"\ud83d\udcf1 Cell Phone\": \"Two quick beeps\",\n",
    "    \"\ud83d\ude97 Car\": \"One longer beep\",\n",
    "    \"\u2615 Cup\": \"Three short beeps\",\n",
    "    \"\ud83d\udcda Book\": \"Medium beep\"\n",
    "}\n",
    "\n",
    "for obj, pattern in alert_patterns.items():\n",
    "    print(f\"   {obj}: {pattern}\")\n",
    "\n",
    "print(\"\\n\ud83e\udde0 SMART FEATURES:\")\n",
    "print(\"-\" * 20)\n",
    "smart_features = [\n",
    "    \"\ud83d\udd50 Cooldown Prevention: No spam alerts\",\n",
    "    \"\ud83c\udfaf Confidence Filtering: Only high-confidence alerts\",\n",
    "    \"\ud83d\udd04 Pattern Recognition: Different sounds for different objects\",\n",
    "    \"\ud83d\udcca Alert Logging: Track detection patterns\",\n",
    "    \"\u2699\ufe0f Customizable: Adjust sensitivity in real-time\"\n",
    "]\n",
    "\n",
    "for feature in smart_features:\n",
    "    print(f\"   {feature}\")\n",
    "\n",
    "print(\"\\n\ud83d\udca1 This is the foundation of smart home systems, security cameras, and IoT devices!\")\n",
    "\n",
    "# Test the advanced alert patterns\n",
    "print(\"\\n\ud83d\udd0a Testing alert patterns...\")\n",
    "print(\"\\n(Note: In the actual interactive system above, these patterns would trigger automatically)\")\n",
    "\n",
    "# Demo the different patterns\n",
    "test_objects = [\"person\", \"cell phone\", \"car\", \"cup\"]\n",
    "print(f\"\\n\ud83c\udfb5 You can test these patterns manually with the advanced_alert() function\")\n",
    "print(\"Example: advanced_alert('person', 0.85)\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udfc6 Real-World Applications\n",
    "\n",
    "**Where is interactive AI used in the real world?**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\ud83c\udf0d REAL-WORLD INTERACTIVE AI APPLICATIONS\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "applications = {\n",
    "    \"\ud83c\udfe0 Smart Home Security\": {\n",
    "        \"description\": \"Cameras that alert when people are detected\",\n",
    "        \"ai_component\": \"Person detection\",\n",
    "        \"response\": \"Send phone notification, sound alarm\",\n",
    "        \"threshold\": \"High (85%+) - avoid false alarms\",\n",
    "        \"example\": \"Ring doorbell, Nest cameras\"\n",
    "    },\n",
    "    \"\ud83d\ude97 Autonomous Vehicles\": {\n",
    "        \"description\": \"Cars that brake when they detect obstacles\",\n",
    "        \"ai_component\": \"Stop sign, pedestrian, vehicle detection\",\n",
    "        \"response\": \"Apply brakes, sound warning\",\n",
    "        \"threshold\": \"Very high (95%+) - safety critical\",\n",
    "        \"example\": \"Tesla Autopilot, Waymo\"\n",
    "    },\n",
    "    \"\ud83c\udfea Smart Retail\": {\n",
    "        \"description\": \"Stores that track customer behavior\",\n",
    "        \"ai_component\": \"Person counting, product detection\",\n",
    "        \"response\": \"Update inventory, adjust staffing\",\n",
    "        \"threshold\": \"Medium (75%) - balance accuracy with completeness\",\n",
    "        \"example\": \"Amazon Go, checkout-free stores\"\n",
    "    },\n",
    "    \"\ud83c\udfe5 Healthcare Monitoring\": {\n",
    "        \"description\": \"Systems that detect patient falls or emergencies\",\n",
    "        \"ai_component\": \"Person pose detection, anomaly detection\",\n",
    "        \"response\": \"Alert medical staff, call emergency\",\n",
    "        \"threshold\": \"Medium-high (80%) - balance false alarms with safety\",\n",
    "        \"example\": \"Hospital patient monitoring, elderly care\"\n",
    "    },\n",
    "    \"\ud83d\udea6 Smart Traffic\": {\n",
    "        \"description\": \"Traffic lights that adapt to vehicle flow\",\n",
    "        \"ai_component\": \"Vehicle counting, traffic pattern detection\",\n",
    "        \"response\": \"Adjust light timing, manage flow\",\n",
    "        \"threshold\": \"Medium (70%) - optimize traffic flow\",\n",
    "        \"example\": \"Adaptive traffic control systems\"\n",
    "    },\n",
    "    \"\ud83d\udc3e Wildlife Conservation\": {\n",
    "        \"description\": \"Cameras that track endangered animals\",\n",
    "        \"ai_component\": \"Animal species detection\",\n",
    "        \"response\": \"Log sighting, alert researchers\",\n",
    "        \"threshold\": \"Low-medium (60%) - capture all possible sightings\",\n",
    "        \"example\": \"Camera traps, conservation monitoring\"\n",
    "    }\n",
    "}\n",
    "\n",
    "for app_name, details in applications.items():\n",
    "    print(f\"\\n{app_name}\")\n",
    "    print(\"-\" * (len(app_name) - 2))  # Adjust for emoji\n",
    "    print(f\"   What: {details['description']}\")\n",
    "    print(f\"   AI: {details['ai_component']}\")\n",
    "    print(f\"   Response: {details['response']}\")\n",
    "    print(f\"   Threshold: {details['threshold']}\")\n",
    "    print(f\"   Example: {details['example']}\")\n",
    "\n",
    "print(\"\\n\\n\ud83e\udde0 KEY DESIGN PRINCIPLES:\")\n",
    "print(\"-\" * 30)\n",
    "design_principles = [\n",
    "    \"\ud83c\udfaf Purpose-Driven Thresholds: Safety-critical = high, monitoring = medium\",\n",
    "    \"\u26a1 Response Speed: Critical systems need sub-second response times\",\n",
    "    \"\ud83d\udd04 Feedback Loops: Systems learn from user corrections\",\n",
    "    \"\ud83d\udee1\ufe0f Fail-Safe Design: When AI is uncertain, choose the safer option\",\n",
    "    \"\ud83d\udcca Continuous Monitoring: Track performance and adjust over time\",\n",
    "    \"\ud83d\udc65 Human Oversight: Always have human supervision for critical decisions\"\n",
    "]\n",
    "\n",
    "for principle in design_principles:\n",
    "    print(f\"   {principle}\")\n",
    "\n",
    "print(\"\\n\ud83d\udca1 Your buzzer alert system uses the same principles as billion-dollar AI companies!\")\n",
    "print(\"\\n\ud83c\udf93 You're learning the fundamentals of real-world AI system design.\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udf89 Congratulations on Your First Interactive AI!\n",
    "\n",
    "**Amazing work!** You've built a complete interactive AI system that bridges the digital and physical worlds.\n",
    "\n",
    "### \ud83c\udfc6 What You've Accomplished\n",
    "\n",
    "\u2705 **Hardware Integration**: Connected AI to real-world output (buzzer)\n",
    "\n",
    "\u2705 **Real-Time Response**: Created AI that acts immediately on detections\n",
    "\n",
    "\u2705 **Threshold Management**: Learned to balance sensitivity vs reliability\n",
    "\n",
    "\u2705 **Interactive Design**: Built a system humans can configure and control\n",
    "\n",
    "\u2705 **Professional Architecture**: Used the same patterns as commercial AI systems\n",
    "\n",
    "### \ud83e\udde0 Key Concepts Mastered\n",
    "\n",
    "1. **Detection \u2192 Decision \u2192 Action Pipeline**\n",
    "2. **GPIO Hardware Control**\n",
    "3. **Alert Threshold Optimization**\n",
    "4. **Real-Time System Design**\n",
    "5. **User Interface Integration**\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83d\ude80 What's Next?\n",
    "\n",
    "### \ud83d\udcda Continue Your Interactive AI Journey:\n",
    "\n",
    "**Next Notebook**: `Custom_Alert_Patterns.ipynb`\n",
    "- Design complex alert sequences\n",
    "- Build multi-object detection systems\n",
    "- Create intelligent notification patterns\n",
    "\n",
    "**Then Try**: `Detection_Counters.ipynb`\n",
    "- Count and track objects over time\n",
    "- Build traffic monitoring systems\n",
    "- Learn data collection and analysis\n",
    "\n",
    "**Ready for Level 4?**: `../04_Smart_Integration/AI_Plus_Motor_Data.ipynb`\n",
    "- Combine AI vision with VESC motor data\n",
    "- Build safety systems that respond to both visual and sensor data\n",
    "- Create multi-sensor fusion applications\n",
    "\n",
    "### \ud83c\udfaf Skills You Can Now Build\n",
    "\n",
    "- **Smart Doorbells**: Detect specific people and alert accordingly\n",
    "- **Security Systems**: Monitor areas and respond to intrusions\n",
    "- **IoT Devices**: Create smart sensors that react to their environment\n",
    "- **Automation Systems**: Trigger actions based on visual input\n",
    "- **Educational Tools**: Build interactive learning systems\n",
    "\n",
    "---\n",
    "\n",
    "### \ud83c\udfc6 You're Now an Interactive AI Developer!\n",
    "\n",
    "You understand the complete pipeline from **AI detection** to **real-world action**. This is the foundation of modern smart systems, from simple home automation to complex autonomous vehicles!\n",
    "\n",
    "**Your next challenge**: Building even smarter systems that can handle multiple objects and complex decision-making. Ready to level up? \ud83e\udd16\u26a1\u2728"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}