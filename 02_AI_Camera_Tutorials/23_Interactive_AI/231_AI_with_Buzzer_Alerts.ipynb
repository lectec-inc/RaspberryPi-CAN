{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI with Buzzer Alerts\n",
    "\n",
    "## Interactive AI Systems\n",
    "\n",
    "In the previous lesson, you learned to read AI detection data. Now you'll create an interactive AI system that responds to detections by controlling physical hardware.\n",
    "\n",
    "## What AI + Hardware Integration Provides\n",
    "\n",
    "**Detection Data**: The AI identifies objects with confidence scores\n",
    "\n",
    "**Decision Logic**: Your code decides what to do with the detection\n",
    "\n",
    "**Hardware Response**: Physical outputs (buzzers, LEDs, motors) respond to AI decisions\n",
    "\n",
    "**Real-Time Interaction**: The system actively responds to what it sees\n",
    "\n",
    "## Understanding GPIO\n",
    "\n",
    "GPIO (General Purpose Input/Output) pins allow the Raspberry Pi to control external hardware:\n",
    "\n",
    "**Digital Output**: Send HIGH (3.3V) or LOW (0V) signals to control devices like LEDs, buzzers, relays\n",
    "\n",
    "**Digital Input**: Read HIGH or LOW signals from sensors, buttons, switches\n",
    "\n",
    "**PWM (Pulse Width Modulation)**: Control brightness, speed, or tone by rapidly switching between HIGH and LOW\n",
    "\n",
    "## Hardware Setup Required\n",
    "\n",
    "For this lesson you need:\n",
    "- **Buzzer** connected to **GPIO Pin 17**\n",
    "- **Ground connection** from buzzer to any Pi ground pin\n",
    "\n",
    "**Wiring:**\n",
    "- Buzzer positive (+) â†’ GPIO Pin 17 (Physical pin 11)  \n",
    "- Buzzer negative (-) â†’ Ground (Physical pin 14 or any GND pin)\n",
    "\n",
    "If you don't have a buzzer, you can substitute an LED to see visual alerts instead of audio alerts.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Your Hardware Setup\n",
    "\n",
    "Let's test the buzzer connection before building the AI system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import RPi.GPIO as GPIO\n",
    "import time\n",
    "\n",
    "# GPIO Setup for buzzer control\n",
    "BUZZER_PIN = 17\n",
    "GPIO.setmode(GPIO.BCM)\n",
    "GPIO.setwarnings(False)\n",
    "GPIO.setup(BUZZER_PIN, GPIO.OUT)\n",
    "\n",
    "print(\"Testing buzzer connection...\")\n",
    "\n",
    "try:\n",
    "    # Test buzzer with 3 short beeps\n",
    "    for i in range(3):\n",
    "        print(f\"Beep {i+1}\")\n",
    "        GPIO.output(BUZZER_PIN, GPIO.HIGH)  # Turn buzzer ON\n",
    "        time.sleep(0.2)\n",
    "        GPIO.output(BUZZER_PIN, GPIO.LOW)   # Turn buzzer OFF\n",
    "        time.sleep(0.3)\n",
    "    \n",
    "    print(\"Buzzer test complete!\")\n",
    "    print(\"Did you hear the beeps? If yes, you're ready for the AI integration.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Buzzer test failed: {e}\")\n",
    "    print(\"Check your wiring and try again\")\n",
    "\n",
    "finally:\n",
    "    GPIO.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How GPIO Control Works\n",
    "\n",
    "GPIO control is simple but powerful:\n",
    "\n",
    "**GPIO.setup(pin, GPIO.OUT)**: Configure a pin as an output\n",
    "\n",
    "**GPIO.output(pin, GPIO.HIGH)**: Send 3.3V to the pin (turn device ON)\n",
    "\n",
    "**GPIO.output(pin, GPIO.LOW)**: Send 0V to the pin (turn device OFF)\n",
    "\n",
    "**GPIO.cleanup()**: Reset all GPIO settings (important for safety)\n",
    "\n",
    "## The AI + Hardware Pipeline\n",
    "\n",
    "```\n",
    "Camera â†’ AI Detection â†’ Decision Logic â†’ GPIO Output â†’ Physical Response\n",
    "```\n",
    "\n",
    "1. **Camera** captures video frame\n",
    "2. **AI Detection** identifies objects with confidence scores  \n",
    "3. **Decision Logic** evaluates if we should respond (threshold check)\n",
    "4. **GPIO Output** sends HIGH/LOW signal to buzzer pin\n",
    "5. **Physical Response** buzzer sounds, alerting humans\n",
    "\n",
    "This is the foundation of smart doorbells, security cameras, and IoT devices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive AI with Configurable Object Detection\n",
    "\n",
    "This system will detect any object from the COCO dataset and trigger buzzer alerts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import threading\n",
    "import RPi.GPIO as GPIO\n",
    "import cv2\n",
    "import numpy as np\n",
    "from IPython.display import display, clear_output, Image\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Add picamera2 to path\n",
    "sys.path.append('/home/pi/picamera2')\n",
    "\n",
    "from picamera2 import MappedArray, Picamera2\n",
    "from picamera2.devices import IMX500\n",
    "from picamera2.devices.imx500 import NetworkIntrinsics\n",
    "\n",
    "# GPIO Setup\n",
    "BUZZER_PIN = 17\n",
    "GPIO.setmode(GPIO.BCM)\n",
    "GPIO.setwarnings(False)\n",
    "GPIO.setup(BUZZER_PIN, GPIO.OUT)\n",
    "GPIO.output(BUZZER_PIN, GPIO.LOW)\n",
    "\n",
    "# Stop button for camera stream\n",
    "stopButton = widgets.ToggleButton(\n",
    "    value=False,\n",
    "    description='Stop AI Detection',\n",
    "    button_style='danger',\n",
    "    icon='square'\n",
    ")\n",
    "\n",
    "# HARDCODED VALUES - Experiment by changing these values\n",
    "TARGET_OBJECT = 'person'  # Change this to experiment with different objects: 'cup', 'apple', 'cell phone', etc.\n",
    "CONFIDENCE_THRESHOLD = 0.7  # Change this to experiment with different sensitivity levels (0.5 to 0.95)\n",
    "\n",
    "# Data output area\n",
    "data_output = widgets.Output()\n",
    "\n",
    "display(widgets.VBox([\n",
    "    stopButton,\n",
    "    data_output\n",
    "]))\n",
    "\n",
    "# Global variables for detection system\n",
    "current_detections = []\n",
    "total_detection_count = 0\n",
    "alert_count = 0\n",
    "last_alert_time = 0\n",
    "last_results = []  # Store detection results globally\n",
    "\n",
    "# COCO labels for the model\n",
    "def get_labels():\n",
    "    \"\"\"Get COCO dataset labels\"\"\"\n",
    "    return [\n",
    "        \"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "        \"traffic light\", \"fire hydrant\", \"\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "        \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"\", \"backpack\",\n",
    "        \"umbrella\", \"\", \"\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\",\n",
    "        \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\",\n",
    "        \"tennis racket\", \"bottle\", \"\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\",\n",
    "        \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\",\n",
    "        \"donut\", \"cake\", \"chair\", \"couch\", \"potted plant\", \"bed\", \"\", \"dining table\", \"\", \"\",\n",
    "        \"toilet\", \"\", \"tv\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\", \"microwave\",\n",
    "        \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "        \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "    ]\n",
    "\n",
    "class Detection:\n",
    "    def __init__(self, coords, category, conf, metadata, imx500, picam2):\n",
    "        \"\"\"Create a Detection object, recording the bounding box, category and confidence.\"\"\"\n",
    "        self.category = category\n",
    "        self.conf = conf\n",
    "        self.box = imx500.convert_inference_coords(coords, metadata, picam2)\n",
    "\n",
    "def parse_detections(metadata: dict, imx500, intrinsics, picam2):\n",
    "    \"\"\"Parse the output tensor into detected objects, scaled to the ISP output.\"\"\"\n",
    "    global last_results, current_detections, total_detection_count\n",
    "    \n",
    "    bbox_normalization = intrinsics.bbox_normalization\n",
    "    bbox_order = intrinsics.bbox_order\n",
    "    threshold = 0.55  # Base detection threshold\n",
    "    \n",
    "    np_outputs = imx500.get_outputs(metadata, add_batch=True)\n",
    "    input_w, input_h = imx500.get_input_size()\n",
    "    \n",
    "    if np_outputs is None:\n",
    "        return last_results\n",
    "    \n",
    "    # Parse detection outputs\n",
    "    boxes, scores, classes = np_outputs[0][0], np_outputs[1][0], np_outputs[2][0]\n",
    "    \n",
    "    if bbox_normalization:\n",
    "        boxes = boxes / input_h\n",
    "    \n",
    "    if bbox_order == \"xy\":\n",
    "        boxes = boxes[:, [1, 0, 3, 2]]\n",
    "    \n",
    "    boxes = np.array_split(boxes, 4, axis=1)\n",
    "    boxes = zip(*boxes)\n",
    "    \n",
    "    # Create detection objects\n",
    "    detections = [\n",
    "        Detection(box, category, score, metadata, imx500, picam2)\n",
    "        for box, score, category in zip(boxes, scores, classes)\n",
    "        if score > threshold\n",
    "    ]\n",
    "    \n",
    "    last_results = detections\n",
    "    return detections\n",
    "\n",
    "def draw_detections(request, stream=\"main\"):\n",
    "    \"\"\"Draw the detections for this request onto the ISP output.\"\"\"\n",
    "    global last_results\n",
    "    detections = last_results\n",
    "    if not detections:\n",
    "        return\n",
    "        \n",
    "    labels = get_labels()\n",
    "    with MappedArray(request, stream) as m:\n",
    "        for detection in detections:\n",
    "            x, y, w, h = detection.box\n",
    "            label = f\"{labels[int(detection.category)]} ({detection.conf:.2f})\"\n",
    "            \n",
    "            # Calculate text size and position\n",
    "            (text_width, text_height), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "            text_x = x + 5\n",
    "            text_y = y + 15\n",
    "            \n",
    "            # Create a copy of the array to draw the background with opacity\n",
    "            overlay = m.array.copy()\n",
    "            \n",
    "            # Draw the background rectangle on the overlay\n",
    "            cv2.rectangle(overlay,\n",
    "                          (text_x, text_y - text_height),\n",
    "                          (text_x + text_width, text_y + baseline),\n",
    "                          (255, 255, 255),  # Background color (white)\n",
    "                          cv2.FILLED)\n",
    "            \n",
    "            alpha = 0.30\n",
    "            cv2.addWeighted(overlay, alpha, m.array, 1 - alpha, 0, m.array)\n",
    "            \n",
    "            # Draw text on top of the background\n",
    "            cv2.putText(m.array, label, (text_x, text_y),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "            \n",
    "            # Draw detection box\n",
    "            cv2.rectangle(m.array, (x, y), (x + w, y + h), (0, 255, 0, 0), thickness=2)\n",
    "\n",
    "def trigger_buzzer_alert(object_name, confidence):\n",
    "    \"\"\"Trigger buzzer when target object is detected\"\"\"\n",
    "    global alert_count, last_alert_time\n",
    "    \n",
    "    current_time = time.time()\n",
    "    \n",
    "    # Cooldown period to prevent spam alerts (2 seconds)\n",
    "    if current_time - last_alert_time < 2.0:\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Buzzer alert pattern\n",
    "        GPIO.output(BUZZER_PIN, GPIO.HIGH)\n",
    "        time.sleep(0.15)  # Beep duration\n",
    "        GPIO.output(BUZZER_PIN, GPIO.LOW)\n",
    "        \n",
    "        alert_count += 1\n",
    "        last_alert_time = current_time\n",
    "        \n",
    "        # Print alert to console\n",
    "        print(f\"ðŸ”Š ALERT #{alert_count}: {object_name.upper()} detected with {confidence:.2f} confidence\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Buzzer alert error: {e}\")\n",
    "\n",
    "def capture_detection_data():\n",
    "    \"\"\"Capture and display detection data\"\"\"\n",
    "    global current_detections, total_detection_count, last_results\n",
    "    \n",
    "    def update_detection_display():\n",
    "        \"\"\"Update our custom detection display\"\"\"\n",
    "        target_object = TARGET_OBJECT  # Use hardcoded value\n",
    "        threshold = CONFIDENCE_THRESHOLD  # Use hardcoded value\n",
    "        \n",
    "        with data_output:\n",
    "            clear_output(wait=True)\n",
    "            print(\"AI + BUZZER ALERT SYSTEM\")\n",
    "            print(\"=\" * 30)\n",
    "            print(f\"ðŸŽ¯ Target Object: {target_object.upper()}\")\n",
    "            print(f\"ðŸŽšï¸ Alert Threshold: {threshold:.1%}\")\n",
    "            print(f\"ðŸ“Š Total Detections: {total_detection_count}\")\n",
    "            print(f\"ðŸ”Š Alerts Triggered: {alert_count}\")\n",
    "            print()\n",
    "            \n",
    "            if last_results:\n",
    "                print(\"CURRENT DETECTIONS:\")\n",
    "                print(\"-\" * 20)\n",
    "                \n",
    "                labels = get_labels()\n",
    "                for i, detection in enumerate(last_results, 1):\n",
    "                    x, y, w, h = detection.box\n",
    "                    conf_pct = detection.conf * 100\n",
    "                    object_name = labels[int(detection.category)]\n",
    "                    \n",
    "                    # Confidence indicator\n",
    "                    if detection.conf >= 0.8:\n",
    "                        indicator = \"ðŸŸ¢ HIGH\"\n",
    "                    elif detection.conf >= 0.6:\n",
    "                        indicator = \"ðŸŸ¡ MEDIUM\"\n",
    "                    else:\n",
    "                        indicator = \"ðŸŸ  LOW\"\n",
    "                    \n",
    "                    # Highlight target object\n",
    "                    name_display = f\"â­ {object_name.upper()}\" if object_name == target_object else object_name.upper()\n",
    "                    \n",
    "                    print(f\"Detection {i}: {name_display}\")\n",
    "                    print(f\"   Confidence: {conf_pct:.1f}% ({indicator})\")\n",
    "                    print(f\"   Location: ({x}, {y})\")\n",
    "                    print(f\"   Size: {w} x {h} pixels\")\n",
    "                    print()\n",
    "            else:\n",
    "                print(\"Waiting for detections...\")\n",
    "            \n",
    "            print(\"ALERT SYSTEM STATUS:\")\n",
    "            print(\"-\" * 20)\n",
    "            print(f\"ðŸŽ¯ Watching for: {target_object}\")\n",
    "            print(f\"ðŸŽšï¸ Confidence needed: {threshold:.1%}\")\n",
    "    \n",
    "    # Monitor detection changes and update display\n",
    "    last_detection_count = 0\n",
    "    while not stopButton.value:\n",
    "        try:\n",
    "            if last_results:\n",
    "                target_object = TARGET_OBJECT  # Use hardcoded value\n",
    "                threshold = CONFIDENCE_THRESHOLD  # Use hardcoded value\n",
    "                labels = get_labels()\n",
    "                \n",
    "                # Check for new detections of target object\n",
    "                for detection in last_results:\n",
    "                    object_name = labels[int(detection.category)]\n",
    "                    \n",
    "                    if object_name == target_object and detection.conf >= threshold:\n",
    "                        # Target object detected with sufficient confidence!\n",
    "                        trigger_buzzer_alert(object_name, detection.conf)\n",
    "                \n",
    "                # Update display if detection count changed\n",
    "                if len(last_results) != last_detection_count:\n",
    "                    total_detection_count += len(last_results) - last_detection_count\n",
    "                    last_detection_count = len(last_results)\n",
    "                    update_detection_display()\n",
    "            \n",
    "            time.sleep(0.5)  # Check for updates every 500ms\n",
    "        except Exception as e:\n",
    "            time.sleep(0.5)\n",
    "            continue\n",
    "\n",
    "def run_detection_demo():\n",
    "    \"\"\"Run the IMX500 detection demo with buzzer integration\"\"\"\n",
    "    global last_results\n",
    "    \n",
    "    try:\n",
    "        # Initialize IMX500 with the object detection model\n",
    "        model_path = \"/usr/share/imx500-models/imx500_network_ssd_mobilenetv2_fpnlite_320x320_pp.rpk\"\n",
    "        imx500 = IMX500(model_path)\n",
    "        intrinsics = imx500.network_intrinsics\n",
    "        \n",
    "        if not intrinsics:\n",
    "            intrinsics = NetworkIntrinsics()\n",
    "            intrinsics.task = \"object detection\"\n",
    "        \n",
    "        # Load labels\n",
    "        intrinsics.labels = get_labels()\n",
    "        intrinsics.update_with_defaults()\n",
    "        \n",
    "        # Initialize camera\n",
    "        picam2 = Picamera2(imx500.camera_num)\n",
    "        config = picam2.create_preview_configuration(\n",
    "            controls={\"FrameRate\": intrinsics.inference_rate}, \n",
    "            buffer_count=12\n",
    "        )\n",
    "        \n",
    "        # Show progress bar for network loading\n",
    "        imx500.show_network_fw_progress_bar()\n",
    "        \n",
    "        # Start camera\n",
    "        picam2.start(config, show_preview=False)\n",
    "        \n",
    "        # Set up aspect ratio if needed\n",
    "        if intrinsics.preserve_aspect_ratio:\n",
    "            imx500.set_auto_aspect_ratio()\n",
    "        \n",
    "        # Set up drawing callback\n",
    "        picam2.pre_callback = draw_detections\n",
    "        \n",
    "        # Create display handle for video\n",
    "        display_handle = display(None, display_id=True)\n",
    "        \n",
    "        # Main loop\n",
    "        while not stopButton.value:\n",
    "            try:\n",
    "                # Parse detections from metadata\n",
    "                last_results = parse_detections(picam2.capture_metadata(), imx500, intrinsics, picam2)\n",
    "                \n",
    "                # Capture frame for display\n",
    "                request = picam2.capture_request()\n",
    "                img = request.make_array(\"main\")\n",
    "                _, jpeg = cv2.imencode('.jpg', img)\n",
    "                display_handle.update(Image(data=jpeg.tobytes()))\n",
    "                request.release()\n",
    "                \n",
    "                time.sleep(0.1)\n",
    "            except Exception as e:\n",
    "                time.sleep(0.1)\n",
    "                continue\n",
    "        \n",
    "        picam2.stop()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(\"Make sure IMX500 camera is connected and model files exist.\")\n",
    "    finally:\n",
    "        GPIO.output(BUZZER_PIN, GPIO.LOW)  # Ensure buzzer is off\n",
    "        GPIO.cleanup()\n",
    "\n",
    "# Start the detection demo in background\n",
    "detection_thread = threading.Thread(target=run_detection_demo, daemon=True)\n",
    "detection_thread.start()\n",
    "\n",
    "# Start our data capture monitoring\n",
    "data_thread = threading.Thread(target=capture_detection_data, daemon=True)\n",
    "data_thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Alert Systems\n",
    "\n",
    "### Threshold Selection\n",
    "\n",
    "The confidence threshold determines when alerts are triggered:\n",
    "\n",
    "**High Threshold (85-95%)**:\n",
    "- Very reliable alerts\n",
    "- Few false positives  \n",
    "- May miss some valid detections\n",
    "- Best for: Security systems, critical alerts\n",
    "\n",
    "**Medium Threshold (70-84%)**:\n",
    "- Balanced accuracy and sensitivity\n",
    "- Occasional false positives\n",
    "- Best for: General monitoring, smart home\n",
    "\n",
    "**Low Threshold (50-69%)**:\n",
    "- High sensitivity, catches most detections\n",
    "- More false alerts\n",
    "- Best for: Research, when missing detections is worse than false alerts\n",
    "\n",
    "### Cooldown Periods\n",
    "\n",
    "The 2-second cooldown prevents alert spam:\n",
    "- Prevents multiple buzzer sounds for the same detection\n",
    "- Reduces annoying repetitive alerts\n",
    "- Allows time for object to move out of frame\n",
    "- Can be adjusted based on use case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment: Test Different Objects\n",
    "\n",
    "Try changing the target object and testing with different items:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common objects to test with your AI system\n",
    "\n",
    "test_objects = {\n",
    "    'person': 'Stand in front of camera',\n",
    "    'cup': 'Hold up a coffee cup or mug', \n",
    "    'cell phone': 'Hold up your phone',\n",
    "    'book': 'Hold up any book or notebook',\n",
    "    'apple': 'Hold up an apple or similar fruit',\n",
    "    'mouse': 'Computer mouse works well',\n",
    "    'keyboard': 'Computer keyboard',\n",
    "    'bottle': 'Water bottle or similar',\n",
    "    'chair': 'Point camera at a chair',\n",
    "    'laptop': 'Open laptop in view'\n",
    "}\n",
    "\n",
    "print(\"OBJECT DETECTION TEST GUIDE\")\n",
    "print(\"=\" * 30)\n",
    "print(\"Try these common objects with your AI alert system:\")\n",
    "print()\n",
    "\n",
    "for obj, instruction in test_objects.items():\n",
    "    print(f\"ðŸ“¦ {obj.upper()}\")\n",
    "    print(f\"   Test: {instruction}\")\n",
    "    print()\n",
    "\n",
    "print(\"TESTING PROCEDURE:\")\n",
    "print(\"1. Select object from dropdown\")\n",
    "print(\"2. Set confidence threshold (try 70% first)\")\n",
    "print(\"3. Follow the instruction above\")\n",
    "print(\"4. Listen for buzzer alert\")\n",
    "print(\"5. Try adjusting threshold if needed\")\n",
    "print()\n",
    "print(\"EXPECTED RESULTS:\")\n",
    "print(\"â€¢ Higher threshold = fewer alerts (more reliable)\")\n",
    "print(\"â€¢ Lower threshold = more alerts (more sensitive)\")\n",
    "print(\"â€¢ Some objects detect better than others\")\n",
    "print(\"â€¢ Lighting and angle affect detection quality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-World Applications\n",
    "\n",
    "This AI + GPIO pattern is used in many commercial systems:\n",
    "\n",
    "**Smart Doorbells**: Detect people and send alerts to phone apps\n",
    "- Target: 'person' with high confidence threshold\n",
    "- Response: Push notification + recorded video\n",
    "\n",
    "**Security Cameras**: Monitor for intruders or specific activities  \n",
    "- Target: 'person' in restricted areas\n",
    "- Response: Alarm sound + alert security team\n",
    "\n",
    "**Smart Retail**: Track customer interactions with products\n",
    "- Target: Multiple objects (products)\n",
    "- Response: Update inventory systems\n",
    "\n",
    "**Wildlife Monitoring**: Camera traps for conservation\n",
    "- Target: Specific animal species\n",
    "- Response: Log sighting data + researcher alerts\n",
    "\n",
    "**Manufacturing Quality Control**: Detect defects on assembly lines\n",
    "- Target: Product anomalies\n",
    "- Response: Stop production line + alert operators\n",
    "\n",
    "### Key Design Principles\n",
    "\n",
    "1. **Choose appropriate thresholds** based on consequences of false positives/negatives\n",
    "2. **Implement cooldown periods** to prevent alert spam  \n",
    "3. **Log all activity** for analysis and improvement\n",
    "4. **Provide user controls** for threshold adjustment\n",
    "5. **Test thoroughly** with real-world conditions\n",
    "\n",
    "The system you just built follows these same professional patterns!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced: Multiple Alert Patterns\n",
    "\n",
    "Want to create different buzzer patterns for different objects? Here's how:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import RPi.GPIO as GPIO\n",
    "import time\n",
    "\n",
    "def create_alert_pattern(object_type):\n",
    "    \"\"\"Create different buzzer patterns for different objects\"\"\"\n",
    "    \n",
    "    # Define patterns: (beep_duration, pause_duration)\n",
    "    patterns = {\n",
    "        'person': [(0.2, 0.3)],  # Single long beep\n",
    "        'cup': [(0.1, 0.1), (0.1, 0.1)],  # Two quick beeps  \n",
    "        'apple': [(0.1, 0.1), (0.1, 0.1), (0.1, 0.3)],  # Three quick beeps\n",
    "        'cell phone': [(0.05, 0.05), (0.05, 0.05), (0.05, 0.05), (0.05, 0.3)],  # Four very quick beeps\n",
    "        'mouse': [(0.3, 0.2)],  # One longer beep\n",
    "        'book': [(0.1, 0.2), (0.2, 0.3)]  # Short then long beep\n",
    "    }\n",
    "    \n",
    "    # Get pattern or use default\n",
    "    pattern = patterns.get(object_type, [(0.15, 0.2)])  # Default: medium beep\n",
    "    \n",
    "    return pattern\n",
    "\n",
    "def play_alert_pattern(object_type):\n",
    "    \"\"\"Play the alert pattern for a specific object\"\"\"\n",
    "    pattern = create_alert_pattern(object_type)\n",
    "    \n",
    "    BUZZER_PIN = 17\n",
    "    GPIO.setmode(GPIO.BCM)\n",
    "    GPIO.setwarnings(False) \n",
    "    GPIO.setup(BUZZER_PIN, GPIO.OUT)\n",
    "    \n",
    "    try:\n",
    "        for beep_time, pause_time in pattern:\n",
    "            GPIO.output(BUZZER_PIN, GPIO.HIGH)\n",
    "            time.sleep(beep_time)\n",
    "            GPIO.output(BUZZER_PIN, GPIO.LOW) \n",
    "            time.sleep(pause_time)\n",
    "    except:\n",
    "        pass\n",
    "    finally:\n",
    "        GPIO.cleanup()\n",
    "\n",
    "# Demonstrate the different patterns\n",
    "print(\"ALERT PATTERN DEMONSTRATIONS\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "pattern_descriptions = {\n",
    "    'person': 'Single long beep',\n",
    "    'cup': 'Two quick beeps',\n",
    "    'apple': 'Three quick beeps', \n",
    "    'cell phone': 'Four rapid beeps',\n",
    "    'mouse': 'One longer beep',\n",
    "    'book': 'Short then long beep'\n",
    "}\n",
    "\n",
    "for obj, desc in pattern_descriptions.items():\n",
    "    print(f\"{obj.upper()}: {desc}\")\n",
    "\n",
    "print(\"\\nTo test a pattern manually, run:\")\n",
    "print(\"play_alert_pattern('person')  # or any other object\")\n",
    "print(\"\\nTo integrate this into your AI system:\")\n",
    "print(\"Replace the simple buzzer code with play_alert_pattern(object_name)\")\n",
    "\n",
    "# Example integration code\n",
    "print(\"\\nEXAMPLE INTEGRATION:\")\n",
    "print(\"=\" * 20)\n",
    "print(\"\"\"\n",
    "def trigger_buzzer_alert(object_name, confidence):\n",
    "    global alert_count, last_alert_time\n",
    "    \n",
    "    current_time = time.time()\n",
    "    if current_time - last_alert_time < 2.0:\n",
    "        return\n",
    "        \n",
    "    play_alert_pattern(object_name)  # Use pattern instead of simple beep\n",
    "    alert_count += 1\n",
    "    last_alert_time = current_time\n",
    "    \n",
    "    print(f\"ðŸ”Š ALERT #{alert_count}: {object_name.upper()} detected\")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: AI + Hardware Integration\n",
    "\n",
    "Congratulations! You've built a complete interactive AI system that bridges the digital and physical worlds.\n",
    "\n",
    "### What You've Accomplished\n",
    "\n",
    "âœ… **GPIO Control**: Learned to control hardware with Raspberry Pi pins\n",
    "\n",
    "âœ… **AI Integration**: Connected AI detection data to physical responses\n",
    "\n",
    "âœ… **Configurable System**: Built controls for different objects and thresholds\n",
    "\n",
    "âœ… **Real-Time Response**: Created a system that responds instantly to detections\n",
    "\n",
    "âœ… **Professional Architecture**: Used patterns found in commercial AI systems\n",
    "\n",
    "### Key Concepts Learned\n",
    "\n",
    "**GPIO Basics**: Digital output control with HIGH/LOW signals\n",
    "\n",
    "**Alert Thresholds**: Balancing sensitivity vs reliability in AI systems\n",
    "\n",
    "**Cooldown Logic**: Preventing spam alerts in real-time systems\n",
    "\n",
    "**Object-Specific Responses**: Different actions for different detections\n",
    "\n",
    "**System Integration**: Combining multiple components into a working system\n",
    "\n",
    "### Real-World Applications\n",
    "\n",
    "The patterns you've learned are used in:\n",
    "- Smart home security systems\n",
    "- Industrial automation\n",
    "- IoT devices and sensors\n",
    "- Autonomous vehicle safety systems\n",
    "- Medical monitoring equipment\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "Ready for more advanced interactive AI? Try:\n",
    "- **Multiple Output Devices**: Control LEDs, motors, servos\n",
    "- **Input Sensors**: Combine camera AI with temperature, motion, sound sensors  \n",
    "- **Network Integration**: Send alerts to phones, web dashboards, cloud services\n",
    "- **Machine Learning**: Train custom models for your specific use cases\n",
    "\n",
    "You now understand the fundamentals of interactive AI systems - congratulations on becoming an AI + hardware integration developer!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ§  Key Concepts Mastered\n",
    "\n",
    "1. **Detection â†’ Decision â†’ Action Pipeline**\n",
    "2. **GPIO Hardware Control**\n",
    "3. **Alert Threshold Optimization**\n",
    "4. **Real-Time System Design**\n",
    "5. **User Interface Integration**\n",
    "\n",
    "\n",
    "### ðŸŽ¯ Skills You Can Now Build\n",
    "\n",
    "- **Smart Doorbells**: Detect specific people and alert accordingly\n",
    "- **Security Systems**: Monitor areas and respond to intrusions\n",
    "- **IoT Devices**: Create smart sensors that react to their environment\n",
    "- **Automation Systems**: Trigger actions based on visual input\n",
    "- **Educational Tools**: Build interactive learning systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
