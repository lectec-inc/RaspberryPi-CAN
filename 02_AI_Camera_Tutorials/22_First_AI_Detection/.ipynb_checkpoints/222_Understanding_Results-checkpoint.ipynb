{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding AI Detection Results\n",
    "\n",
    "## Reading AI Data\n",
    "\n",
    "In the previous lesson, you saw bounding boxes and labels on the video feed. Now you'll learn to read and interpret the actual data the AI provides.\n",
    "\n",
    "## What AI Actually Reports\n",
    "\n",
    "For each detected object, the AI provides:\n",
    "\n",
    "**Object Class**: What type of object (person, cup, phone, etc.)\n",
    "\n",
    "**Confidence Score**: Probability from 0.0 to 1.0 (or 0% to 100%)\n",
    "\n",
    "**Bounding Box**: Four coordinates defining the rectangle around the object\n",
    "\n",
    "**Timestamp**: When the detection occurred\n",
    "\n",
    "## Understanding Confidence Scores\n",
    "\n",
    "Confidence scores tell you how certain the AI is:\n",
    "\n",
    "- **0.9-1.0 (90-100%)**: Very reliable - almost certainly correct\n",
    "- **0.7-0.9 (70-90%)**: Usually reliable - good for most applications  \n",
    "- **0.5-0.7 (50-70%)**: Moderately reliable - use with caution\n",
    "- **Below 0.5 (50%)**: Low reliability - often filtered out\n",
    "\n",
    "The AI system only shows detections above a confidence threshold (usually 0.5 or 50%).\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live AI Data Analysis\n",
    "\n",
    "This tool captures live AI detection data and displays the raw information the system provides:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import threading\n",
    "from IPython.display import display, clear_output, Image\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Add picamera2 to path\n",
    "sys.path.append('/home/pi/picamera2')\n",
    "sys.path.append('/home/pi/picamera2/examples/imx500')\n",
    "\n",
    "# Import the existing IMX500 detection demo\n",
    "from imx500_object_detection_demo import *\n",
    "\n",
    "# Stop button for camera stream\n",
    "stopButton = widgets.ToggleButton(\n",
    "    value=False,\n",
    "    description='Stop AI Detection',\n",
    "    button_style='danger',\n",
    "    icon='square'\n",
    ")\n",
    "print(\"Please allow up to 30 seconds for the camera to load\")\n",
    "# Data output area\n",
    "data_output = widgets.Output()\n",
    "\n",
    "display(widgets.VBox([stopButton, data_output]))\n",
    "\n",
    "# Global variables for our data capture\n",
    "current_detections = []\n",
    "total_detection_count = 0\n",
    "\n",
    "def capture_detection_data():\n",
    "    \"\"\"Capture and display detection data from the existing demo\"\"\"\n",
    "    global current_detections, total_detection_count, last_detections\n",
    "    \n",
    "    def update_detection_display():\n",
    "        \"\"\"Update our custom detection display\"\"\"\n",
    "        with data_output:\n",
    "            clear_output(wait=True)\n",
    "            print(\"REAL-TIME AI DETECTION DATA\")\n",
    "            print(\"=\" * 30)\n",
    "            print(f\"Total detections: {total_detection_count}\")\n",
    "            print(f\"Current detections: {len(last_detections) if last_detections else 0}\")\n",
    "            print()\n",
    "            \n",
    "            if last_detections:\n",
    "                print(\"CURRENT DETECTIONS:\")\n",
    "                print(\"-\" * 20)\n",
    "                \n",
    "                for i, detection in enumerate(last_detections, 1):\n",
    "                    x, y, w, h = detection.box\n",
    "                    conf_pct = detection.conf * 100\n",
    "                    object_name = get_labels()[int(detection.category)]\n",
    "                    \n",
    "                    # Confidence indicator\n",
    "                    if detection.conf >= 0.8:\n",
    "                        indicator = \"🟢 HIGH\"\n",
    "                    elif detection.conf >= 0.6:\n",
    "                        indicator = \"🟡 MEDIUM\"\n",
    "                    else:\n",
    "                        indicator = \"🟠 LOW\"\n",
    "                    \n",
    "                    print(f\"Detection {i}: {object_name.upper()}\")\n",
    "                    print(f\"   Confidence: {conf_pct:.1f}% ({indicator})\")\n",
    "                    print(f\"   Location: Top-left ({x}, {y})\")\n",
    "                    print(f\"   Size: {w} x {h} pixels\")\n",
    "                    print(f\"   Bounding Box: [{x}, {y}, {x+w}, {y+h}]\")\n",
    "                    print()\n",
    "            else:\n",
    "                print(\"Waiting for detections...\")\n",
    "            \n",
    "            print(\"CONFIDENCE LEVELS:\")\n",
    "            print(\"🟢 HIGH (80%+): Very reliable\")\n",
    "            print(\"🟡 MEDIUM (60-80%): Usually reliable\") \n",
    "            print(\"🟠 LOW (40-60%): Use with caution\")\n",
    "    \n",
    "    # Monitor detection changes and update display\n",
    "    last_detection_count = 0\n",
    "    while not stopButton.value:\n",
    "        try:\n",
    "            if last_detections and len(last_detections) != last_detection_count:\n",
    "                # New detections found, print and update display\n",
    "                for detection in last_detections[last_detection_count:]:\n",
    "                    x, y, w, h = detection.box\n",
    "                    object_name = get_labels()[int(detection.category)]\n",
    "                    print(f\"DETECTED: {object_name} at ({x}, {y}) with {detection.conf:.2f} confidence\")\n",
    "                \n",
    "                total_detection_count += len(last_detections) - last_detection_count\n",
    "                last_detection_count = len(last_detections)\n",
    "                update_detection_display()\n",
    "            \n",
    "            time.sleep(0.5)  # Check for updates every 500ms\n",
    "        except Exception as e:\n",
    "            time.sleep(0.5)\n",
    "            continue\n",
    "\n",
    "def run_detection_demo():\n",
    "    \"\"\"Run the existing IMX500 detection demo with our data capture\"\"\"\n",
    "    global picam2, imx500, intrinsics, last_results\n",
    "    \n",
    "    try:\n",
    "        # Set up the demo (using existing code from imx500_object_detection_demo.py)\n",
    "        model_path = \"/usr/share/imx500-models/imx500_network_ssd_mobilenetv2_fpnlite_320x320_pp.rpk\"\n",
    "        \n",
    "        # This uses the existing demo's setup code\n",
    "        imx500 = IMX500(model_path)\n",
    "        intrinsics = imx500.network_intrinsics\n",
    "        if not intrinsics:\n",
    "            intrinsics = NetworkIntrinsics()\n",
    "            intrinsics.task = \"object detection\"\n",
    "        \n",
    "        # Load labels using existing function\n",
    "        if intrinsics.labels is None:\n",
    "            with open(\"/home/pi/picamera2/examples/imx500/assets/coco_labels.txt\", \"r\") as f:\n",
    "                intrinsics.labels = f.read().splitlines()\n",
    "        intrinsics.update_with_defaults()\n",
    "        \n",
    "        # Set up camera (from existing demo)\n",
    "        picam2 = Picamera2(imx500.camera_num)\n",
    "        config = picam2.create_preview_configuration(\n",
    "            controls={\"FrameRate\": intrinsics.inference_rate}, \n",
    "            buffer_count=12\n",
    "        )\n",
    "        \n",
    "        imx500.show_network_fw_progress_bar()\n",
    "        picam2.start(config, show_preview=False)\n",
    "        \n",
    "        if intrinsics.preserve_aspect_ratio:\n",
    "            imx500.set_auto_aspect_ratio()\n",
    "        \n",
    "        # Use existing draw_detections function\n",
    "        picam2.pre_callback = draw_detections\n",
    "        \n",
    "        # Create display handle for video\n",
    "        display_handle = display(None, display_id=True)\n",
    "        \n",
    "        # Main loop (simplified from existing demo)\n",
    "        while not stopButton.value:\n",
    "            try:\n",
    "                # Use existing parse_detections function\n",
    "                last_results = parse_detections(picam2.capture_metadata())\n",
    "                \n",
    "                # Capture frame for display\n",
    "                request = picam2.capture_request()\n",
    "                img = request.make_array(\"main\")\n",
    "                _, jpeg = cv2.imencode('.jpg', img)\n",
    "                display_handle.update(Image(data=jpeg.tobytes()))\n",
    "                request.release()\n",
    "                \n",
    "                time.sleep(0.1)\n",
    "            except Exception as e:\n",
    "                time.sleep(0.1)\n",
    "                continue\n",
    "        \n",
    "        picam2.stop()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(\"Make sure IMX500 camera is connected and model files exist.\")\n",
    "\n",
    "# Start the detection demo in background\n",
    "detection_thread = threading.Thread(target=run_detection_demo, daemon=True)\n",
    "detection_thread.start()\n",
    "\n",
    "# Start our data capture monitoring\n",
    "data_thread = threading.Thread(target=capture_detection_data, daemon=True)\n",
    "data_thread.start()\n",
    "\n",
    "print(\"Click 'Stop AI Detection' when finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Bounding Boxes\n",
    "\n",
    "Bounding boxes define rectangular areas around detected objects using four coordinates:\n",
    "\n",
    "**Format**: [x_min, y_min, x_max, y_max]\n",
    "\n",
    "- **x_min, y_min**: Top-left corner coordinates\n",
    "- **x_max, y_max**: Bottom-right corner coordinates\n",
    "- **Width**: x_max - x_min\n",
    "- **Height**: y_max - y_min\n",
    "- **Center**: ((x_min + x_max) / 2, (y_min + y_max) / 2)\n",
    "\n",
    "## Confidence Threshold Effects\n",
    "\n",
    "Try adjusting the confidence slider while the analysis runs:\n",
    "\n",
    "**High Threshold (0.8-0.9)**:\n",
    "- Only very reliable detections shown\n",
    "- Fewer false positives\n",
    "- Might miss some real objects\n",
    "\n",
    "**Medium Threshold (0.5-0.7)**:\n",
    "- Balanced approach\n",
    "- Good for most applications\n",
    "- Occasional false positives\n",
    "\n",
    "**Low Threshold (0.1-0.4)**:\n",
    "- Shows uncertain detections\n",
    "- More false positives\n",
    "- Useful for research/debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Concepts Summary\n",
    "\n",
    "**Real Detection Data**: We capture actual AI detection results, not simulated data\n",
    "\n",
    "**Detection Stream**: Continuous flow of object detection information from the camera\n",
    "\n",
    "**Structured Output**: Each detection provides object type, confidence, location, and timestamp\n",
    "\n",
    "**Console Monitoring**: Detections are printed as they occur for easy monitoring\n",
    "\n",
    "**Future Applications**: This detection stream will be used in later lessons to trigger actions\n",
    "\n",
    "## Understanding the Data\n",
    "\n",
    "When you run the detection stream, you'll see:\n",
    "\n",
    "1. **Live video feed** with AI bounding boxes and labels\n",
    "2. **Data panel** showing current detections with detailed information  \n",
    "3. **Console output** printing each detection as it happens\n",
    "\n",
    "The console output format: `DETECTED: [object] at ([x], [y]) with [confidence] confidence`\n",
    "\n",
    "This provides a simple way to monitor what the AI sees in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
