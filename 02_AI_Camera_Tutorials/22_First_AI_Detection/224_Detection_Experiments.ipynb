{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83e\uddea Detection Experiments: Testing AI Limits & Capabilities\n",
    "\n",
    "**Time to be a scientist!** \ud83d\udd2c Let's systematically test what affects AI detection and discover the boundaries of what's possible.\n",
    "\n",
    "## \ud83c\udfaf What You'll Discover\n",
    "- How distance affects detection accuracy\n",
    "- The impact of lighting conditions\n",
    "- Object orientation and angle effects\n",
    "- Size limitations and optimal conditions\n",
    "- Environmental factors that help or hurt AI\n",
    "\n",
    "## \ud83d\udd2c Scientific Method Applied to AI\n",
    "We'll use **controlled experiments** to understand AI behavior:\n",
    "1. **Hypothesis**: Make a prediction\n",
    "2. **Test**: Try it with the camera\n",
    "3. **Observe**: Record what happens\n",
    "4. **Analyze**: Understand why\n",
    "5. **Apply**: Use knowledge for better AI\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udd27 Experiment Setup\n",
    "\n",
    "Let's prepare our experimental environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import cv2\n",
    "import numpy as np\n",
    "from IPython.display import display, clear_output, Image, HTML\n",
    "import ipywidgets as widgets\n",
    "import threading\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "# Experiment tracking variables\n",
    "experiment_results = []\n",
    "current_experiment = None\n",
    "\n",
    "print(\"\ud83e\uddea AI DETECTION EXPERIMENT LAB\")\n",
    "print(\"=\" * 35)\n",
    "print(\"\\n\ud83d\udd2c Welcome, AI Researcher!\")\n",
    "print(\"\\n\ud83d\udccb Available Experiments:\")\n",
    "print(\"   1. \ud83d\udccf Distance Testing\")\n",
    "print(\"   2. \ud83d\udca1 Lighting Conditions\")\n",
    "print(\"   3. \ud83d\udd04 Object Orientation\")\n",
    "print(\"   4. \ud83d\udcd0 Size & Scale Effects\")\n",
    "print(\"   5. \ud83c\udf2b\ufe0f Environmental Challenges\")\n",
    "print(\"   6. \u26a1 Performance Optimization\")\n",
    "\n",
    "# Setup experiment controls\n",
    "experiment_selector = widgets.Dropdown(\n",
    "    options=[\n",
    "        ('\ud83d\udccf Distance Testing', 'distance'),\n",
    "        ('\ud83d\udca1 Lighting Conditions', 'lighting'),\n",
    "        ('\ud83d\udd04 Object Orientation', 'orientation'),\n",
    "        ('\ud83d\udcd0 Size & Scale Effects', 'scale'),\n",
    "        ('\ud83c\udf2b\ufe0f Environmental Challenges', 'environment'),\n",
    "        ('\u26a1 Performance Optimization', 'performance')\n",
    "    ],\n",
    "    value='distance',\n",
    "    description='Experiment:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "start_experiment_btn = widgets.Button(\n",
    "    description='\ud83d\ude80 Start Experiment',\n",
    "    button_style='success',\n",
    "    layout=widgets.Layout(width='150px', height='40px')\n",
    ")\n",
    "\n",
    "stop_experiment_btn = widgets.Button(\n",
    "    description='\u23f9\ufe0f Stop',\n",
    "    button_style='danger',\n",
    "    layout=widgets.Layout(width='100px', height='40px')\n",
    ")\n",
    "\n",
    "experiment_output = widgets.Output()\n",
    "video_output = widgets.Output()\n",
    "\n",
    "display(widgets.VBox([\n",
    "    experiment_selector,\n",
    "    widgets.HBox([start_experiment_btn, stop_experiment_btn]),\n",
    "    experiment_output,\n",
    "    video_output\n",
    "]))\n",
    "\n",
    "print(\"\\n\u2705 Experiment lab ready!\")\n",
    "print(\"\\n\ud83c\udfaf Choose an experiment above and click 'Start Experiment'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment definitions and procedures\n",
    "EXPERIMENTS = {\n",
    "    'distance': {\n",
    "        'name': '\ud83d\udccf Distance Testing Experiment',\n",
    "        'hypothesis': 'Objects closer to camera will have higher confidence scores',\n",
    "        'procedure': [\n",
    "            '1. Place object very close to camera (< 1 foot)',\n",
    "            '2. Slowly move object away from camera',\n",
    "            '3. Note confidence changes at different distances',\n",
    "            '4. Find maximum reliable detection distance'\n",
    "        ],\n",
    "        'what_to_observe': 'Confidence scores decreasing with distance',\n",
    "        'tips': 'Use a distinctive object like a coffee cup or book'\n",
    "    },\n",
    "    'lighting': {\n",
    "        'name': '\ud83d\udca1 Lighting Conditions Experiment',\n",
    "        'hypothesis': 'Better lighting improves detection accuracy and confidence',\n",
    "        'procedure': [\n",
    "            '1. Test in bright natural light',\n",
    "            '2. Test in dim indoor lighting',\n",
    "            '3. Test with artificial light sources',\n",
    "            '4. Test in shadows or backlighting'\n",
    "        ],\n",
    "        'what_to_observe': 'How confidence scores change with light levels',\n",
    "        'tips': 'Try positioning lamp or moving near window'\n",
    "    },\n",
    "    'orientation': {\n",
    "        'name': '\ud83d\udd04 Object Orientation Experiment',\n",
    "        'hypothesis': 'Objects shown from typical viewing angles detect better',\n",
    "        'procedure': [\n",
    "            '1. Show object from normal viewing angle',\n",
    "            '2. Rotate object 90 degrees',\n",
    "            '3. Show object upside down',\n",
    "            '4. Show object from unusual angles'\n",
    "        ],\n",
    "        'what_to_observe': 'Which orientations give highest confidence',\n",
    "        'tips': 'Books, phones, and cups work great for this test'\n",
    "    },\n",
    "    'scale': {\n",
    "        'name': '\ud83d\udcd0 Size & Scale Effects Experiment',\n",
    "        'hypothesis': 'Medium-sized objects in frame detect better than very large or tiny ones',\n",
    "        'procedure': [\n",
    "            '1. Fill entire frame with object (very close)',\n",
    "            '2. Show object taking ~50% of frame',\n",
    "            '3. Show object taking ~25% of frame',\n",
    "            '4. Show object very small in frame'\n",
    "        ],\n",
    "        'what_to_observe': 'Optimal size for detection confidence',\n",
    "        'tips': 'Use zoom or distance to control apparent size'\n",
    "    },\n",
    "    'environment': {\n",
    "        'name': '\ud83c\udf2b\ufe0f Environmental Challenges Experiment',\n",
    "        'hypothesis': 'Cluttered backgrounds and occlusion reduce detection performance',\n",
    "        'procedure': [\n",
    "            '1. Test with clean, simple background',\n",
    "            '2. Test with cluttered background',\n",
    "            '3. Test with similar objects nearby',\n",
    "            '4. Test with partial occlusion (object partially hidden)'\n",
    "        ],\n",
    "        'what_to_observe': 'How background complexity affects detection',\n",
    "        'tips': 'Try placing object on desk vs. in cluttered area'\n",
    "    },\n",
    "    'performance': {\n",
    "        'name': '\u26a1 Performance Optimization Experiment',\n",
    "        'hypothesis': 'Lower resolution and framerate can maintain accuracy while improving stability',\n",
    "        'procedure': [\n",
    "            '1. Test at full resolution (1920x1080)',\n",
    "            '2. Test at medium resolution (1280x720)',\n",
    "            '3. Test at lower framerate (15fps vs 30fps)',\n",
    "            '4. Monitor CPU temperature during tests'\n",
    "        ],\n",
    "        'what_to_observe': 'Performance vs accuracy trade-offs',\n",
    "        'tips': 'Check system temperature: vcgencmd measure_temp'\n",
    "    }\n",
    "}\n",
    "\n",
    "def start_experiment(experiment_type):\n",
    "    \"\"\"Start the selected experiment\"\"\"\n",
    "    global current_experiment\n",
    "    current_experiment = experiment_type\n",
    "    \n",
    "    exp_info = EXPERIMENTS[experiment_type]\n",
    "    \n",
    "    with experiment_output:\n",
    "        clear_output(wait=True)\n",
    "        print(f\"\ud83e\uddea {exp_info['name']}\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"\\n\ud83c\udfaf HYPOTHESIS: {exp_info['hypothesis']}\")\n",
    "        print(f\"\\n\ud83d\udccb PROCEDURE:\")\n",
    "        for step in exp_info['procedure']:\n",
    "            print(f\"   {step}\")\n",
    "        print(f\"\\n\ud83d\udc40 WHAT TO OBSERVE: {exp_info['what_to_observe']}\")\n",
    "        print(f\"\\n\ud83d\udca1 TIPS: {exp_info['tips']}\")\n",
    "        print(f\"\\n\ud83d\ude80 Experiment starting in 3 seconds...\")\n",
    "        print(f\"\\n\ud83d\udcca Watch for confidence score changes in the video feed below!\")\n",
    "    \n",
    "    # Start video feed after short delay\n",
    "    time.sleep(3)\n",
    "    start_detection_feed(experiment_type)\n",
    "\n",
    "def start_detection_feed(experiment_type):\n",
    "    \"\"\"Start AI detection video feed for experiments\"\"\"\n",
    "    \n",
    "    # Choose resolution based on experiment\n",
    "    if experiment_type == 'performance':\n",
    "        width, height, fps = \"1280\", \"720\", \"20\"  # Lower for performance testing\n",
    "    else:\n",
    "        width, height, fps = \"1920\", \"1080\", \"30\"  # Full quality for other tests\n",
    "    \n",
    "    # Clean up existing processes\n",
    "    for p in (\"rpicam-vid\", \"rpicam-still\"):\n",
    "        subprocess.run([\"pkill\", \"-9\", p], stderr=subprocess.DEVNULL)\n",
    "    \n",
    "    def run_detection():\n",
    "        cmd = [\n",
    "            \"rpicam-vid\",\n",
    "            \"--inline\",\n",
    "            \"-t\", \"0\",\n",
    "            \"--width\", width,\n",
    "            \"--height\", height,\n",
    "            \"--framerate\", fps,\n",
    "            \"--codec\", \"mjpeg\",\n",
    "            \"--post-process-file\", \"/usr/share/rpi-camera-assets/imx500_mobilenet_ssd.json\",\n",
    "            \"-o\", \"-\"\n",
    "        ]\n",
    "        \n",
    "        try:\n",
    "            proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            \n",
    "            data = b\"\"\n",
    "            frame_count = 0\n",
    "            start_time = time.time()\n",
    "            \n",
    "            display_handle = None\n",
    "            \n",
    "            while current_experiment == experiment_type:\n",
    "                chunk = proc.stdout.read(4096)\n",
    "                if not chunk:\n",
    "                    break\n",
    "                    \n",
    "                data += chunk\n",
    "                \n",
    "                start = data.find(b'\\xff\\xd8')\n",
    "                end = data.find(b'\\xff\\xd9')\n",
    "                \n",
    "                if start != -1 and end != -1:\n",
    "                    jpg_data = data[start:end+2]\n",
    "                    data = data[end+2:]\n",
    "                    \n",
    "                    try:\n",
    "                        frame = cv2.imdecode(np.frombuffer(jpg_data, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "                        if frame is not None:\n",
    "                            _, display_jpg = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 85])\n",
    "                            \n",
    "                            with video_output:\n",
    "                                if display_handle is None:\n",
    "                                    display_handle = display(Image(data=display_jpg.tobytes()), display_id=True)\n",
    "                                else:\n",
    "                                    display_handle.update(Image(data=display_jpg.tobytes()))\n",
    "                            \n",
    "                            frame_count += 1\n",
    "                            \n",
    "                            # Update experiment status every 60 frames\n",
    "                            if frame_count % 60 == 0:\n",
    "                                elapsed = time.time() - start_time\n",
    "                                fps_actual = frame_count / elapsed\n",
    "                                \n",
    "                                with experiment_output:\n",
    "                                    # Keep existing content, just update status\n",
    "                                    print(f\"\\n\u23f1\ufe0f Experiment Status: Running for {elapsed:.0f}s at {fps_actual:.1f} FPS\")\n",
    "                                    if experiment_type == 'performance':\n",
    "                                        # Show CPU temp for performance experiments\n",
    "                                        try:\n",
    "                                            temp_result = subprocess.run(['vcgencmd', 'measure_temp'], \n",
    "                                                                       capture_output=True, text=True)\n",
    "                                            if temp_result.returncode == 0:\n",
    "                                                temp = temp_result.stdout.strip().split('=')[1]\n",
    "                                                print(f\"\ud83c\udf21\ufe0f CPU Temperature: {temp}\")\n",
    "                                        except:\n",
    "                                            pass\n",
    "                    except:\n",
    "                        continue\n",
    "                \n",
    "                time.sleep(0.001)\n",
    "                \n",
    "        except Exception as e:\n",
    "            with experiment_output:\n",
    "                print(f\"\\n\u274c Experiment error: {str(e)}\")\n",
    "        finally:\n",
    "            try:\n",
    "                proc.terminate()\n",
    "                proc.wait(timeout=2)\n",
    "            except:\n",
    "                proc.kill()\n",
    "    \n",
    "    # Run detection in separate thread\n",
    "    detection_thread = threading.Thread(target=run_detection, daemon=True)\n",
    "    detection_thread.start()\n",
    "\n",
    "def stop_experiment():\n",
    "    \"\"\"Stop current experiment\"\"\"\n",
    "    global current_experiment\n",
    "    current_experiment = None\n",
    "    \n",
    "    # Kill camera processes\n",
    "    for p in (\"rpicam-vid\", \"rpicam-still\"):\n",
    "        subprocess.run([\"pkill\", \"-9\", p], stderr=subprocess.DEVNULL)\n",
    "    \n",
    "    with experiment_output:\n",
    "        print(\"\\n\u23f9\ufe0f Experiment stopped\")\n",
    "        print(\"\\n\ud83d\udcdd Don't forget to record your observations!\")\n",
    "        print(\"\\n\ud83d\udd2c Ready for next experiment or analysis\")\n",
    "    \n",
    "    with video_output:\n",
    "        clear_output(wait=True)\n",
    "\n",
    "# Connect button handlers\n",
    "def on_start_click(button):\n",
    "    start_experiment(experiment_selector.value)\n",
    "\n",
    "def on_stop_click(button):\n",
    "    stop_experiment()\n",
    "\n",
    "start_experiment_btn.on_click(on_start_click)\n",
    "stop_experiment_btn.on_click(on_stop_click)\n",
    "\n",
    "print(\"\\n\u2705 Experiment controls ready!\")\n",
    "print(\"\\n\ud83c\udfaf Select an experiment type and click 'Start Experiment' to begin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcca Experiment Results Recording & Analysis\n",
    "\n",
    "Use this section to record your observations and analyze patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment results recording system\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"\ud83d\udcca EXPERIMENT RESULTS LAB\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Sample results from common experiments\n",
    "sample_results = {\n",
    "    \"\ud83d\udccf Distance Testing\": {\n",
    "        \"observations\": {\n",
    "            \"Very Close (< 1 foot)\": \"95-99% confidence, object may be cropped\",\n",
    "            \"Optimal Range (1-4 feet)\": \"85-95% confidence, best detection\",\n",
    "            \"Medium Distance (4-8 feet)\": \"70-85% confidence, still reliable\",\n",
    "            \"Far Distance (8+ feet)\": \"40-70% confidence, depends on object size\",\n",
    "            \"Very Far (15+ feet)\": \"<40% confidence, unreliable\"\n",
    "        },\n",
    "        \"key_findings\": [\n",
    "            \"Optimal detection range: 1-6 feet\",\n",
    "            \"Large objects detectable further than small ones\",\n",
    "            \"Confidence drops exponentially with distance\"\n",
    "        ]\n",
    "    },\n",
    "    \"\ud83d\udca1 Lighting Conditions\": {\n",
    "        \"observations\": {\n",
    "            \"Bright Natural Light\": \"90-95% confidence, excellent accuracy\",\n",
    "            \"Good Indoor Lighting\": \"80-90% confidence, very good\",\n",
    "            \"Dim Indoor Light\": \"60-80% confidence, acceptable\",\n",
    "            \"Shadows/Backlighting\": \"40-60% confidence, challenging\",\n",
    "            \"Very Dark\": \"<40% confidence, unreliable\"\n",
    "        },\n",
    "        \"key_findings\": [\n",
    "            \"Natural light gives best results\",\n",
    "            \"Shadows significantly impact confidence\",\n",
    "            \"Even overhead light improves detection dramatically\"\n",
    "        ]\n",
    "    },\n",
    "    \"\ud83d\udd04 Object Orientation\": {\n",
    "        \"observations\": {\n",
    "            \"Normal Viewing Angle\": \"85-95% confidence\",\n",
    "            \"45\u00b0 Rotation\": \"75-85% confidence\",\n",
    "            \"90\u00b0 Rotation\": \"60-75% confidence\",\n",
    "            \"Upside Down\": \"50-70% confidence\",\n",
    "            \"Extreme Angles\": \"30-50% confidence\"\n",
    "        },\n",
    "        \"key_findings\": [\n",
    "            \"AI trained on typical viewing angles\",\n",
    "            \"Some objects more orientation-sensitive than others\",\n",
    "            \"Symmetrical objects less affected by rotation\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Display sample results\n",
    "for experiment, results in sample_results.items():\n",
    "    print(f\"\\n\ud83e\uddea {experiment}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    print(\"\\n\ud83d\udccb Typical Observations:\")\n",
    "    for condition, result in results[\"observations\"].items():\n",
    "        print(f\"   \u2022 {condition}: {result}\")\n",
    "    \n",
    "    print(\"\\n\ud83c\udfaf Key Findings:\")\n",
    "    for finding in results[\"key_findings\"]:\n",
    "        print(f\"   \u2713 {finding}\")\n",
    "\n",
    "print(\"\\n\\n\ud83d\udcdd YOUR EXPERIMENT NOTES:\")\n",
    "print(\"=\" * 30)\n",
    "print(\"Use the space below to record your own observations:\")\n",
    "\n",
    "# Create interactive note-taking area\n",
    "notes_area = widgets.Textarea(\n",
    "    value=\"Experiment: \\nDate: {}\\n\\nObservations:\\n- \\n- \\n- \\n\\nConclusions:\\n- \\n- \\n\\nNext steps: \\n\".format(datetime.now().strftime(\"%Y-%m-%d %H:%M\")),\n",
    "    placeholder='Record your experiment observations here...',\n",
    "    description='Lab Notes:',\n",
    "    layout=widgets.Layout(width='100%', height='200px'),\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "save_notes_btn = widgets.Button(\n",
    "    description='\ud83d\udcbe Save Notes',\n",
    "    button_style='info',\n",
    "    layout=widgets.Layout(width='120px')\n",
    ")\n",
    "\n",
    "def save_notes(button):\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"/tmp/ai_experiment_notes_{timestamp}.txt\"\n",
    "    \n",
    "    try:\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(notes_area.value)\n",
    "        print(f\"\u2705 Notes saved to {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\u274c Error saving notes: {e}\")\n",
    "\n",
    "save_notes_btn.on_click(save_notes)\n",
    "\n",
    "display(widgets.VBox([notes_area, save_notes_btn]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udfaf Quick Experiment Challenges\n",
    "\n",
    "Try these focused challenges to test specific aspects of AI detection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\ud83c\udfc6 AI DETECTION CHALLENGES\")\n",
    "print(\"=\" * 30)\n",
    "print(\"\\n\ud83c\udfae Complete these challenges to master AI detection:\")\n",
    "\n",
    "challenges = [\n",
    "    {\n",
    "        \"title\": \"\ud83c\udfaf The Confidence Hunter\",\n",
    "        \"task\": \"Find an object that consistently gives >95% confidence\",\n",
    "        \"difficulty\": \"Easy\",\n",
    "        \"tips\": \"Try well-lit, distinctive objects like phones or cups\",\n",
    "        \"success_criteria\": \"Achieve >95% confidence for 10+ seconds\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"\ud83d\udccf The Distance Master\",\n",
    "        \"task\": \"Find the maximum distance for reliable detection\",\n",
    "        \"difficulty\": \"Medium\",\n",
    "        \"tips\": \"Start close and slowly move away while watching confidence\",\n",
    "        \"success_criteria\": \"Determine max distance for >70% confidence\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"\ud83c\udf19 The Shadow Detective\",\n",
    "        \"task\": \"Get good detection in challenging lighting\",\n",
    "        \"difficulty\": \"Medium\",\n",
    "        \"tips\": \"Try different light sources and angles\",\n",
    "        \"success_criteria\": \"Achieve >80% confidence in dim conditions\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"\ud83d\udd04 The Orientation Optimizer\",\n",
    "        \"task\": \"Find the best angle for tricky objects\",\n",
    "        \"difficulty\": \"Medium\",\n",
    "        \"tips\": \"Test books, remotes, or phones at different angles\",\n",
    "        \"success_criteria\": \"Compare confidence at 5+ different angles\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"\ud83c\udfc3 The Speed Demon\",\n",
    "        \"task\": \"Test detection on moving objects\",\n",
    "        \"difficulty\": \"Hard\",\n",
    "        \"tips\": \"Move objects at different speeds across the frame\",\n",
    "        \"success_criteria\": \"Track object successfully while in motion\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"\ud83c\udfad The Impostor Hunter\",\n",
    "        \"task\": \"Find objects that fool the AI\",\n",
    "        \"difficulty\": \"Hard\",\n",
    "        \"tips\": \"Try objects that look similar to COCO dataset items\",\n",
    "        \"success_criteria\": \"Find 3+ objects that get misidentified\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for i, challenge in enumerate(challenges, 1):\n",
    "    difficulty_emoji = {\n",
    "        \"Easy\": \"\ud83d\udfe2\",\n",
    "        \"Medium\": \"\ud83d\udfe1\", \n",
    "        \"Hard\": \"\ud83d\udd34\"\n",
    "    }[challenge[\"difficulty\"]]\n",
    "    \n",
    "    print(f\"\\n{i}. {challenge['title']} {difficulty_emoji}\")\n",
    "    print(f\"   \ud83d\udccb Task: {challenge['task']}\")\n",
    "    print(f\"   \ud83d\udca1 Tips: {challenge['tips']}\")\n",
    "    print(f\"   \u2705 Success: {challenge['success_criteria']}\")\n",
    "\n",
    "print(\"\\n\\n\ud83c\udfc5 CHALLENGE TRACKING:\")\n",
    "print(\"-\" * 20)\n",
    "print(\"Mark your completed challenges:\")\n",
    "print(\"\u25a1 Confidence Hunter\")\n",
    "print(\"\u25a1 Distance Master\")\n",
    "print(\"\u25a1 Shadow Detective\")\n",
    "print(\"\u25a1 Orientation Optimizer\")\n",
    "print(\"\u25a1 Speed Demon\")\n",
    "print(\"\u25a1 Impostor Hunter\")\n",
    "\n",
    "print(\"\\n\ud83c\udf89 Complete all 6 challenges to become an AI Detection Expert!\")\n",
    "print(\"\\n\ud83d\udcaa Pro Tip: Document your results in the notes section above!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcc8 Performance Analysis & Optimization Tips\n",
    "\n",
    "Learn how to optimize AI performance for different scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\u26a1 AI PERFORMANCE OPTIMIZATION GUIDE\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "print(\"\\n\ud83c\udfaf OPTIMIZATION STRATEGIES:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "optimization_tips = {\n",
    "    \"\ud83d\udda5\ufe0f For Pi Zero 2W\": {\n",
    "        \"resolution\": \"Use 1280x720 for complex applications\",\n",
    "        \"framerate\": \"20fps is sufficient for most uses\",\n",
    "        \"cooling\": \"Add passive heatsink for sustained operation\",\n",
    "        \"os\": \"Use Pi OS Lite (64-bit) - no desktop\"\n",
    "    },\n",
    "    \"\ud83d\udcca For Accuracy\": {\n",
    "        \"lighting\": \"Ensure good, even lighting\",\n",
    "        \"distance\": \"Keep objects 1-6 feet from camera\",\n",
    "        \"background\": \"Use simple, uncluttered backgrounds\",\n",
    "        \"stability\": \"Mount camera to reduce motion blur\"\n",
    "    },\n",
    "    \"\u26a1 For Speed\": {\n",
    "        \"resolution\": \"Lower resolution = faster processing\",\n",
    "        \"roi\": \"Focus on specific region of interest\",\n",
    "        \"threshold\": \"Higher confidence threshold = fewer detections to process\",\n",
    "        \"objects\": \"Filter to only objects you care about\"\n",
    "    },\n",
    "    \"\ud83d\udd0b For Battery Life\": {\n",
    "        \"framerate\": \"Reduce to 10-15fps for battery applications\",\n",
    "        \"resolution\": \"640x480 can be sufficient for basic detection\",\n",
    "        \"sleep\": \"Use detection intervals instead of continuous\",\n",
    "        \"gpio\": \"Power down unnecessary peripherals\"\n",
    "    }\n",
    "}\n",
    "\n",
    "for category, tips in optimization_tips.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for aspect, tip in tips.items():\n",
    "        print(f\"   \u2022 {aspect.title()}: {tip}\")\n",
    "\n",
    "print(\"\\n\\n\ud83c\udf21\ufe0f THERMAL MANAGEMENT:\")\n",
    "print(\"-\" * 25)\n",
    "print(\"Monitor CPU temperature to prevent throttling:\")\n",
    "print(\"\")\n",
    "print(\"# Check current temperature\")\n",
    "print(\"vcgencmd measure_temp\")\n",
    "print(\"\")\n",
    "print(\"# Temperature guidelines:\")\n",
    "print(\"\u2022 <60\u00b0C: Excellent\")\n",
    "print(\"\u2022 60-70\u00b0C: Good\")\n",
    "print(\"\u2022 70-80\u00b0C: Monitor closely\")\n",
    "print(\"\u2022 >80\u00b0C: Add cooling or reduce load\")\n",
    "\n",
    "print(\"\\n\\n\ud83d\udcca PERFORMANCE METRICS TO TRACK:\")\n",
    "print(\"-\" * 35)\n",
    "metrics = [\n",
    "    \"\ud83d\uddbc\ufe0f Actual FPS achieved\",\n",
    "    \"\ud83c\udf21\ufe0f CPU temperature\",\n",
    "    \"\ud83d\udcca Average confidence scores\",\n",
    "    \"\u23f1\ufe0f Detection latency\",\n",
    "    \"\ud83c\udfaf Detection accuracy rate\",\n",
    "    \"\ud83d\udcbe Memory usage\"\n",
    "]\n",
    "\n",
    "for metric in metrics:\n",
    "    print(f\"   {metric}\")\n",
    "\n",
    "print(\"\\n\\n\ud83d\udd27 QUICK PERFORMANCE CHECK:\")\n",
    "print(\"-\" * 30)\n",
    "try:\n",
    "    # Check CPU temperature\n",
    "    temp_result = subprocess.run(['vcgencmd', 'measure_temp'], capture_output=True, text=True)\n",
    "    if temp_result.returncode == 0:\n",
    "        temp = temp_result.stdout.strip()\n",
    "        print(f\"\ud83c\udf21\ufe0f Current CPU Temperature: {temp}\")\n",
    "        \n",
    "        temp_val = float(temp.split('=')[1].replace(\"'C\", \"\"))\n",
    "        if temp_val < 60:\n",
    "            print(\"   \u2705 Excellent - No thermal concerns\")\n",
    "        elif temp_val < 70:\n",
    "            print(\"   \ud83d\udfe1 Good - Normal operating temperature\")\n",
    "        elif temp_val < 80:\n",
    "            print(\"   \ud83d\udfe0 Warm - Monitor during extended use\")\n",
    "        else:\n",
    "            print(\"   \ud83d\udd34 Hot - Consider adding cooling or reducing load\")\n",
    "    else:\n",
    "        print(\"\u274c Unable to read CPU temperature\")\n",
    "except Exception as e:\n",
    "    print(f\"\u274c Temperature check failed: {e}\")\n",
    "\n",
    "# Check available memory\n",
    "try:\n",
    "    mem_result = subprocess.run(['free', '-h'], capture_output=True, text=True)\n",
    "    if mem_result.returncode == 0:\n",
    "        mem_lines = mem_result.stdout.strip().split('\\n')\n",
    "        if len(mem_lines) >= 2:\n",
    "            mem_info = mem_lines[1].split()\n",
    "            print(f\"\ud83d\udcbe Memory: {mem_info[2]} used / {mem_info[1]} total\")\n",
    "except Exception as e:\n",
    "    print(f\"\u274c Memory check failed: {e}\")\n",
    "\n",
    "print(\"\\n\ud83c\udfaf Remember: Optimization is about finding the right balance for YOUR specific use case!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udf89 Experiment Conclusions\n",
    "\n",
    "Congratulations on completing your AI detection experiments! Let's summarize what you've learned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\ud83c\udf93 EXPERIMENT CONCLUSIONS & KEY LEARNINGS\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "key_discoveries = {\n",
    "    \"\ud83d\udd0d Detection Fundamentals\": [\n",
    "        \"AI confidence varies dramatically with conditions\",\n",
    "        \"Distance, lighting, and orientation all matter\",\n",
    "        \"Optimal detection zone: 1-6 feet with good lighting\",\n",
    "        \"Background complexity affects detection reliability\"\n",
    "    ],\n",
    "    \"\u26a1 Performance Insights\": [\n",
    "        \"IMX500 does AI processing, Pi CPU stays cool\",\n",
    "        \"Resolution and framerate can be tuned for application\",\n",
    "        \"Pi Zero 2W can handle 30fps at 1080p for simple scenes\",\n",
    "        \"Thermal management important for sustained operation\"\n",
    "    ],\n",
    "    \"\ud83c\udfaf Practical Applications\": [\n",
    "        \"Choose confidence threshold based on use case\",\n",
    "        \"Environmental factors must be considered in design\",\n",
    "        \"Testing and validation essential for reliability\",\n",
    "        \"Optimization requires balancing multiple factors\"\n",
    "    ],\n",
    "    \"\ud83e\udde0 AI Understanding\": [\n",
    "        \"AI has predictable strengths and limitations\",\n",
    "        \"Training data affects what AI can detect well\",\n",
    "        \"Confidence scores provide valuable reliability information\",\n",
    "        \"Real-world performance differs from lab conditions\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "for category, learnings in key_discoveries.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for learning in learnings:\n",
    "        print(f\"   \u2713 {learning}\")\n",
    "\n",
    "print(\"\\n\\n\ud83d\ude80 NEXT STEPS IN YOUR AI JOURNEY:\")\n",
    "print(\"-\" * 35)\n",
    "next_steps = [\n",
    "    \"\ud83d\udcda Study Object Types Guide to understand all 80+ detectable objects\",\n",
    "    \"\ud83d\udd0a Move to Level 3: Interactive AI with GPIO and buzzer alerts\",\n",
    "    \"\ud83d\ude97 Explore Level 4: Integration with VESC motor data\",\n",
    "    \"\ud83c\udfd7\ufe0f Design Level 5: Your own real-world AI application\",\n",
    "    \"\ud83d\udd2c Continue experimenting with different objects and scenarios\",\n",
    "    \"\ud83d\udcca Practice choosing appropriate confidence thresholds\"\n",
    "]\n",
    "\n",
    "for step in next_steps:\n",
    "    print(f\"   {step}\")\n",
    "\n",
    "print(\"\\n\\n\ud83c\udfc6 EXPERIMENT MASTER ACHIEVEMENT UNLOCKED!\")\n",
    "print(\"=\" * 45)\n",
    "print(\"You now have hands-on experience with:\")\n",
    "print(\"   \ud83d\udd2c Scientific method applied to AI\")\n",
    "print(\"   \ud83d\udcca Systematic performance analysis\")\n",
    "print(\"   \ud83c\udfaf Optimization for real-world conditions\")\n",
    "print(\"   \ud83e\udde0 Deep understanding of AI behavior\")\n",
    "\n",
    "print(\"\\n\ud83c\udf93 You're ready to build reliable AI applications!\")\n",
    "print(\"\\n\ud83d\udca1 Pro Tip: Keep experimenting! Every new scenario teaches you something about AI behavior.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\ude80 What's Next?\n",
    "\n",
    "Amazing work completing these detection experiments! You now have a **scientific understanding** of AI behavior.\n",
    "\n",
    "### \ud83d\udcda Continue Your AI Journey:\n",
    "\n",
    "**Next Notebook**: `Object_Types_Guide.ipynb`\n",
    "- Complete reference to all 80+ detectable objects\n",
    "- Tips for detecting specific object categories\n",
    "- Understanding the COCO dataset\n",
    "\n",
    "**Ready for Level 3?**: `../03_Interactive_AI/AI_with_Buzzer_Alerts.ipynb`\n",
    "- Make AI respond to the world with sound and GPIO!\n",
    "- Build your first interactive AI system\n",
    "- Learn hardware integration patterns\n",
    "\n",
    "### \ud83c\udfaf Key Achievements Unlocked\n",
    "\n",
    "\u2705 **Scientific AI Analysis**: You can systematically test AI performance\n",
    "\n",
    "\u2705 **Performance Optimization**: You understand the trade-offs and tuning parameters\n",
    "\n",
    "\u2705 **Real-World Readiness**: You know how environmental factors affect AI\n",
    "\n",
    "\u2705 **Reliability Assessment**: You can evaluate when AI results are trustworthy\n",
    "\n",
    "---\n",
    "\n",
    "### \ud83e\udde0 You're Now an AI Experimentalist!\n",
    "\n",
    "You have the skills to **test**, **validate**, and **optimize** AI systems for real-world deployment. This experimental mindset will serve you well as you build increasingly sophisticated AI applications! \ud83e\udd16\ud83d\udd2c\u2728"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}