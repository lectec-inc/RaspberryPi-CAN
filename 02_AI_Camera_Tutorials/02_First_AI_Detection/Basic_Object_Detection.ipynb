{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üß† Level 2: Your First AI Object Detection Experience\n",
        "\n",
        "**Welcome to real Artificial Intelligence!** üéâ\n",
        "\n",
        "In this notebook, you'll experience **real-time object detection** for the first time. Your camera will **automatically identify objects** in the real world and tell you what it sees!\n",
        "\n",
        "## üéØ What You'll Learn\n",
        "- How AI \"sees\" and recognizes objects\n",
        "- What confidence scores mean\n",
        "- How bounding boxes work\n",
        "- Why the IMX500 camera is special\n",
        "\n",
        "## üîß What You'll Need\n",
        "- Sony IMX500 AI Camera connected to your Pi\n",
        "- Some objects to detect (phone, cup, book, etc.)\n",
        "- Good lighting for best results\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìö Understanding AI Object Detection\n",
        "\n",
        "**What is Object Detection?**\n",
        "\n",
        "Imagine you're looking at a photo and someone asks you:\n",
        "- \"What objects do you see?\"\n",
        "- \"Where exactly are they in the photo?\"\n",
        "- \"How sure are you that's really a cup?\"\n",
        "\n",
        "That's exactly what AI object detection does! It:\n",
        "1. **Identifies** what objects are in the image\n",
        "2. **Locates** where each object is (draws boxes around them)\n",
        "3. **Estimates** how confident it is about each detection\n",
        "\n",
        "**Why is the IMX500 Special?**\n",
        "\n",
        "Most cameras just capture images. The IMX500 is **smart** - it has a tiny computer built right into the sensor that runs AI models at incredible speed!\n",
        "\n",
        "- **üöÄ Super Fast**: Processes AI at 30 frames per second\n",
        "- **‚ö° Efficient**: Your Pi CPU stays cool and available\n",
        "- **üéØ Accurate**: Uses proven MobileNet SSD architecture\n",
        "- **üì¶ Ready-to-Use**: No complex setup required"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üî• Let's Start Detecting!\n",
        "\n",
        "Run the cell below to start your first AI object detection experience:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "import subprocess\nimport cv2\nimport numpy as np\nfrom IPython.display import display, clear_output, Image\nimport ipywidgets as widgets\nimport threading\nimport time\nimport json\n\n# ‚îÄ‚îÄ Setup: Clean any existing camera processes\nprint(\"üîß Setting up AI camera...\")\nfor p in (\"libcamera-vid\", \"libcamera-still\", \"libcamera-raw\"):\n    subprocess.run([\"pkill\", \"-9\", p], stderr=subprocess.DEVNULL)\nsubprocess.run([\"sudo\", \"rmmod\", \"bcm2835_v4l2\"], stderr=subprocess.DEVNULL)\n\nprint(\"‚úÖ Camera setup complete!\")\nprint(\"\\nStarting AI Object Detection...\")\nprint(\"\\nTry pointing the camera at:\")\nprint(\"   ‚Ä¢ Your phone or laptop\")\nprint(\"   ‚Ä¢ A cup or bottle\")\nprint(\"   ‚Ä¢ A book or notebook\")\nprint(\"   ‚Ä¢ Your hand (detects as 'person')\")\nprint(\"   ‚Ä¢ Any household objects!\")\n\n# Create stop button\nstop_button = widgets.ToggleButton(\n    value=False,\n    description='‚èπÔ∏è Stop AI Detection',\n    button_style='danger',\n    layout=widgets.Layout(width='200px', height='40px')\n)\n\n# Create status display\nstatus_output = widgets.Output()\n\ndisplay(widgets.VBox([stop_button, status_output]))",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "def run_ai_detection():\n    \"\"\"Run periodic AI object detection with the IMX500 camera - optimized for headless operation\"\"\"\n    \n    detection_count = 0\n    frames_processed = 0\n    \n    with status_output:\n        clear_output(wait=True)\n        print(\"AI Detection Status: ACTIVE (Headless Mode)\")\n        print(\"Taking periodic AI-enhanced photos...\")\n        print(\"This works great in headless environments!\")\n        \n    # Create display handle for updating the same image area\n    display_handle = display(None, display_id=True)\n    \n    while not stop_button.value:\n        try:\n            # Capture still image with AI processing\n            output_file = f\"/tmp/ai_detection_{frames_processed}.jpg\"\n            \n            cmd = [\n                \"rpicam-still\",\n                \"--width\", \"1280\",   # High quality for better detection\n                \"--height\", \"720\",\n                \"--post-process-file\", \"/usr/share/rpi-camera-assets/imx500_mobilenet_ssd.json\",\n                \"-o\", output_file,\n                \"--immediate\",        # Take photo immediately\n                \"--timeout\", \"100\"    # Quick timeout\n            ]\n            \n            # Run capture command\n            result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)\n            \n            if result.returncode == 0:\n                # Read and display the AI-enhanced image\n                try:\n                    with open(output_file, 'rb') as f:\n                        img_data = f.read()\n                    \n                    # Display the image with AI detections\n                    display_handle.update(Image(data=img_data))\n                    \n                    frames_processed += 1\n                    \n                    # Check for detections in stderr output (where AI results are logged)\n                    if \"Object:\" in result.stderr:\n                        detection_count += 1\n                    \n                    # Update status\n                    with status_output:\n                        clear_output(wait=True)\n                        print(f\"AI Detection Status: ACTIVE (Headless Mode)\")\n                        print(f\"Photos processed: {frames_processed}\")\n                        print(f\"‚úÖ AI detections found: {detection_count}\")\n                        print(f\"Updating every ~3 seconds\")\n                        print(f\"\\\\nLook for colored boxes around detected objects!\")\n                        print(f\"Object names appear above each box\")\n                        print(f\"Confidence scores show AI certainty\")\n                        print(f\"\\\\nWorking in headless mode - perfect for remote learning!\")\n                    \n                    # Clean up the temporary file\n                    try:\n                        import os\n                        os.remove(output_file)\n                    except:\n                        pass\n                        \n                except Exception as e:\n                    print(f\"Display error: {e}\")\n                    \n            else:\n                with status_output:\n                    clear_output(wait=True)\n                    print(\"‚ùå Camera capture failed\")\n                    print(\"Troubleshooting:\")\n                    print(\"   ‚Ä¢ Check IMX500 camera connection\")\n                    print(\"   ‚Ä¢ Verify AI model files exist\")\n                    print(\"   ‚Ä¢ Try restarting notebook\")\n                    break\n            \n            # Wait before next capture (headless-friendly approach)\n            time.sleep(3)\n            \n        except subprocess.TimeoutExpired:\n            with status_output:\n                clear_output(wait=True)\n                print(\"Camera timeout - retrying...\")\n            continue\n            \n        except Exception as e:\n            with status_output:\n                clear_output(wait=True)\n                print(f\"‚ùå Error: {str(e)}\")\n                print(\"Troubleshooting:\")\n                print(\"   ‚Ä¢ Check camera connection\")\n                print(\"   ‚Ä¢ Verify model files exist\")\n                print(\"   ‚Ä¢ Try kernel restart\")\n            break\n    \n    # Final status\n    with status_output:\n        clear_output(wait=True)\n        print(\"‚èπÔ∏è AI Detection stopped\")\n        print(f\"Total photos processed: {frames_processed}\")\n        print(f\"Total detections found: {detection_count}\")\n\n# Start AI detection in a separate thread\ndetection_thread = threading.Thread(target=run_ai_detection, daemon=True)\ndetection_thread.start()\n\nprint(\"\\\\nüöÄ AI Object Detection is now running! (Headless Mode)\")\nprint(\"\\\\nWatch the images above - you should see:\")\nprint(\"   Colored boxes around detected objects\")\nprint(\"   Object names (like 'person', 'cell phone', 'cup')\")\nprint(\"   Confidence scores (like 85%, 92%)\")\nprint(\"\\\\nImages update every ~3 seconds - perfect for headless operation!\")\nprint(\"\\\\n‚èπÔ∏è Click 'Stop AI Detection' when you're done exploring!\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéâ Congratulations!\n",
        "\n",
        "You just ran **real artificial intelligence** on your Raspberry Pi! Here's what just happened:\n",
        "\n",
        "### üß† The Magic Behind the Scenes\n",
        "\n",
        "1. **AI Model**: Your camera used **MobileNet SSD** - a neural network trained on millions of images\n",
        "2. **On-Sensor Processing**: The AI runs directly on the IMX500 chip, not your Pi's CPU!\n",
        "3. **Real-Time Speed**: 30 frames per second of AI analysis\n",
        "4. **80 Object Types**: Can detect phones, cups, people, cars, and much more\n",
        "\n",
        "### üîç What Did You Notice?\n",
        "\n",
        "**Bounding Boxes**: The colored rectangles around objects\n",
        "- Show exactly where the AI \"sees\" each object\n",
        "- Different colors for different object types\n",
        "\n",
        "**Object Labels**: The text above each box\n",
        "- Shows what the AI thinks the object is\n",
        "- Based on training from millions of example images\n",
        "\n",
        "**Confidence Scores**: The percentages you saw\n",
        "- How \"sure\" the AI is about each detection\n",
        "- Higher = more confident (85% vs 45%)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß™ Quick Experiment\n",
        "\n",
        "Before moving on, try this fun experiment to understand how AI \"sees\" differently than humans:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Quick AI Understanding Test\n",
        "print(\"üß™ AI UNDERSTANDING EXPERIMENT\")\n",
        "print(\"=\"*40)\n",
        "print(\"\\nüìù What did you observe? (Think about these questions)\")\n",
        "print(\"\\n1. üéØ ACCURACY QUESTIONS:\")\n",
        "print(\"   ‚Ä¢ Did the AI correctly identify most objects?\")\n",
        "print(\"   ‚Ä¢ What objects was it most confident about?\")\n",
        "print(\"   ‚Ä¢ Did it ever mistake one object for another?\")\n",
        "\n",
        "print(\"\\n2. üîç DETECTION QUESTIONS:\")\n",
        "print(\"   ‚Ä¢ How close did you need to hold objects?\")\n",
        "print(\"   ‚Ä¢ Did lighting affect the detections?\")\n",
        "print(\"   ‚Ä¢ What happened when you moved objects quickly?\")\n",
        "\n",
        "print(\"\\n3. üß† AI BEHAVIOR QUESTIONS:\")\n",
        "print(\"   ‚Ä¢ Did confidence scores change as you moved objects?\")\n",
        "print(\"   ‚Ä¢ What was the lowest confidence score you saw?\")\n",
        "print(\"   ‚Ä¢ Did it detect partial objects (like half a cup)?\")\n",
        "\n",
        "print(\"\\nüí° These observations help you understand:\")\n",
        "print(\"   ‚úì AI has strengths and limitations\")\n",
        "print(\"   ‚úì Confidence scores matter for real applications\")\n",
        "print(\"   ‚úì Environmental factors affect AI performance\")\n",
        "\n",
        "print(\"\\nüéì You're now ready for Level 2.2: Understanding AI Results!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ What's Next?\n",
        "\n",
        "Amazing work! You've successfully:\n",
        "- ‚úÖ Experienced real-time AI object detection\n",
        "- ‚úÖ Learned about bounding boxes and confidence scores\n",
        "- ‚úÖ Understood how the IMX500 processes AI on-sensor\n",
        "\n",
        "### üìö Continue Your AI Journey:\n",
        "\n",
        "**Next Notebook**: `Understanding_Results.ipynb`\n",
        "- Deep dive into confidence scores\n",
        "- Learn when to trust AI predictions\n",
        "- Understand detection thresholds\n",
        "\n",
        "**Then Try**: `Detection_Experiments.ipynb`\n",
        "- Test different objects and scenarios\n",
        "- Explore detection limits and capabilities\n",
        "- Learn about environmental factors\n",
        "\n",
        "---\n",
        "\n",
        "### üéØ Key Takeaways\n",
        "\n",
        "1. **AI is Fast**: 30fps real-time detection on a tiny Pi Zero 2W!\n",
        "2. **AI is Smart**: Recognizes 80+ different object types\n",
        "3. **AI is Honest**: Gives confidence scores, not just guesses\n",
        "4. **AI is Practical**: Ready to use in real applications\n",
        "\n",
        "**You're now officially an AI practitioner!** üéâü§ñ"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}